Wed Apr 07 12:44:47 /Users/theodore/phutball $ ipython                                                        (sage)
Python 3.9.2 | packaged by conda-forge | (default, Feb 21 2021, 05:02:20) 
Type 'copyright', 'credits' or 'license' for more information
IPython 7.22.0 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import pickle

In [2]: with open("2021-04-07-3ply-data1.pickle","rb") as f:
   ...:     (train_boards, train_labels), (test_boards, test_labels) = pickle.load(f)
   ...: 

In [3]: train_boards.shape
Out[3]: (19000, 571)

In [4]: train_labels.shape
Out[4]: (19000,)

In [5]: test_boards.shape
Out[5]: (4667, 571)

In [6]: test_labels.shape
Out[6]: (4667,)

In [7]: import tensorflow as tf
   ...: 
   ...: from tensorflow import keras
   ...: from tensorflow.keras import layers
   ...: from tensorflow.keras.layers.experimental import preprocessing
   ...: 
   ...: print(tf.__version__)
   ...: 
---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-7-e610ecf6537d> in <module>
----> 1 import tensorflow as tf
      2 
      3 from tensorflow import keras
      4 from tensorflow.keras import layers
      5 from tensorflow.keras.layers.experimental import preprocessing

ModuleNotFoundError: No module named 'tensorflow'

In [8]: import tensorflow as tf
   ...: 
   ...: from tensorflow import keras
   ...: from tensorflow.keras import layers
   ...: from tensorflow.keras.layers.experimental import preprocessing
   ...: 
   ...: print(tf.__version__)
   ...: 
INFO:tensorflow:Enabling eager execution
INFO:tensorflow:Enabling v2 tensorshape
INFO:tensorflow:Enabling resource variables
INFO:tensorflow:Enabling tensor equality
INFO:tensorflow:Enabling control flow v2
2.5.0-rc0

In [9]: import matplotlib.pyplot as plt
   ...: import numpy as np
   ...: import pandas as pd
   ...: import seaborn as sns

In [10]: 
    ...: # Make numpy printouts easier to read.
    ...: np.set_printoptions(precision=3, suppress=True)
    ...: 

In [11]: model = keras.Sequential([
    ...:       layers.Dense(128, activation='relu'),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 
2021-04-07 13:12:56.763543: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.

In [12]: model.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [13]: model.summary()
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-13-5f15418b3570> in <module>
----> 1 model.summary()

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py in summary(self, line_length, positions, print_fn)
   2475     """
   2476     if not self.built:
-> 2477       raise ValueError('This model has not yet been built. '
   2478                        'Build the model first by calling `build()` or calling '
   2479                        '`fit()` with some data, or specify '

ValueError: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.

In [14]: model = keras.Sequential([
    ...:       layers.Dense(128, activation='relu', input_shape = 571),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-14-97baa952e187> in <module>
      1 model = keras.Sequential([
----> 2       layers.Dense(128, activation='relu', input_shape = 571),
      3       layers.Dense(1)
      4   ])

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/keras/layers/core.py in __init__(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)
   1161                bias_constraint=None,
   1162                **kwargs):
-> 1163     super(Dense, self).__init__(
   1164         activity_regularizer=activity_regularizer, **kwargs)
   1165 

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    520     self._self_setattr_tracking = False  # pylint: disable=protected-access
    521     try:
--> 522       result = method(self, *args, **kwargs)
    523     finally:
    524       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py in __init__(self, trainable, name, dtype, dynamic, **kwargs)
    436         else:
    437           batch_size = None
--> 438         batch_input_shape = (batch_size,) + tuple(kwargs['input_shape'])
    439       self._batch_input_shape = batch_input_shape
    440 

TypeError: 'int' object is not iterable

In [15]: model = keras.Sequential([
    ...:       layers.Dense(128, activation='relu', input_shape = (571,)),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [16]: model.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [17]: model.summary()
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_3 (Dense)              (None, 128)               73216     
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 129       
=================================================================
Total params: 73,345
Trainable params: 73,345
Non-trainable params: 0
_________________________________________________________________

In [18]: history = model.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
2021-04-07 13:17:19.339488: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/100
475/475 [==============================] - 1s 1ms/step - loss: 0.1477 - val_loss: 0.0950
Epoch 2/100
475/475 [==============================] - 0s 787us/step - loss: 0.0671 - val_loss: 0.0870
Epoch 3/100
475/475 [==============================] - 0s 801us/step - loss: 0.0570 - val_loss: 0.0846
Epoch 4/100
475/475 [==============================] - 0s 804us/step - loss: 0.0509 - val_loss: 0.0805
Epoch 5/100
475/475 [==============================] - 0s 792us/step - loss: 0.0471 - val_loss: 0.0779
Epoch 6/100
475/475 [==============================] - 0s 811us/step - loss: 0.0445 - val_loss: 0.0789
Epoch 7/100
475/475 [==============================] - 0s 791us/step - loss: 0.0414 - val_loss: 0.0766
Epoch 8/100
475/475 [==============================] - 0s 793us/step - loss: 0.0402 - val_loss: 0.0750
Epoch 9/100
475/475 [==============================] - 0s 797us/step - loss: 0.0387 - val_loss: 0.0772
Epoch 10/100
475/475 [==============================] - 0s 813us/step - loss: 0.0368 - val_loss: 0.0753
Epoch 11/100
475/475 [==============================] - 0s 822us/step - loss: 0.0356 - val_loss: 0.0746
Epoch 12/100
475/475 [==============================] - 0s 772us/step - loss: 0.0339 - val_loss: 0.0737
Epoch 13/100
475/475 [==============================] - 0s 852us/step - loss: 0.0333 - val_loss: 0.0751
Epoch 14/100
475/475 [==============================] - 0s 784us/step - loss: 0.0320 - val_loss: 0.0736
Epoch 15/100
475/475 [==============================] - 0s 774us/step - loss: 0.0314 - val_loss: 0.0733
Epoch 16/100
475/475 [==============================] - 0s 765us/step - loss: 0.0302 - val_loss: 0.0733
Epoch 17/100
475/475 [==============================] - 0s 777us/step - loss: 0.0300 - val_loss: 0.0729
Epoch 18/100
475/475 [==============================] - 0s 782us/step - loss: 0.0294 - val_loss: 0.0747
Epoch 19/100
475/475 [==============================] - 0s 769us/step - loss: 0.0289 - val_loss: 0.0736
Epoch 20/100
475/475 [==============================] - 0s 790us/step - loss: 0.0279 - val_loss: 0.0749
Epoch 21/100
475/475 [==============================] - 0s 811us/step - loss: 0.0281 - val_loss: 0.0734
Epoch 22/100
475/475 [==============================] - 0s 791us/step - loss: 0.0269 - val_loss: 0.0740
Epoch 23/100
475/475 [==============================] - 0s 808us/step - loss: 0.0268 - val_loss: 0.0734
Epoch 24/100
475/475 [==============================] - 0s 776us/step - loss: 0.0266 - val_loss: 0.0741
Epoch 25/100
475/475 [==============================] - 0s 849us/step - loss: 0.0258 - val_loss: 0.0739
Epoch 26/100
475/475 [==============================] - 0s 806us/step - loss: 0.0253 - val_loss: 0.0724
Epoch 27/100
475/475 [==============================] - 0s 815us/step - loss: 0.0244 - val_loss: 0.0735
Epoch 28/100
475/475 [==============================] - 0s 775us/step - loss: 0.0246 - val_loss: 0.0739
Epoch 29/100
475/475 [==============================] - 0s 809us/step - loss: 0.0243 - val_loss: 0.0734
Epoch 30/100
475/475 [==============================] - 0s 911us/step - loss: 0.0236 - val_loss: 0.0740
Epoch 31/100
475/475 [==============================] - 0s 840us/step - loss: 0.0236 - val_loss: 0.0749
Epoch 32/100
475/475 [==============================] - 0s 793us/step - loss: 0.0236 - val_loss: 0.0749
Epoch 33/100
475/475 [==============================] - 0s 802us/step - loss: 0.0233 - val_loss: 0.0752
Epoch 34/100
475/475 [==============================] - 0s 788us/step - loss: 0.0220 - val_loss: 0.0757
Epoch 35/100
475/475 [==============================] - 0s 808us/step - loss: 0.0223 - val_loss: 0.0753
Epoch 36/100
475/475 [==============================] - 0s 808us/step - loss: 0.0226 - val_loss: 0.0745
Epoch 37/100
475/475 [==============================] - 0s 794us/step - loss: 0.0215 - val_loss: 0.0759
Epoch 38/100
475/475 [==============================] - 0s 768us/step - loss: 0.0220 - val_loss: 0.0749
Epoch 39/100
475/475 [==============================] - 0s 813us/step - loss: 0.0212 - val_loss: 0.0757
Epoch 40/100
475/475 [==============================] - 0s 796us/step - loss: 0.0215 - val_loss: 0.0758
Epoch 41/100
475/475 [==============================] - 0s 806us/step - loss: 0.0216 - val_loss: 0.0761
Epoch 42/100
475/475 [==============================] - 0s 791us/step - loss: 0.0209 - val_loss: 0.0755
Epoch 43/100
475/475 [==============================] - 0s 821us/step - loss: 0.0207 - val_loss: 0.0749
Epoch 44/100
475/475 [==============================] - 0s 789us/step - loss: 0.0206 - val_loss: 0.0749
Epoch 45/100
475/475 [==============================] - 0s 813us/step - loss: 0.0203 - val_loss: 0.0761
Epoch 46/100
475/475 [==============================] - 0s 795us/step - loss: 0.0209 - val_loss: 0.0759
Epoch 47/100
475/475 [==============================] - 0s 807us/step - loss: 0.0203 - val_loss: 0.0741
Epoch 48/100
475/475 [==============================] - 0s 806us/step - loss: 0.0200 - val_loss: 0.0765
Epoch 49/100
475/475 [==============================] - 0s 820us/step - loss: 0.0201 - val_loss: 0.0749
Epoch 50/100
475/475 [==============================] - 0s 793us/step - loss: 0.0193 - val_loss: 0.0751
Epoch 51/100
475/475 [==============================] - 0s 782us/step - loss: 0.0193 - val_loss: 0.0759
Epoch 52/100
475/475 [==============================] - 0s 931us/step - loss: 0.0191 - val_loss: 0.0755
Epoch 53/100
475/475 [==============================] - 0s 934us/step - loss: 0.0190 - val_loss: 0.0755
Epoch 54/100
475/475 [==============================] - 0s 935us/step - loss: 0.0192 - val_loss: 0.0766
Epoch 55/100
475/475 [==============================] - 0s 946us/step - loss: 0.0187 - val_loss: 0.0764
Epoch 56/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0754
Epoch 57/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0183 - val_loss: 0.0764
Epoch 58/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0184 - val_loss: 0.0770
Epoch 59/100
475/475 [==============================] - 0s 947us/step - loss: 0.0180 - val_loss: 0.0764
Epoch 60/100
475/475 [==============================] - 0s 954us/step - loss: 0.0184 - val_loss: 0.0759
Epoch 61/100
475/475 [==============================] - 0s 941us/step - loss: 0.0181 - val_loss: 0.0765
Epoch 62/100
475/475 [==============================] - 0s 813us/step - loss: 0.0183 - val_loss: 0.0768
Epoch 63/100
475/475 [==============================] - 0s 780us/step - loss: 0.0180 - val_loss: 0.0772
Epoch 64/100
475/475 [==============================] - 0s 780us/step - loss: 0.0176 - val_loss: 0.0793
Epoch 65/100
475/475 [==============================] - 0s 796us/step - loss: 0.0178 - val_loss: 0.0769
Epoch 66/100
475/475 [==============================] - 0s 796us/step - loss: 0.0177 - val_loss: 0.0767
Epoch 67/100
475/475 [==============================] - 0s 769us/step - loss: 0.0172 - val_loss: 0.0768
Epoch 68/100
475/475 [==============================] - 0s 770us/step - loss: 0.0179 - val_loss: 0.0766
Epoch 69/100
475/475 [==============================] - 0s 767us/step - loss: 0.0174 - val_loss: 0.0776
Epoch 70/100
475/475 [==============================] - 0s 788us/step - loss: 0.0171 - val_loss: 0.0771
Epoch 71/100
475/475 [==============================] - 0s 772us/step - loss: 0.0172 - val_loss: 0.0778
Epoch 72/100
475/475 [==============================] - 0s 765us/step - loss: 0.0168 - val_loss: 0.0770
Epoch 73/100
475/475 [==============================] - 0s 773us/step - loss: 0.0165 - val_loss: 0.0773
Epoch 74/100
475/475 [==============================] - 0s 784us/step - loss: 0.0169 - val_loss: 0.0773
Epoch 75/100
475/475 [==============================] - 0s 765us/step - loss: 0.0165 - val_loss: 0.0785
Epoch 76/100
475/475 [==============================] - 0s 766us/step - loss: 0.0168 - val_loss: 0.0769
Epoch 77/100
475/475 [==============================] - 0s 774us/step - loss: 0.0164 - val_loss: 0.0777
Epoch 78/100
475/475 [==============================] - 0s 781us/step - loss: 0.0161 - val_loss: 0.0771
Epoch 79/100
475/475 [==============================] - 0s 779us/step - loss: 0.0164 - val_loss: 0.0773
Epoch 80/100
475/475 [==============================] - 0s 771us/step - loss: 0.0166 - val_loss: 0.0772
Epoch 81/100
475/475 [==============================] - 0s 757us/step - loss: 0.0162 - val_loss: 0.0778
Epoch 82/100
475/475 [==============================] - 0s 779us/step - loss: 0.0162 - val_loss: 0.0775
Epoch 83/100
475/475 [==============================] - 0s 779us/step - loss: 0.0161 - val_loss: 0.0785
Epoch 84/100
475/475 [==============================] - 0s 761us/step - loss: 0.0161 - val_loss: 0.0776
Epoch 85/100
475/475 [==============================] - 0s 785us/step - loss: 0.0161 - val_loss: 0.0771
Epoch 86/100
475/475 [==============================] - 0s 780us/step - loss: 0.0158 - val_loss: 0.0777
Epoch 87/100
475/475 [==============================] - 0s 862us/step - loss: 0.0155 - val_loss: 0.0772
Epoch 88/100
475/475 [==============================] - 0s 858us/step - loss: 0.0159 - val_loss: 0.0778
Epoch 89/100
475/475 [==============================] - 0s 783us/step - loss: 0.0155 - val_loss: 0.0782
Epoch 90/100
475/475 [==============================] - 0s 768us/step - loss: 0.0156 - val_loss: 0.0773
Epoch 91/100
475/475 [==============================] - 0s 775us/step - loss: 0.0155 - val_loss: 0.0782
Epoch 92/100
475/475 [==============================] - 0s 769us/step - loss: 0.0150 - val_loss: 0.0792
Epoch 93/100
475/475 [==============================] - 0s 765us/step - loss: 0.0156 - val_loss: 0.0771
Epoch 94/100
475/475 [==============================] - 0s 772us/step - loss: 0.0155 - val_loss: 0.0777
Epoch 95/100
475/475 [==============================] - 0s 811us/step - loss: 0.0155 - val_loss: 0.0783
Epoch 96/100
475/475 [==============================] - 0s 870us/step - loss: 0.0152 - val_loss: 0.0773
Epoch 97/100
475/475 [==============================] - 0s 804us/step - loss: 0.0150 - val_loss: 0.0780
Epoch 98/100
475/475 [==============================] - 0s 825us/step - loss: 0.0152 - val_loss: 0.0787
Epoch 99/100
475/475 [==============================] - 0s 811us/step - loss: 0.0149 - val_loss: 0.0775
Epoch 100/100
475/475 [==============================] - 0s 778us/step - loss: 0.0148 - val_loss: 0.0786

In [19]: train_boards.shape
Out[19]: (19000, 571)

In [20]: from tensorflow.keras import regularizers

In [21]: l2_model = keras.Sequential([
    ...:       layers.Dense(128, activation='relu', input_shape = (571,),kernel_regularizer=regularizers.l2(0.001)),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [22]: l2_model.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [23]: l2_model.summary()
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_5 (Dense)              (None, 128)               73216     
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 129       
=================================================================
Total params: 73,345
Trainable params: 73,345
Non-trainable params: 0
_________________________________________________________________

In [24]: l2_history = l2_model.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 946us/step - loss: 0.2715 - val_loss: 0.1265
Epoch 2/100
475/475 [==============================] - 0s 800us/step - loss: 0.1038 - val_loss: 0.1106
Epoch 3/100
475/475 [==============================] - 0s 827us/step - loss: 0.0878 - val_loss: 0.1017
Epoch 4/100
475/475 [==============================] - 0s 818us/step - loss: 0.0811 - val_loss: 0.1000
Epoch 5/100
475/475 [==============================] - 0s 819us/step - loss: 0.0778 - val_loss: 0.0993
Epoch 6/100
475/475 [==============================] - 0s 833us/step - loss: 0.0749 - val_loss: 0.0964
Epoch 7/100
475/475 [==============================] - 0s 825us/step - loss: 0.0737 - val_loss: 0.1000
Epoch 8/100
475/475 [==============================] - 0s 833us/step - loss: 0.0720 - val_loss: 0.0931
Epoch 9/100
475/475 [==============================] - 0s 835us/step - loss: 0.0698 - val_loss: 0.0933
Epoch 10/100
475/475 [==============================] - 0s 861us/step - loss: 0.0684 - val_loss: 0.0915
Epoch 11/100
475/475 [==============================] - 0s 814us/step - loss: 0.0687 - val_loss: 0.0918
Epoch 12/100
475/475 [==============================] - 0s 834us/step - loss: 0.0664 - val_loss: 0.0933
Epoch 13/100
475/475 [==============================] - 0s 814us/step - loss: 0.0667 - val_loss: 0.0893
Epoch 14/100
475/475 [==============================] - 0s 848us/step - loss: 0.0647 - val_loss: 0.0897
Epoch 15/100
475/475 [==============================] - 0s 832us/step - loss: 0.0644 - val_loss: 0.0910
Epoch 16/100
475/475 [==============================] - 0s 845us/step - loss: 0.0636 - val_loss: 0.0914
Epoch 17/100
475/475 [==============================] - 0s 837us/step - loss: 0.0631 - val_loss: 0.0916
Epoch 18/100
475/475 [==============================] - 0s 840us/step - loss: 0.0627 - val_loss: 0.0917
Epoch 19/100
475/475 [==============================] - 0s 832us/step - loss: 0.0632 - val_loss: 0.0892
Epoch 20/100
475/475 [==============================] - 0s 798us/step - loss: 0.0627 - val_loss: 0.0883
Epoch 21/100
475/475 [==============================] - 0s 805us/step - loss: 0.0613 - val_loss: 0.0887
Epoch 22/100
475/475 [==============================] - 0s 809us/step - loss: 0.0611 - val_loss: 0.0864
Epoch 23/100
475/475 [==============================] - 0s 820us/step - loss: 0.0611 - val_loss: 0.0882
Epoch 24/100
475/475 [==============================] - 0s 843us/step - loss: 0.0607 - val_loss: 0.0873
Epoch 25/100
475/475 [==============================] - 0s 835us/step - loss: 0.0609 - val_loss: 0.0890
Epoch 26/100
475/475 [==============================] - 0s 825us/step - loss: 0.0600 - val_loss: 0.0885
Epoch 27/100
475/475 [==============================] - 0s 805us/step - loss: 0.0601 - val_loss: 0.0871
Epoch 28/100
475/475 [==============================] - 0s 829us/step - loss: 0.0590 - val_loss: 0.0873
Epoch 29/100
475/475 [==============================] - 0s 819us/step - loss: 0.0597 - val_loss: 0.0868
Epoch 30/100
475/475 [==============================] - 0s 827us/step - loss: 0.0588 - val_loss: 0.0870
Epoch 31/100
475/475 [==============================] - 0s 855us/step - loss: 0.0590 - val_loss: 0.0855
Epoch 32/100
475/475 [==============================] - 0s 806us/step - loss: 0.0583 - val_loss: 0.0860
Epoch 33/100
475/475 [==============================] - 0s 811us/step - loss: 0.0591 - val_loss: 0.0906
Epoch 34/100
475/475 [==============================] - 0s 829us/step - loss: 0.0590 - val_loss: 0.0886
Epoch 35/100
475/475 [==============================] - 0s 812us/step - loss: 0.0587 - val_loss: 0.0877
Epoch 36/100
475/475 [==============================] - 0s 853us/step - loss: 0.0579 - val_loss: 0.0880
Epoch 37/100
475/475 [==============================] - 0s 843us/step - loss: 0.0586 - val_loss: 0.0906
Epoch 38/100
475/475 [==============================] - 0s 830us/step - loss: 0.0579 - val_loss: 0.0870
Epoch 39/100
475/475 [==============================] - 0s 827us/step - loss: 0.0582 - val_loss: 0.0867
Epoch 40/100
475/475 [==============================] - 0s 823us/step - loss: 0.0577 - val_loss: 0.0880
Epoch 41/100
475/475 [==============================] - 0s 837us/step - loss: 0.0571 - val_loss: 0.0893
Epoch 42/100
475/475 [==============================] - 0s 833us/step - loss: 0.0582 - val_loss: 0.0884
Epoch 43/100
475/475 [==============================] - 0s 806us/step - loss: 0.0571 - val_loss: 0.0886
Epoch 44/100
475/475 [==============================] - 0s 835us/step - loss: 0.0580 - val_loss: 0.0870
Epoch 45/100
475/475 [==============================] - 0s 812us/step - loss: 0.0569 - val_loss: 0.0883
Epoch 46/100
475/475 [==============================] - 0s 802us/step - loss: 0.0578 - val_loss: 0.0867
Epoch 47/100
475/475 [==============================] - 0s 816us/step - loss: 0.0582 - val_loss: 0.0878
Epoch 48/100
475/475 [==============================] - 0s 816us/step - loss: 0.0566 - val_loss: 0.0874
Epoch 49/100
475/475 [==============================] - 0s 826us/step - loss: 0.0563 - val_loss: 0.0878
Epoch 50/100
475/475 [==============================] - 0s 810us/step - loss: 0.0567 - val_loss: 0.0899
Epoch 51/100
475/475 [==============================] - 0s 819us/step - loss: 0.0572 - val_loss: 0.0873
Epoch 52/100
475/475 [==============================] - 0s 836us/step - loss: 0.0566 - val_loss: 0.0878
Epoch 53/100
475/475 [==============================] - 0s 842us/step - loss: 0.0567 - val_loss: 0.0871
Epoch 54/100
475/475 [==============================] - 0s 811us/step - loss: 0.0571 - val_loss: 0.0882
Epoch 55/100
475/475 [==============================] - 0s 794us/step - loss: 0.0569 - val_loss: 0.0864
Epoch 56/100
475/475 [==============================] - 0s 803us/step - loss: 0.0559 - val_loss: 0.0886
Epoch 57/100
475/475 [==============================] - 0s 816us/step - loss: 0.0563 - val_loss: 0.0889
Epoch 58/100
475/475 [==============================] - 0s 804us/step - loss: 0.0557 - val_loss: 0.0871
Epoch 59/100
475/475 [==============================] - 0s 833us/step - loss: 0.0564 - val_loss: 0.0867
Epoch 60/100
475/475 [==============================] - 0s 815us/step - loss: 0.0561 - val_loss: 0.0860
Epoch 61/100
475/475 [==============================] - 0s 823us/step - loss: 0.0554 - val_loss: 0.0861
Epoch 62/100
475/475 [==============================] - 0s 824us/step - loss: 0.0554 - val_loss: 0.0865
Epoch 63/100
475/475 [==============================] - 0s 795us/step - loss: 0.0563 - val_loss: 0.0892
Epoch 64/100
475/475 [==============================] - 0s 815us/step - loss: 0.0566 - val_loss: 0.0884
Epoch 65/100
475/475 [==============================] - 0s 831us/step - loss: 0.0561 - val_loss: 0.0861
Epoch 66/100
475/475 [==============================] - 0s 836us/step - loss: 0.0559 - val_loss: 0.0862
Epoch 67/100
475/475 [==============================] - 0s 819us/step - loss: 0.0557 - val_loss: 0.0860
Epoch 68/100
475/475 [==============================] - 0s 826us/step - loss: 0.0554 - val_loss: 0.0881
Epoch 69/100
475/475 [==============================] - 0s 831us/step - loss: 0.0551 - val_loss: 0.0863
Epoch 70/100
475/475 [==============================] - 0s 822us/step - loss: 0.0568 - val_loss: 0.0863
Epoch 71/100
475/475 [==============================] - 0s 842us/step - loss: 0.0562 - val_loss: 0.0862
Epoch 72/100
475/475 [==============================] - 0s 852us/step - loss: 0.0568 - val_loss: 0.0862
Epoch 73/100
475/475 [==============================] - 0s 814us/step - loss: 0.0548 - val_loss: 0.0895
Epoch 74/100
475/475 [==============================] - 0s 816us/step - loss: 0.0561 - val_loss: 0.0884
Epoch 75/100
475/475 [==============================] - 0s 825us/step - loss: 0.0551 - val_loss: 0.0867
Epoch 76/100
475/475 [==============================] - 0s 808us/step - loss: 0.0548 - val_loss: 0.0889
Epoch 77/100
475/475 [==============================] - 0s 808us/step - loss: 0.0554 - val_loss: 0.0884
Epoch 78/100
475/475 [==============================] - 0s 840us/step - loss: 0.0562 - val_loss: 0.0885
Epoch 79/100
475/475 [==============================] - 0s 836us/step - loss: 0.0561 - val_loss: 0.0868
Epoch 80/100
475/475 [==============================] - 0s 825us/step - loss: 0.0557 - val_loss: 0.0845
Epoch 81/100
475/475 [==============================] - 0s 825us/step - loss: 0.0552 - val_loss: 0.0897
Epoch 82/100
475/475 [==============================] - 0s 822us/step - loss: 0.0552 - val_loss: 0.0879
Epoch 83/100
475/475 [==============================] - 0s 834us/step - loss: 0.0552 - val_loss: 0.0873
Epoch 84/100
475/475 [==============================] - 0s 824us/step - loss: 0.0547 - val_loss: 0.0873
Epoch 85/100
475/475 [==============================] - 0s 808us/step - loss: 0.0546 - val_loss: 0.0877
Epoch 86/100
475/475 [==============================] - 0s 800us/step - loss: 0.0555 - val_loss: 0.0884
Epoch 87/100
475/475 [==============================] - 0s 804us/step - loss: 0.0553 - val_loss: 0.0868
Epoch 88/100
475/475 [==============================] - 0s 822us/step - loss: 0.0551 - val_loss: 0.0874
Epoch 89/100
475/475 [==============================] - 0s 815us/step - loss: 0.0552 - val_loss: 0.0848
Epoch 90/100
475/475 [==============================] - 0s 831us/step - loss: 0.0548 - val_loss: 0.0863
Epoch 91/100
475/475 [==============================] - 0s 826us/step - loss: 0.0551 - val_loss: 0.0878
Epoch 92/100
475/475 [==============================] - 0s 797us/step - loss: 0.0554 - val_loss: 0.0859
Epoch 93/100
475/475 [==============================] - 0s 840us/step - loss: 0.0545 - val_loss: 0.0864
Epoch 94/100
475/475 [==============================] - 0s 837us/step - loss: 0.0552 - val_loss: 0.0863
Epoch 95/100
475/475 [==============================] - 0s 826us/step - loss: 0.0548 - val_loss: 0.0871
Epoch 96/100
475/475 [==============================] - 0s 842us/step - loss: 0.0548 - val_loss: 0.0886
Epoch 97/100
475/475 [==============================] - 0s 814us/step - loss: 0.0552 - val_loss: 0.0869
Epoch 98/100
475/475 [==============================] - 0s 839us/step - loss: 0.0557 - val_loss: 0.0876
Epoch 99/100
475/475 [==============================] - 0s 803us/step - loss: 0.0543 - val_loss: 0.0862
Epoch 100/100
475/475 [==============================] - 0s 809us/step - loss: 0.0549 - val_loss: 0.0880

In [25]: l2_model_01 = keras.Sequential([
    ...:       layers.Dense(128, activation='relu', input_shape = (571,),kernel_regularizer=regularizers.l2(0.01)),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [26]: l2_model_01.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [27]: l2_01_history = l2_model_01.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 962us/step - loss: 0.7139 - val_loss: 0.1323
Epoch 2/100
475/475 [==============================] - 0s 824us/step - loss: 0.1169 - val_loss: 0.1165
Epoch 3/100
475/475 [==============================] - 0s 841us/step - loss: 0.1077 - val_loss: 0.1136
Epoch 4/100
475/475 [==============================] - 0s 809us/step - loss: 0.1029 - val_loss: 0.1119
Epoch 5/100
475/475 [==============================] - 0s 810us/step - loss: 0.1007 - val_loss: 0.1089
Epoch 6/100
475/475 [==============================] - 0s 824us/step - loss: 0.0986 - val_loss: 0.1067
Epoch 7/100
475/475 [==============================] - 0s 817us/step - loss: 0.0954 - val_loss: 0.1044
Epoch 8/100
475/475 [==============================] - 0s 843us/step - loss: 0.0944 - val_loss: 0.1061
Epoch 9/100
475/475 [==============================] - 0s 831us/step - loss: 0.0919 - val_loss: 0.1046
Epoch 10/100
475/475 [==============================] - 0s 830us/step - loss: 0.0919 - val_loss: 0.1013
Epoch 11/100
475/475 [==============================] - 0s 838us/step - loss: 0.0906 - val_loss: 0.1019
Epoch 12/100
475/475 [==============================] - 0s 832us/step - loss: 0.0907 - val_loss: 0.1041
Epoch 13/100
475/475 [==============================] - 0s 833us/step - loss: 0.0900 - val_loss: 0.1057
Epoch 14/100
475/475 [==============================] - 0s 841us/step - loss: 0.0886 - val_loss: 0.0972
Epoch 15/100
475/475 [==============================] - 0s 824us/step - loss: 0.0886 - val_loss: 0.1003
Epoch 16/100
475/475 [==============================] - 0s 839us/step - loss: 0.0866 - val_loss: 0.1004
Epoch 17/100
475/475 [==============================] - 0s 831us/step - loss: 0.0871 - val_loss: 0.0987
Epoch 18/100
475/475 [==============================] - 0s 831us/step - loss: 0.0843 - val_loss: 0.1003
Epoch 19/100
475/475 [==============================] - 0s 836us/step - loss: 0.0846 - val_loss: 0.0997
Epoch 20/100
475/475 [==============================] - 0s 856us/step - loss: 0.0856 - val_loss: 0.0980
Epoch 21/100
475/475 [==============================] - 0s 842us/step - loss: 0.0843 - val_loss: 0.1003
Epoch 22/100
475/475 [==============================] - 0s 840us/step - loss: 0.0851 - val_loss: 0.0975
Epoch 23/100
475/475 [==============================] - 0s 837us/step - loss: 0.0845 - val_loss: 0.1007
Epoch 24/100
475/475 [==============================] - 0s 814us/step - loss: 0.0834 - val_loss: 0.0994
Epoch 25/100
475/475 [==============================] - 0s 834us/step - loss: 0.0827 - val_loss: 0.0948
Epoch 26/100
475/475 [==============================] - 0s 842us/step - loss: 0.0825 - val_loss: 0.0990
Epoch 27/100
475/475 [==============================] - 0s 848us/step - loss: 0.0814 - val_loss: 0.0958
Epoch 28/100
475/475 [==============================] - 0s 826us/step - loss: 0.0810 - val_loss: 0.0964
Epoch 29/100
475/475 [==============================] - 0s 852us/step - loss: 0.0822 - val_loss: 0.0956
Epoch 30/100
475/475 [==============================] - 0s 846us/step - loss: 0.0802 - val_loss: 0.1009
Epoch 31/100
475/475 [==============================] - 0s 859us/step - loss: 0.0821 - val_loss: 0.0979
Epoch 32/100
475/475 [==============================] - 0s 834us/step - loss: 0.0811 - val_loss: 0.0976
Epoch 33/100
475/475 [==============================] - 0s 828us/step - loss: 0.0811 - val_loss: 0.0984
Epoch 34/100
475/475 [==============================] - 0s 834us/step - loss: 0.0811 - val_loss: 0.0947
Epoch 35/100
475/475 [==============================] - 0s 840us/step - loss: 0.0798 - val_loss: 0.0979
Epoch 36/100
475/475 [==============================] - 0s 830us/step - loss: 0.0810 - val_loss: 0.0973
Epoch 37/100
475/475 [==============================] - 0s 878us/step - loss: 0.0806 - val_loss: 0.0963
Epoch 38/100
475/475 [==============================] - 0s 863us/step - loss: 0.0798 - val_loss: 0.0992
Epoch 39/100
475/475 [==============================] - 0s 837us/step - loss: 0.0818 - val_loss: 0.0944
Epoch 40/100
475/475 [==============================] - 0s 848us/step - loss: 0.0793 - val_loss: 0.0991
Epoch 41/100
475/475 [==============================] - 0s 848us/step - loss: 0.0800 - val_loss: 0.0962
Epoch 42/100
475/475 [==============================] - 0s 825us/step - loss: 0.0799 - val_loss: 0.0968
Epoch 43/100
475/475 [==============================] - 0s 839us/step - loss: 0.0791 - val_loss: 0.0973
Epoch 44/100
475/475 [==============================] - 0s 832us/step - loss: 0.0798 - val_loss: 0.0968
Epoch 45/100
475/475 [==============================] - 0s 845us/step - loss: 0.0797 - val_loss: 0.0945
Epoch 46/100
475/475 [==============================] - 0s 841us/step - loss: 0.0800 - val_loss: 0.0948
Epoch 47/100
475/475 [==============================] - 0s 847us/step - loss: 0.0794 - val_loss: 0.0952
Epoch 48/100
475/475 [==============================] - 0s 805us/step - loss: 0.0795 - val_loss: 0.0964
Epoch 49/100
475/475 [==============================] - 0s 834us/step - loss: 0.0784 - val_loss: 0.0988
Epoch 50/100
475/475 [==============================] - 0s 843us/step - loss: 0.0808 - val_loss: 0.0991
Epoch 51/100
475/475 [==============================] - 0s 834us/step - loss: 0.0788 - val_loss: 0.0956
Epoch 52/100
475/475 [==============================] - 0s 844us/step - loss: 0.0805 - val_loss: 0.0969
Epoch 53/100
475/475 [==============================] - 0s 837us/step - loss: 0.0796 - val_loss: 0.0974
Epoch 54/100
475/475 [==============================] - 0s 844us/step - loss: 0.0776 - val_loss: 0.0967
Epoch 55/100
475/475 [==============================] - 0s 858us/step - loss: 0.0778 - val_loss: 0.0991
Epoch 56/100
475/475 [==============================] - 0s 840us/step - loss: 0.0795 - val_loss: 0.1005
Epoch 57/100
475/475 [==============================] - 0s 851us/step - loss: 0.0790 - val_loss: 0.0955
Epoch 58/100
475/475 [==============================] - 0s 833us/step - loss: 0.0796 - val_loss: 0.0952
Epoch 59/100
475/475 [==============================] - 0s 851us/step - loss: 0.0792 - val_loss: 0.0933
Epoch 60/100
475/475 [==============================] - 0s 843us/step - loss: 0.0784 - val_loss: 0.0949
Epoch 61/100
475/475 [==============================] - 0s 836us/step - loss: 0.0787 - val_loss: 0.0953
Epoch 62/100
475/475 [==============================] - 0s 821us/step - loss: 0.0788 - val_loss: 0.0963
Epoch 63/100
475/475 [==============================] - 0s 815us/step - loss: 0.0781 - val_loss: 0.0969
Epoch 64/100
475/475 [==============================] - 0s 807us/step - loss: 0.0794 - val_loss: 0.0976
Epoch 65/100
475/475 [==============================] - 0s 828us/step - loss: 0.0794 - val_loss: 0.0957
Epoch 66/100
475/475 [==============================] - 0s 827us/step - loss: 0.0793 - val_loss: 0.0941
Epoch 67/100
475/475 [==============================] - 0s 818us/step - loss: 0.0789 - val_loss: 0.0941
Epoch 68/100
475/475 [==============================] - 0s 822us/step - loss: 0.0793 - val_loss: 0.0951
Epoch 69/100
475/475 [==============================] - 0s 808us/step - loss: 0.0778 - val_loss: 0.0964
Epoch 70/100
475/475 [==============================] - 0s 844us/step - loss: 0.0795 - val_loss: 0.0951
Epoch 71/100
475/475 [==============================] - 0s 849us/step - loss: 0.0780 - val_loss: 0.0994
Epoch 72/100
475/475 [==============================] - 0s 851us/step - loss: 0.0786 - val_loss: 0.0971
Epoch 73/100
475/475 [==============================] - 0s 849us/step - loss: 0.0798 - val_loss: 0.0984
Epoch 74/100
475/475 [==============================] - 0s 842us/step - loss: 0.0792 - val_loss: 0.0967
Epoch 75/100
475/475 [==============================] - 0s 859us/step - loss: 0.0785 - val_loss: 0.0950
Epoch 76/100
475/475 [==============================] - 0s 836us/step - loss: 0.0778 - val_loss: 0.0973
Epoch 77/100
475/475 [==============================] - 0s 838us/step - loss: 0.0792 - val_loss: 0.1003
Epoch 78/100
475/475 [==============================] - 0s 859us/step - loss: 0.0790 - val_loss: 0.0934
Epoch 79/100
475/475 [==============================] - 0s 843us/step - loss: 0.0784 - val_loss: 0.0990
Epoch 80/100
475/475 [==============================] - 0s 831us/step - loss: 0.0782 - val_loss: 0.0968
Epoch 81/100
475/475 [==============================] - 0s 835us/step - loss: 0.0779 - val_loss: 0.0984
Epoch 82/100
475/475 [==============================] - 0s 948us/step - loss: 0.0784 - val_loss: 0.0977
Epoch 83/100
475/475 [==============================] - 0s 799us/step - loss: 0.0779 - val_loss: 0.0980
Epoch 84/100
475/475 [==============================] - 0s 815us/step - loss: 0.0768 - val_loss: 0.0962
Epoch 85/100
475/475 [==============================] - 0s 820us/step - loss: 0.0779 - val_loss: 0.0947
Epoch 86/100
475/475 [==============================] - 0s 816us/step - loss: 0.0782 - val_loss: 0.1006
Epoch 87/100
475/475 [==============================] - 0s 839us/step - loss: 0.0785 - val_loss: 0.0955
Epoch 88/100
475/475 [==============================] - 0s 839us/step - loss: 0.0776 - val_loss: 0.0965
Epoch 89/100
475/475 [==============================] - 0s 833us/step - loss: 0.0789 - val_loss: 0.0976
Epoch 90/100
475/475 [==============================] - 0s 838us/step - loss: 0.0782 - val_loss: 0.0947
Epoch 91/100
475/475 [==============================] - 0s 839us/step - loss: 0.0766 - val_loss: 0.0955
Epoch 92/100
475/475 [==============================] - 0s 841us/step - loss: 0.0782 - val_loss: 0.0968
Epoch 93/100
475/475 [==============================] - 0s 840us/step - loss: 0.0789 - val_loss: 0.0957
Epoch 94/100
475/475 [==============================] - 0s 815us/step - loss: 0.0766 - val_loss: 0.0959
Epoch 95/100
475/475 [==============================] - 0s 838us/step - loss: 0.0772 - val_loss: 0.0951
Epoch 96/100
475/475 [==============================] - 0s 835us/step - loss: 0.0773 - val_loss: 0.0946
Epoch 97/100
475/475 [==============================] - 0s 826us/step - loss: 0.0771 - val_loss: 0.0941
Epoch 98/100
475/475 [==============================] - 0s 858us/step - loss: 0.0773 - val_loss: 0.0941
Epoch 99/100
475/475 [==============================] - 0s 842us/step - loss: 0.0768 - val_loss: 0.0950
Epoch 100/100
475/475 [==============================] - 0s 850us/step - loss: 0.0780 - val_loss: 0.0972

In [28]: history
Out[28]: <tensorflow.python.keras.callbacks.History at 0x1a9a55790>

In [29]: help(history)


In [30]: print(history.params)
{'verbose': 1, 'epochs': 100, 'steps': 475}

In [31]: help(history)


In [32]: history.history
Out[32]: 
{'loss': [0.10699568688869476,
  0.06620673090219498,
  0.05682859197258949,
  0.05159791558980942,
  0.04770505800843239,
  0.04486750811338425,
  0.04242954030632973,
  0.0405547097325325,
  0.03883722797036171,
  0.03737886622548103,
  0.03591874614357948,
  0.03475451469421387,
  0.0336000882089138,
  0.03288594260811806,
  0.03195684030652046,
  0.03097050078213215,
  0.03047294355928898,
  0.02974659763276577,
  0.02956276945769787,
  0.028544453904032707,
  0.0279384758323431,
  0.0273146815598011,
  0.026891222223639488,
  0.02687886357307434,
  0.02605770342051983,
  0.02582302875816822,
  0.02516280859708786,
  0.025080716237425804,
  0.024633554741740227,
  0.024070201441645622,
  0.024122685194015503,
  0.02379762753844261,
  0.023424025624990463,
  0.022979972884058952,
  0.02280677668750286,
  0.022665483877062798,
  0.02218874916434288,
  0.022186802700161934,
  0.021762024611234665,
  0.02152121439576149,
  0.02165350317955017,
  0.02136421389877796,
  0.020861269906163216,
  0.020906701683998108,
  0.020605014637112617,
  0.02066492848098278,
  0.020501187071204185,
  0.020060177892446518,
  0.01994345337152481,
  0.019794750958681107,
  0.01961447112262249,
  0.01953997276723385,
  0.019346294924616814,
  0.01941443607211113,
  0.019095055758953094,
  0.01890331506729126,
  0.018652163445949554,
  0.018685415387153625,
  0.018324390053749084,
  0.01852923259139061,
  0.018480151891708374,
  0.018288707360625267,
  0.018226124346256256,
  0.018034927546977997,
  0.01789768412709236,
  0.01796683669090271,
  0.017696725204586983,
  0.017914138734340668,
  0.017593996599316597,
  0.017447281628847122,
  0.01756208762526512,
  0.01708603836596012,
  0.01706286333501339,
  0.017208989709615707,
  0.016783498227596283,
  0.01691344939172268,
  0.01654723472893238,
  0.01660296320915222,
  0.016525523737072945,
  0.016666147857904434,
  0.016502423211932182,
  0.016409456729888916,
  0.016503416001796722,
  0.016236232593655586,
  0.016102422028779984,
  0.01569201983511448,
  0.015955738723278046,
  0.01596146821975708,
  0.015653179958462715,
  0.015733396634459496,
  0.015645485371351242,
  0.015444883145391941,
  0.015590216033160686,
  0.01564362645149231,
  0.015384265221655369,
  0.015172523446381092,
  0.015161328949034214,
  0.015365757048130035,
  0.015169288031756878,
  0.015107621438801289],
 'val_loss': [0.09500259160995483,
  0.0870155319571495,
  0.08456751704216003,
  0.08051605522632599,
  0.07794447243213654,
  0.07885900139808655,
  0.07663818448781967,
  0.07495993375778198,
  0.07716146856546402,
  0.07533272355794907,
  0.07464411109685898,
  0.07374139130115509,
  0.07514054328203201,
  0.07364784181118011,
  0.07329468429088593,
  0.07331827282905579,
  0.07285545766353607,
  0.07465186715126038,
  0.07364822179079056,
  0.07494078576564789,
  0.07341480255126953,
  0.07402360439300537,
  0.07336033880710602,
  0.07411325722932816,
  0.07392993569374084,
  0.07241704314947128,
  0.07354804128408432,
  0.0738828033208847,
  0.07337520271539688,
  0.07397504895925522,
  0.07489354908466339,
  0.07494162768125534,
  0.07520978897809982,
  0.07572513073682785,
  0.07533878833055496,
  0.07447893917560577,
  0.07585661858320236,
  0.0749301165342331,
  0.07565061002969742,
  0.07578872889280319,
  0.0761357992887497,
  0.07551281899213791,
  0.07488537579774857,
  0.07494078576564789,
  0.07611174136400223,
  0.07591556757688522,
  0.07409396022558212,
  0.07652116566896439,
  0.07485547661781311,
  0.07510039955377579,
  0.07593651115894318,
  0.07548005878925323,
  0.07552890479564667,
  0.07656579464673996,
  0.0764240249991417,
  0.0754319429397583,
  0.07636585086584091,
  0.07698321342468262,
  0.07641496509313583,
  0.07593514770269394,
  0.07646499574184418,
  0.07675047963857651,
  0.07717974483966827,
  0.07928580790758133,
  0.07694932818412781,
  0.07668904960155487,
  0.07679775357246399,
  0.0765790268778801,
  0.07764769345521927,
  0.07707356661558151,
  0.0778181403875351,
  0.07703602313995361,
  0.07730051875114441,
  0.07733925431966782,
  0.0785217136144638,
  0.07692138105630875,
  0.07768696546554565,
  0.07705066353082657,
  0.07732508331537247,
  0.07722599059343338,
  0.07780466973781586,
  0.07747390121221542,
  0.0784987285733223,
  0.07763722538948059,
  0.07705170661211014,
  0.07768159359693527,
  0.07716654986143112,
  0.07779453694820404,
  0.07819053530693054,
  0.07731606066226959,
  0.07820587605237961,
  0.07919900864362717,
  0.07710833847522736,
  0.07766086608171463,
  0.07829193770885468,
  0.0772537887096405,
  0.07797655463218689,
  0.07870274037122726,
  0.07752036303281784,
  0.07855192571878433]}

In [33]: l2_model_1 = keras.Sequential([
    ...:       layers.Dense(128, activation='relu', input_shape = (571,),kernel_regularizer=regularizers.l2(0.01)),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [34]: l2_model_1.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [35]: l2_1_history = l2_model_1.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 991us/step - loss: 0.7205 - val_loss: 0.1330
Epoch 2/100
475/475 [==============================] - 0s 815us/step - loss: 0.1183 - val_loss: 0.1134
Epoch 3/100
475/475 [==============================] - 0s 800us/step - loss: 0.1084 - val_loss: 0.1091
Epoch 4/100
475/475 [==============================] - 0s 836us/step - loss: 0.1028 - val_loss: 0.1112
Epoch 5/100
475/475 [==============================] - 0s 829us/step - loss: 0.0997 - val_loss: 0.1071
Epoch 6/100
475/475 [==============================] - 0s 818us/step - loss: 0.0997 - val_loss: 0.1082
Epoch 7/100
475/475 [==============================] - 0s 839us/step - loss: 0.0963 - val_loss: 0.1059
Epoch 8/100
475/475 [==============================] - 0s 839us/step - loss: 0.0947 - val_loss: 0.1038
Epoch 9/100
475/475 [==============================] - 0s 840us/step - loss: 0.0924 - val_loss: 0.0994
Epoch 10/100
475/475 [==============================] - 0s 839us/step - loss: 0.0914 - val_loss: 0.1036
Epoch 11/100
475/475 [==============================] - 0s 842us/step - loss: 0.0915 - val_loss: 0.1019
Epoch 12/100
475/475 [==============================] - 0s 837us/step - loss: 0.0903 - val_loss: 0.1011
Epoch 13/100
475/475 [==============================] - 0s 845us/step - loss: 0.0882 - val_loss: 0.0982
Epoch 14/100
475/475 [==============================] - 0s 846us/step - loss: 0.0882 - val_loss: 0.1019
Epoch 15/100
475/475 [==============================] - 0s 831us/step - loss: 0.0867 - val_loss: 0.1007
Epoch 16/100
475/475 [==============================] - 0s 834us/step - loss: 0.0877 - val_loss: 0.0992
Epoch 17/100
475/475 [==============================] - 0s 814us/step - loss: 0.0869 - val_loss: 0.0994
Epoch 18/100
475/475 [==============================] - 0s 838us/step - loss: 0.0849 - val_loss: 0.0980
Epoch 19/100
475/475 [==============================] - 0s 826us/step - loss: 0.0848 - val_loss: 0.0980
Epoch 20/100
475/475 [==============================] - 0s 811us/step - loss: 0.0847 - val_loss: 0.0967
Epoch 21/100
475/475 [==============================] - 0s 875us/step - loss: 0.0834 - val_loss: 0.0978
Epoch 22/100
475/475 [==============================] - 0s 843us/step - loss: 0.0843 - val_loss: 0.0949
Epoch 23/100
475/475 [==============================] - 0s 855us/step - loss: 0.0832 - val_loss: 0.0998
Epoch 24/100
475/475 [==============================] - 0s 840us/step - loss: 0.0820 - val_loss: 0.0970
Epoch 25/100
475/475 [==============================] - 0s 839us/step - loss: 0.0818 - val_loss: 0.0984
Epoch 26/100
475/475 [==============================] - 0s 843us/step - loss: 0.0826 - val_loss: 0.1005
Epoch 27/100
475/475 [==============================] - 0s 864us/step - loss: 0.0814 - val_loss: 0.0987
Epoch 28/100
475/475 [==============================] - 0s 809us/step - loss: 0.0823 - val_loss: 0.1024
Epoch 29/100
475/475 [==============================] - 0s 809us/step - loss: 0.0819 - val_loss: 0.0968
Epoch 30/100
475/475 [==============================] - 0s 870us/step - loss: 0.0816 - val_loss: 0.0962
Epoch 31/100
475/475 [==============================] - 0s 840us/step - loss: 0.0816 - val_loss: 0.0976
Epoch 32/100
475/475 [==============================] - 0s 829us/step - loss: 0.0805 - val_loss: 0.0981
Epoch 33/100
475/475 [==============================] - 0s 808us/step - loss: 0.0807 - val_loss: 0.0943
Epoch 34/100
475/475 [==============================] - 0s 815us/step - loss: 0.0806 - val_loss: 0.0974
Epoch 35/100
475/475 [==============================] - 0s 820us/step - loss: 0.0801 - val_loss: 0.0946
Epoch 36/100
475/475 [==============================] - 0s 823us/step - loss: 0.0804 - val_loss: 0.0975
Epoch 37/100
475/475 [==============================] - 0s 828us/step - loss: 0.0804 - val_loss: 0.0956
Epoch 38/100
475/475 [==============================] - 0s 829us/step - loss: 0.0808 - val_loss: 0.0978
Epoch 39/100
475/475 [==============================] - 0s 835us/step - loss: 0.0796 - val_loss: 0.0976
Epoch 40/100
475/475 [==============================] - 0s 831us/step - loss: 0.0796 - val_loss: 0.0946
Epoch 41/100
475/475 [==============================] - 0s 834us/step - loss: 0.0788 - val_loss: 0.0967
Epoch 42/100
475/475 [==============================] - 0s 811us/step - loss: 0.0783 - val_loss: 0.0967
Epoch 43/100
475/475 [==============================] - 0s 832us/step - loss: 0.0804 - val_loss: 0.0943
Epoch 44/100
475/475 [==============================] - 0s 830us/step - loss: 0.0784 - val_loss: 0.0962
Epoch 45/100
475/475 [==============================] - 0s 859us/step - loss: 0.0792 - val_loss: 0.0957
Epoch 46/100
475/475 [==============================] - 0s 818us/step - loss: 0.0791 - val_loss: 0.0941
Epoch 47/100
475/475 [==============================] - 0s 821us/step - loss: 0.0792 - val_loss: 0.0941
Epoch 48/100
475/475 [==============================] - 0s 805us/step - loss: 0.0795 - val_loss: 0.0954
Epoch 49/100
475/475 [==============================] - 0s 814us/step - loss: 0.0791 - val_loss: 0.0986
Epoch 50/100
475/475 [==============================] - 0s 820us/step - loss: 0.0785 - val_loss: 0.0961
Epoch 51/100
475/475 [==============================] - 0s 819us/step - loss: 0.0782 - val_loss: 0.0955
Epoch 52/100
475/475 [==============================] - 0s 836us/step - loss: 0.0779 - val_loss: 0.0945
Epoch 53/100
475/475 [==============================] - 0s 826us/step - loss: 0.0785 - val_loss: 0.0945
Epoch 54/100
475/475 [==============================] - 0s 832us/step - loss: 0.0794 - val_loss: 0.0926
Epoch 55/100
475/475 [==============================] - 0s 835us/step - loss: 0.0781 - val_loss: 0.0942
Epoch 56/100
475/475 [==============================] - 0s 839us/step - loss: 0.0782 - val_loss: 0.0971
Epoch 57/100
475/475 [==============================] - 0s 843us/step - loss: 0.0789 - val_loss: 0.0938
Epoch 58/100
475/475 [==============================] - 0s 859us/step - loss: 0.0785 - val_loss: 0.0955
Epoch 59/100
475/475 [==============================] - 0s 823us/step - loss: 0.0781 - val_loss: 0.0939
Epoch 60/100
475/475 [==============================] - 0s 841us/step - loss: 0.0777 - val_loss: 0.0968
Epoch 61/100
475/475 [==============================] - 0s 840us/step - loss: 0.0780 - val_loss: 0.0964
Epoch 62/100
475/475 [==============================] - 0s 839us/step - loss: 0.0782 - val_loss: 0.0934
Epoch 63/100
475/475 [==============================] - 0s 835us/step - loss: 0.0773 - val_loss: 0.0953
Epoch 64/100
475/475 [==============================] - 0s 830us/step - loss: 0.0791 - val_loss: 0.0924
Epoch 65/100
475/475 [==============================] - 0s 841us/step - loss: 0.0786 - val_loss: 0.0941
Epoch 66/100
475/475 [==============================] - 0s 862us/step - loss: 0.0782 - val_loss: 0.0945
Epoch 67/100
475/475 [==============================] - 0s 865us/step - loss: 0.0787 - val_loss: 0.0944
Epoch 68/100
475/475 [==============================] - 0s 830us/step - loss: 0.0783 - val_loss: 0.0962
Epoch 69/100
475/475 [==============================] - 0s 818us/step - loss: 0.0781 - val_loss: 0.0941
Epoch 70/100
475/475 [==============================] - 0s 893us/step - loss: 0.0781 - val_loss: 0.0929
Epoch 71/100
475/475 [==============================] - 0s 831us/step - loss: 0.0776 - val_loss: 0.0948
Epoch 72/100
475/475 [==============================] - 0s 809us/step - loss: 0.0775 - val_loss: 0.0925
Epoch 73/100
475/475 [==============================] - 0s 832us/step - loss: 0.0772 - val_loss: 0.0940
Epoch 74/100
475/475 [==============================] - 0s 827us/step - loss: 0.0766 - val_loss: 0.0943
Epoch 75/100
475/475 [==============================] - 0s 832us/step - loss: 0.0777 - val_loss: 0.0956
Epoch 76/100
475/475 [==============================] - 0s 815us/step - loss: 0.0779 - val_loss: 0.0977
Epoch 77/100
475/475 [==============================] - 0s 854us/step - loss: 0.0775 - val_loss: 0.0924
Epoch 78/100
475/475 [==============================] - 0s 841us/step - loss: 0.0773 - val_loss: 0.0927
Epoch 79/100
475/475 [==============================] - 0s 840us/step - loss: 0.0778 - val_loss: 0.0937
Epoch 80/100
475/475 [==============================] - 0s 823us/step - loss: 0.0774 - val_loss: 0.0946
Epoch 81/100
475/475 [==============================] - 0s 806us/step - loss: 0.0780 - val_loss: 0.0937
Epoch 82/100
475/475 [==============================] - 0s 814us/step - loss: 0.0778 - val_loss: 0.0946
Epoch 83/100
475/475 [==============================] - 0s 831us/step - loss: 0.0761 - val_loss: 0.0987
Epoch 84/100
475/475 [==============================] - 0s 805us/step - loss: 0.0766 - val_loss: 0.0977
Epoch 85/100
475/475 [==============================] - 0s 835us/step - loss: 0.0788 - val_loss: 0.0958
Epoch 86/100
475/475 [==============================] - 0s 837us/step - loss: 0.0766 - val_loss: 0.0969
Epoch 87/100
475/475 [==============================] - 0s 844us/step - loss: 0.0767 - val_loss: 0.0959
Epoch 88/100
475/475 [==============================] - 0s 817us/step - loss: 0.0787 - val_loss: 0.0918
Epoch 89/100
475/475 [==============================] - 0s 839us/step - loss: 0.0767 - val_loss: 0.0923
Epoch 90/100
475/475 [==============================] - 0s 841us/step - loss: 0.0772 - val_loss: 0.0974
Epoch 91/100
475/475 [==============================] - 0s 807us/step - loss: 0.0768 - val_loss: 0.0946
Epoch 92/100
475/475 [==============================] - 0s 847us/step - loss: 0.0786 - val_loss: 0.0929
Epoch 93/100
475/475 [==============================] - 0s 812us/step - loss: 0.0775 - val_loss: 0.0950
Epoch 94/100
475/475 [==============================] - 0s 832us/step - loss: 0.0771 - val_loss: 0.0942
Epoch 95/100
475/475 [==============================] - 0s 816us/step - loss: 0.0773 - val_loss: 0.0939
Epoch 96/100
475/475 [==============================] - 0s 820us/step - loss: 0.0779 - val_loss: 0.0952
Epoch 97/100
475/475 [==============================] - 0s 827us/step - loss: 0.0786 - val_loss: 0.0924
Epoch 98/100
475/475 [==============================] - 0s 822us/step - loss: 0.0767 - val_loss: 0.0933
Epoch 99/100
475/475 [==============================] - 0s 807us/step - loss: 0.0774 - val_loss: 0.0940
Epoch 100/100
475/475 [==============================] - 0s 835us/step - loss: 0.0773 - val_loss: 0.0923

In [36]: l2_model_huge = keras.Sequential([
    ...:       layers.Dense(128, activation='relu', input_shape = (571,),kernel_regularizer=regularizers.l2(100)),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [37]: l2_model_huge.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [38]: l2_huge_history = l2_model_huge.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 1ms/step - loss: 4085.6579 - val_loss: 0.1782
Epoch 2/100
475/475 [==============================] - 0s 904us/step - loss: 0.1808 - val_loss: 0.1785
Epoch 3/100
475/475 [==============================] - 0s 954us/step - loss: 0.1816 - val_loss: 0.1787
Epoch 4/100
475/475 [==============================] - 0s 936us/step - loss: 0.1811 - val_loss: 0.1783
Epoch 5/100
475/475 [==============================] - 0s 880us/step - loss: 0.1824 - val_loss: 0.1805
Epoch 6/100
475/475 [==============================] - 0s 863us/step - loss: 0.1842 - val_loss: 0.1791
Epoch 7/100
475/475 [==============================] - 0s 814us/step - loss: 0.1832 - val_loss: 0.1840
Epoch 8/100
475/475 [==============================] - 0s 824us/step - loss: 0.1826 - val_loss: 0.1797
Epoch 9/100
475/475 [==============================] - 0s 822us/step - loss: 0.1833 - val_loss: 0.1819
Epoch 10/100
475/475 [==============================] - 0s 830us/step - loss: 0.1846 - val_loss: 0.1830
Epoch 11/100
475/475 [==============================] - 0s 828us/step - loss: 0.1827 - val_loss: 0.1828
Epoch 12/100
475/475 [==============================] - 0s 835us/step - loss: 0.1841 - val_loss: 0.1823
Epoch 13/100
475/475 [==============================] - 0s 839us/step - loss: 0.1867 - val_loss: 0.1849
Epoch 14/100
475/475 [==============================] - 0s 831us/step - loss: 0.1877 - val_loss: 0.1856
Epoch 15/100
475/475 [==============================] - 0s 838us/step - loss: 0.1877 - val_loss: 0.1857
Epoch 16/100
475/475 [==============================] - 0s 860us/step - loss: 0.1865 - val_loss: 0.1849
Epoch 17/100
475/475 [==============================] - 0s 829us/step - loss: 0.1900 - val_loss: 0.1903
Epoch 18/100
475/475 [==============================] - 0s 839us/step - loss: 0.1883 - val_loss: 0.1889
Epoch 19/100
475/475 [==============================] - 0s 832us/step - loss: 0.1902 - val_loss: 0.1868
Epoch 20/100
475/475 [==============================] - 0s 841us/step - loss: 0.1915 - val_loss: 0.1867
Epoch 21/100
475/475 [==============================] - 0s 837us/step - loss: 0.1915 - val_loss: 0.1893
Epoch 22/100
475/475 [==============================] - 0s 841us/step - loss: 0.1929 - val_loss: 0.1909
Epoch 23/100
475/475 [==============================] - 0s 842us/step - loss: 0.1943 - val_loss: 0.1891
Epoch 24/100
475/475 [==============================] - 0s 839us/step - loss: 0.1922 - val_loss: 0.1894
Epoch 25/100
475/475 [==============================] - 0s 848us/step - loss: 0.1919 - val_loss: 0.1904
Epoch 26/100
475/475 [==============================] - 0s 830us/step - loss: 0.1931 - val_loss: 0.1922
Epoch 27/100
475/475 [==============================] - 0s 840us/step - loss: 0.1950 - val_loss: 0.1882
Epoch 28/100
475/475 [==============================] - 0s 834us/step - loss: 0.1928 - val_loss: 0.1889
Epoch 29/100
475/475 [==============================] - 0s 833us/step - loss: 0.1918 - val_loss: 0.1942
Epoch 30/100
475/475 [==============================] - 0s 846us/step - loss: 0.1943 - val_loss: 0.1907
Epoch 31/100
475/475 [==============================] - 0s 838us/step - loss: 0.1942 - val_loss: 0.1919
Epoch 32/100
475/475 [==============================] - 0s 821us/step - loss: 0.1948 - val_loss: 0.1922
Epoch 33/100
475/475 [==============================] - 0s 846us/step - loss: 0.1926 - val_loss: 0.1909
Epoch 34/100
475/475 [==============================] - 0s 818us/step - loss: 0.1940 - val_loss: 0.1973
Epoch 35/100
475/475 [==============================] - 0s 847us/step - loss: 0.1965 - val_loss: 0.1894
Epoch 36/100
475/475 [==============================] - 0s 815us/step - loss: 0.1961 - val_loss: 0.1906
Epoch 37/100
475/475 [==============================] - 0s 845us/step - loss: 0.1942 - val_loss: 0.1919
Epoch 38/100
475/475 [==============================] - 0s 837us/step - loss: 0.1961 - val_loss: 0.1926
Epoch 39/100
475/475 [==============================] - 0s 842us/step - loss: 0.1940 - val_loss: 0.1937
Epoch 40/100
475/475 [==============================] - 0s 829us/step - loss: 0.1938 - val_loss: 0.1912
Epoch 41/100
475/475 [==============================] - 0s 846us/step - loss: 0.1955 - val_loss: 0.1930
Epoch 42/100
475/475 [==============================] - 0s 852us/step - loss: 0.1965 - val_loss: 0.1940
Epoch 43/100
475/475 [==============================] - 0s 845us/step - loss: 0.1954 - val_loss: 0.1906
Epoch 44/100
475/475 [==============================] - 0s 909us/step - loss: 0.1945 - val_loss: 0.1962
Epoch 45/100
475/475 [==============================] - 0s 887us/step - loss: 0.1957 - val_loss: 0.1933
Epoch 46/100
475/475 [==============================] - 0s 949us/step - loss: 0.1973 - val_loss: 0.1958
Epoch 47/100
475/475 [==============================] - 0s 941us/step - loss: 0.1963 - val_loss: 0.1929
Epoch 48/100
475/475 [==============================] - 0s 821us/step - loss: 0.1953 - val_loss: 0.2063
Epoch 49/100
475/475 [==============================] - 0s 811us/step - loss: 0.1966 - val_loss: 0.1937
Epoch 50/100
475/475 [==============================] - 0s 813us/step - loss: 0.1961 - val_loss: 0.1974
Epoch 51/100
475/475 [==============================] - 0s 820us/step - loss: 0.1953 - val_loss: 0.1914
Epoch 52/100
475/475 [==============================] - 0s 829us/step - loss: 0.1975 - val_loss: 0.1947
Epoch 53/100
475/475 [==============================] - 0s 826us/step - loss: 0.1975 - val_loss: 0.1922
Epoch 54/100
475/475 [==============================] - 0s 851us/step - loss: 0.1947 - val_loss: 0.1959
Epoch 55/100
475/475 [==============================] - 0s 923us/step - loss: 0.1977 - val_loss: 0.2038
Epoch 56/100
475/475 [==============================] - 0s 864us/step - loss: 0.1982 - val_loss: 0.1932
Epoch 57/100
475/475 [==============================] - 0s 877us/step - loss: 0.1966 - val_loss: 0.1970
Epoch 58/100
475/475 [==============================] - 0s 981us/step - loss: 0.1961 - val_loss: 0.1957
Epoch 59/100
475/475 [==============================] - 0s 829us/step - loss: 0.1985 - val_loss: 0.1935
Epoch 60/100
475/475 [==============================] - 0s 803us/step - loss: 0.1974 - val_loss: 0.1925
Epoch 61/100
475/475 [==============================] - 0s 813us/step - loss: 0.1991 - val_loss: 0.1949
Epoch 62/100
475/475 [==============================] - 0s 815us/step - loss: 0.1999 - val_loss: 0.1962
Epoch 63/100
475/475 [==============================] - 0s 897us/step - loss: 0.1983 - val_loss: 0.1967
Epoch 64/100
475/475 [==============================] - 0s 829us/step - loss: 0.1999 - val_loss: 0.1997
Epoch 65/100
475/475 [==============================] - 0s 816us/step - loss: 0.1994 - val_loss: 0.1965
Epoch 66/100
475/475 [==============================] - 0s 883us/step - loss: 0.1992 - val_loss: 0.1977
Epoch 67/100
475/475 [==============================] - 0s 994us/step - loss: 0.1978 - val_loss: 0.1969
Epoch 68/100
475/475 [==============================] - 0s 873us/step - loss: 0.2000 - val_loss: 0.1977
Epoch 69/100
475/475 [==============================] - 0s 891us/step - loss: 0.1998 - val_loss: 0.1950
Epoch 70/100
475/475 [==============================] - 0s 855us/step - loss: 0.2009 - val_loss: 0.1983
Epoch 71/100
475/475 [==============================] - 0s 833us/step - loss: 0.2013 - val_loss: 0.1980
Epoch 72/100
475/475 [==============================] - 0s 834us/step - loss: 0.2018 - val_loss: 0.2024
Epoch 73/100
475/475 [==============================] - 0s 929us/step - loss: 0.2020 - val_loss: 0.2016
Epoch 74/100
475/475 [==============================] - 0s 849us/step - loss: 0.2041 - val_loss: 0.2021
Epoch 75/100
475/475 [==============================] - 0s 831us/step - loss: 0.2030 - val_loss: 0.1998
Epoch 76/100
475/475 [==============================] - 0s 836us/step - loss: 0.2025 - val_loss: 0.2026
Epoch 77/100
475/475 [==============================] - 0s 858us/step - loss: 0.2043 - val_loss: 0.2078
Epoch 78/100
475/475 [==============================] - 0s 818us/step - loss: 0.2031 - val_loss: 0.2056
Epoch 79/100
475/475 [==============================] - 0s 824us/step - loss: 0.2025 - val_loss: 0.1999
Epoch 80/100
475/475 [==============================] - 0s 826us/step - loss: 0.2053 - val_loss: 0.1975
Epoch 81/100
475/475 [==============================] - 0s 853us/step - loss: 0.2042 - val_loss: 0.2062
Epoch 82/100
475/475 [==============================] - 0s 875us/step - loss: 0.2053 - val_loss: 0.2052
Epoch 83/100
475/475 [==============================] - 0s 885us/step - loss: 0.2061 - val_loss: 0.2069
Epoch 84/100
475/475 [==============================] - 0s 944us/step - loss: 0.2065 - val_loss: 0.2040
Epoch 85/100
475/475 [==============================] - 0s 938us/step - loss: 0.2078 - val_loss: 0.2017
Epoch 86/100
475/475 [==============================] - 0s 914us/step - loss: 0.2079 - val_loss: 0.2172
Epoch 87/100
475/475 [==============================] - 0s 847us/step - loss: 0.2070 - val_loss: 0.2100
Epoch 88/100
475/475 [==============================] - 0s 863us/step - loss: 0.2106 - val_loss: 0.2052
Epoch 89/100
475/475 [==============================] - 0s 854us/step - loss: 0.2086 - val_loss: 0.2146
Epoch 90/100
475/475 [==============================] - 0s 867us/step - loss: 0.2106 - val_loss: 0.2113
Epoch 91/100
475/475 [==============================] - 0s 823us/step - loss: 0.2092 - val_loss: 0.2025
Epoch 92/100
475/475 [==============================] - 0s 842us/step - loss: 0.2113 - val_loss: 0.2068
Epoch 93/100
475/475 [==============================] - 0s 858us/step - loss: 0.2120 - val_loss: 0.2179
Epoch 94/100
475/475 [==============================] - 0s 837us/step - loss: 0.2126 - val_loss: 0.2121
Epoch 95/100
475/475 [==============================] - 0s 839us/step - loss: 0.2098 - val_loss: 0.2116
Epoch 96/100
475/475 [==============================] - 0s 848us/step - loss: 0.2120 - val_loss: 0.2150
Epoch 97/100
475/475 [==============================] - 0s 835us/step - loss: 0.2126 - val_loss: 0.2100
Epoch 98/100
475/475 [==============================] - 0s 823us/step - loss: 0.2121 - val_loss: 0.2036
Epoch 99/100
475/475 [==============================] - 0s 848us/step - loss: 0.2106 - val_loss: 0.2204
Epoch 100/100
475/475 [==============================] - 0s 843us/step - loss: 0.2126 - val_loss: 0.2101

In [39]: l2_model_0001 = keras.Sequential([
    ...:       layers.Dense(128, activation='relu', input_shape = (571,),kernel_regularizer=regularizers.l2(0.0001)),
    ...: 
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [40]: l2_model_0001.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [41]: l2_0001_history = l2_model_0001.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 970us/step - loss: 0.1769 - val_loss: 0.1001
Epoch 2/100
475/475 [==============================] - 0s 872us/step - loss: 0.0766 - val_loss: 0.0956
Epoch 3/100
475/475 [==============================] - 0s 862us/step - loss: 0.0676 - val_loss: 0.0925
Epoch 4/100
475/475 [==============================] - 0s 837us/step - loss: 0.0616 - val_loss: 0.0921
Epoch 5/100
475/475 [==============================] - 0s 840us/step - loss: 0.0575 - val_loss: 0.0893
Epoch 6/100
475/475 [==============================] - 0s 848us/step - loss: 0.0560 - val_loss: 0.0869
Epoch 7/100
475/475 [==============================] - 0s 848us/step - loss: 0.0533 - val_loss: 0.0873
Epoch 8/100
475/475 [==============================] - 0s 848us/step - loss: 0.0524 - val_loss: 0.0872
Epoch 9/100
475/475 [==============================] - 0s 846us/step - loss: 0.0516 - val_loss: 0.0881
Epoch 10/100
475/475 [==============================] - 0s 850us/step - loss: 0.0506 - val_loss: 0.0866
Epoch 11/100
475/475 [==============================] - 0s 857us/step - loss: 0.0501 - val_loss: 0.0849
Epoch 12/100
475/475 [==============================] - 0s 837us/step - loss: 0.0483 - val_loss: 0.0857
Epoch 13/100
475/475 [==============================] - 0s 832us/step - loss: 0.0486 - val_loss: 0.0858
Epoch 14/100
475/475 [==============================] - 0s 841us/step - loss: 0.0482 - val_loss: 0.0844
Epoch 15/100
475/475 [==============================] - 0s 834us/step - loss: 0.0469 - val_loss: 0.0850
Epoch 16/100
475/475 [==============================] - 0s 837us/step - loss: 0.0463 - val_loss: 0.0864
Epoch 17/100
475/475 [==============================] - 0s 841us/step - loss: 0.0462 - val_loss: 0.0845
Epoch 18/100
475/475 [==============================] - 0s 831us/step - loss: 0.0456 - val_loss: 0.0835
Epoch 19/100
475/475 [==============================] - 0s 842us/step - loss: 0.0457 - val_loss: 0.0876
Epoch 20/100
475/475 [==============================] - 0s 871us/step - loss: 0.0453 - val_loss: 0.0849
Epoch 21/100
475/475 [==============================] - 0s 829us/step - loss: 0.0442 - val_loss: 0.0858
Epoch 22/100
475/475 [==============================] - 0s 815us/step - loss: 0.0439 - val_loss: 0.0850
Epoch 23/100
475/475 [==============================] - 0s 850us/step - loss: 0.0435 - val_loss: 0.0847
Epoch 24/100
475/475 [==============================] - 0s 840us/step - loss: 0.0432 - val_loss: 0.0855
Epoch 25/100
475/475 [==============================] - 0s 835us/step - loss: 0.0432 - val_loss: 0.0859
Epoch 26/100
475/475 [==============================] - 0s 836us/step - loss: 0.0430 - val_loss: 0.0847
Epoch 27/100
475/475 [==============================] - 0s 846us/step - loss: 0.0423 - val_loss: 0.0864
Epoch 28/100
475/475 [==============================] - 0s 846us/step - loss: 0.0425 - val_loss: 0.0858
Epoch 29/100
475/475 [==============================] - 0s 838us/step - loss: 0.0423 - val_loss: 0.0833
Epoch 30/100
475/475 [==============================] - 0s 839us/step - loss: 0.0421 - val_loss: 0.0873
Epoch 31/100
475/475 [==============================] - 0s 842us/step - loss: 0.0421 - val_loss: 0.0852
Epoch 32/100
475/475 [==============================] - 0s 851us/step - loss: 0.0418 - val_loss: 0.0852
Epoch 33/100
475/475 [==============================] - 0s 835us/step - loss: 0.0421 - val_loss: 0.0860
Epoch 34/100
475/475 [==============================] - 0s 841us/step - loss: 0.0412 - val_loss: 0.0856
Epoch 35/100
475/475 [==============================] - 0s 823us/step - loss: 0.0411 - val_loss: 0.0850
Epoch 36/100
475/475 [==============================] - 0s 828us/step - loss: 0.0410 - val_loss: 0.0848
Epoch 37/100
475/475 [==============================] - 0s 839us/step - loss: 0.0412 - val_loss: 0.0839
Epoch 38/100
475/475 [==============================] - 0s 848us/step - loss: 0.0409 - val_loss: 0.0864
Epoch 39/100
475/475 [==============================] - 0s 984us/step - loss: 0.0411 - val_loss: 0.0861
Epoch 40/100
475/475 [==============================] - 0s 802us/step - loss: 0.0408 - val_loss: 0.0849
Epoch 41/100
475/475 [==============================] - 0s 842us/step - loss: 0.0408 - val_loss: 0.0858
Epoch 42/100
475/475 [==============================] - 0s 820us/step - loss: 0.0407 - val_loss: 0.0849
Epoch 43/100
475/475 [==============================] - 0s 822us/step - loss: 0.0409 - val_loss: 0.0835
Epoch 44/100
475/475 [==============================] - 0s 829us/step - loss: 0.0402 - val_loss: 0.0844
Epoch 45/100
475/475 [==============================] - 0s 834us/step - loss: 0.0398 - val_loss: 0.0853
Epoch 46/100
475/475 [==============================] - 0s 837us/step - loss: 0.0401 - val_loss: 0.0841
Epoch 47/100
475/475 [==============================] - 0s 838us/step - loss: 0.0400 - val_loss: 0.0838
Epoch 48/100
475/475 [==============================] - 0s 839us/step - loss: 0.0401 - val_loss: 0.0844
Epoch 49/100
475/475 [==============================] - 0s 862us/step - loss: 0.0403 - val_loss: 0.0836
Epoch 50/100
475/475 [==============================] - 0s 834us/step - loss: 0.0395 - val_loss: 0.0832
Epoch 51/100
475/475 [==============================] - 0s 838us/step - loss: 0.0394 - val_loss: 0.0851
Epoch 52/100
475/475 [==============================] - 0s 839us/step - loss: 0.0398 - val_loss: 0.0864
Epoch 53/100
475/475 [==============================] - 0s 838us/step - loss: 0.0393 - val_loss: 0.0840
Epoch 54/100
475/475 [==============================] - 0s 838us/step - loss: 0.0391 - val_loss: 0.0837
Epoch 55/100
475/475 [==============================] - 0s 847us/step - loss: 0.0393 - val_loss: 0.0839
Epoch 56/100
475/475 [==============================] - 0s 841us/step - loss: 0.0393 - val_loss: 0.0837
Epoch 57/100
475/475 [==============================] - 0s 825us/step - loss: 0.0387 - val_loss: 0.0858
Epoch 58/100
475/475 [==============================] - 0s 824us/step - loss: 0.0393 - val_loss: 0.0851
Epoch 59/100
475/475 [==============================] - 0s 865us/step - loss: 0.0389 - val_loss: 0.0835
Epoch 60/100
475/475 [==============================] - 0s 840us/step - loss: 0.0385 - val_loss: 0.0843
Epoch 61/100
475/475 [==============================] - 0s 836us/step - loss: 0.0389 - val_loss: 0.0836
Epoch 62/100
475/475 [==============================] - 0s 839us/step - loss: 0.0390 - val_loss: 0.0828
Epoch 63/100
475/475 [==============================] - 0s 842us/step - loss: 0.0386 - val_loss: 0.0848
Epoch 64/100
475/475 [==============================] - 0s 842us/step - loss: 0.0383 - val_loss: 0.0836
Epoch 65/100
475/475 [==============================] - 0s 848us/step - loss: 0.0389 - val_loss: 0.0836
Epoch 66/100
475/475 [==============================] - 0s 851us/step - loss: 0.0385 - val_loss: 0.0843
Epoch 67/100
475/475 [==============================] - 0s 834us/step - loss: 0.0382 - val_loss: 0.0844
Epoch 68/100
475/475 [==============================] - 0s 825us/step - loss: 0.0391 - val_loss: 0.0830
Epoch 69/100
475/475 [==============================] - 0s 865us/step - loss: 0.0377 - val_loss: 0.0844
Epoch 70/100
475/475 [==============================] - 0s 836us/step - loss: 0.0383 - val_loss: 0.0835
Epoch 71/100
475/475 [==============================] - 0s 844us/step - loss: 0.0384 - val_loss: 0.0830
Epoch 72/100
475/475 [==============================] - 0s 815us/step - loss: 0.0379 - val_loss: 0.0834
Epoch 73/100
475/475 [==============================] - 0s 847us/step - loss: 0.0375 - val_loss: 0.0827
Epoch 74/100
475/475 [==============================] - 0s 824us/step - loss: 0.0378 - val_loss: 0.0843
Epoch 75/100
475/475 [==============================] - 0s 847us/step - loss: 0.0382 - val_loss: 0.0830
Epoch 76/100
475/475 [==============================] - 0s 843us/step - loss: 0.0378 - val_loss: 0.0839
Epoch 77/100
475/475 [==============================] - 0s 843us/step - loss: 0.0380 - val_loss: 0.0823
Epoch 78/100
475/475 [==============================] - 0s 834us/step - loss: 0.0381 - val_loss: 0.0822
Epoch 79/100
475/475 [==============================] - 0s 841us/step - loss: 0.0381 - val_loss: 0.0835
Epoch 80/100
475/475 [==============================] - 0s 839us/step - loss: 0.0373 - val_loss: 0.0851
Epoch 81/100
475/475 [==============================] - 0s 841us/step - loss: 0.0378 - val_loss: 0.0842
Epoch 82/100
475/475 [==============================] - 0s 854us/step - loss: 0.0376 - val_loss: 0.0835
Epoch 83/100
475/475 [==============================] - 0s 853us/step - loss: 0.0378 - val_loss: 0.0822
Epoch 84/100
475/475 [==============================] - 0s 855us/step - loss: 0.0378 - val_loss: 0.0821
Epoch 85/100
475/475 [==============================] - 0s 930us/step - loss: 0.0377 - val_loss: 0.0828
Epoch 86/100
475/475 [==============================] - 0s 914us/step - loss: 0.0372 - val_loss: 0.0809
Epoch 87/100
475/475 [==============================] - 0s 876us/step - loss: 0.0380 - val_loss: 0.0842
Epoch 88/100
475/475 [==============================] - 0s 853us/step - loss: 0.0379 - val_loss: 0.0818
Epoch 89/100
475/475 [==============================] - 0s 881us/step - loss: 0.0375 - val_loss: 0.0817
Epoch 90/100
475/475 [==============================] - 0s 799us/step - loss: 0.0372 - val_loss: 0.0829
Epoch 91/100
475/475 [==============================] - 0s 915us/step - loss: 0.0370 - val_loss: 0.0849
Epoch 92/100
475/475 [==============================] - 0s 915us/step - loss: 0.0370 - val_loss: 0.0839
Epoch 93/100
475/475 [==============================] - 0s 862us/step - loss: 0.0373 - val_loss: 0.0825
Epoch 94/100
475/475 [==============================] - 0s 894us/step - loss: 0.0377 - val_loss: 0.0808
Epoch 95/100
475/475 [==============================] - 0s 842us/step - loss: 0.0370 - val_loss: 0.0828
Epoch 96/100
475/475 [==============================] - 0s 852us/step - loss: 0.0374 - val_loss: 0.0819
Epoch 97/100
475/475 [==============================] - 0s 885us/step - loss: 0.0375 - val_loss: 0.0820
Epoch 98/100
475/475 [==============================] - 0s 845us/step - loss: 0.0372 - val_loss: 0.0828
Epoch 99/100
475/475 [==============================] - 0s 801us/step - loss: 0.0371 - val_loss: 0.0805
Epoch 100/100
475/475 [==============================] - 0s 926us/step - loss: 0.0368 - val_loss: 0.0835

In [42]: dropout_model = keras.Sequential([
    ...:       layers.Dense(128, activation='relu', input_shape = (571,)),
    ...:       layers.Dropout(0.2),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [43]: dropout_model.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [44]: dropout_history = dropout_model.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 930us/step - loss: 0.1750 - val_loss: 0.0921
Epoch 2/100
475/475 [==============================] - 0s 801us/step - loss: 0.0846 - val_loss: 0.0833
Epoch 3/100
475/475 [==============================] - 0s 827us/step - loss: 0.0715 - val_loss: 0.0798
Epoch 4/100
475/475 [==============================] - 0s 813us/step - loss: 0.0640 - val_loss: 0.0791
Epoch 5/100
475/475 [==============================] - 0s 793us/step - loss: 0.0604 - val_loss: 0.0756
Epoch 6/100
475/475 [==============================] - 0s 791us/step - loss: 0.0567 - val_loss: 0.0768
Epoch 7/100
475/475 [==============================] - 0s 800us/step - loss: 0.0538 - val_loss: 0.0759
Epoch 8/100
475/475 [==============================] - 0s 857us/step - loss: 0.0520 - val_loss: 0.0762
Epoch 9/100
475/475 [==============================] - 0s 821us/step - loss: 0.0509 - val_loss: 0.0737
Epoch 10/100
475/475 [==============================] - 0s 817us/step - loss: 0.0497 - val_loss: 0.0746
Epoch 11/100
475/475 [==============================] - 0s 822us/step - loss: 0.0486 - val_loss: 0.0754
Epoch 12/100
475/475 [==============================] - 0s 822us/step - loss: 0.0479 - val_loss: 0.0746
Epoch 13/100
475/475 [==============================] - 0s 815us/step - loss: 0.0465 - val_loss: 0.0727
Epoch 14/100
475/475 [==============================] - 0s 785us/step - loss: 0.0460 - val_loss: 0.0730
Epoch 15/100
475/475 [==============================] - 0s 801us/step - loss: 0.0447 - val_loss: 0.0736
Epoch 16/100
475/475 [==============================] - 0s 799us/step - loss: 0.0445 - val_loss: 0.0728
Epoch 17/100
475/475 [==============================] - 0s 808us/step - loss: 0.0437 - val_loss: 0.0736
Epoch 18/100
475/475 [==============================] - 0s 818us/step - loss: 0.0439 - val_loss: 0.0725
Epoch 19/100
475/475 [==============================] - 0s 774us/step - loss: 0.0434 - val_loss: 0.0751
Epoch 20/100
475/475 [==============================] - 0s 793us/step - loss: 0.0422 - val_loss: 0.0744
Epoch 21/100
475/475 [==============================] - 0s 817us/step - loss: 0.0425 - val_loss: 0.0731
Epoch 22/100
475/475 [==============================] - 0s 808us/step - loss: 0.0420 - val_loss: 0.0722
Epoch 23/100
475/475 [==============================] - 0s 817us/step - loss: 0.0418 - val_loss: 0.0727
Epoch 24/100
475/475 [==============================] - 0s 796us/step - loss: 0.0415 - val_loss: 0.0727
Epoch 25/100
475/475 [==============================] - 0s 787us/step - loss: 0.0406 - val_loss: 0.0731
Epoch 26/100
475/475 [==============================] - 0s 813us/step - loss: 0.0407 - val_loss: 0.0724
Epoch 27/100
475/475 [==============================] - 0s 810us/step - loss: 0.0407 - val_loss: 0.0731
Epoch 28/100
475/475 [==============================] - 0s 816us/step - loss: 0.0400 - val_loss: 0.0751
Epoch 29/100
475/475 [==============================] - 0s 810us/step - loss: 0.0398 - val_loss: 0.0746
Epoch 30/100
475/475 [==============================] - 0s 839us/step - loss: 0.0399 - val_loss: 0.0736
Epoch 31/100
475/475 [==============================] - 0s 840us/step - loss: 0.0394 - val_loss: 0.0725
Epoch 32/100
475/475 [==============================] - 0s 826us/step - loss: 0.0388 - val_loss: 0.0738
Epoch 33/100
475/475 [==============================] - 0s 836us/step - loss: 0.0389 - val_loss: 0.0728
Epoch 34/100
475/475 [==============================] - 0s 856us/step - loss: 0.0384 - val_loss: 0.0739
Epoch 35/100
475/475 [==============================] - 0s 826us/step - loss: 0.0381 - val_loss: 0.0733
Epoch 36/100
475/475 [==============================] - 0s 857us/step - loss: 0.0391 - val_loss: 0.0733
Epoch 37/100
475/475 [==============================] - 0s 841us/step - loss: 0.0387 - val_loss: 0.0728
Epoch 38/100
475/475 [==============================] - 0s 879us/step - loss: 0.0374 - val_loss: 0.0749
Epoch 39/100
475/475 [==============================] - 0s 841us/step - loss: 0.0378 - val_loss: 0.0744
Epoch 40/100
475/475 [==============================] - 0s 813us/step - loss: 0.0375 - val_loss: 0.0727
Epoch 41/100
475/475 [==============================] - 0s 931us/step - loss: 0.0374 - val_loss: 0.0743
Epoch 42/100
475/475 [==============================] - 0s 910us/step - loss: 0.0372 - val_loss: 0.0719
Epoch 43/100
475/475 [==============================] - 0s 945us/step - loss: 0.0372 - val_loss: 0.0734
Epoch 44/100
475/475 [==============================] - 0s 794us/step - loss: 0.0372 - val_loss: 0.0729
Epoch 45/100
475/475 [==============================] - 0s 817us/step - loss: 0.0368 - val_loss: 0.0735
Epoch 46/100
475/475 [==============================] - 0s 985us/step - loss: 0.0367 - val_loss: 0.0740
Epoch 47/100
475/475 [==============================] - 0s 891us/step - loss: 0.0370 - val_loss: 0.0746
Epoch 48/100
475/475 [==============================] - 0s 896us/step - loss: 0.0378 - val_loss: 0.0746
Epoch 49/100
475/475 [==============================] - 0s 920us/step - loss: 0.0363 - val_loss: 0.0734
Epoch 50/100
475/475 [==============================] - 0s 974us/step - loss: 0.0362 - val_loss: 0.0722
Epoch 51/100
475/475 [==============================] - 0s 894us/step - loss: 0.0363 - val_loss: 0.0741
Epoch 52/100
475/475 [==============================] - 0s 857us/step - loss: 0.0360 - val_loss: 0.0728
Epoch 53/100
475/475 [==============================] - 0s 843us/step - loss: 0.0362 - val_loss: 0.0733
Epoch 54/100
475/475 [==============================] - 0s 849us/step - loss: 0.0359 - val_loss: 0.0729
Epoch 55/100
475/475 [==============================] - 0s 857us/step - loss: 0.0359 - val_loss: 0.0732
Epoch 56/100
475/475 [==============================] - 0s 843us/step - loss: 0.0361 - val_loss: 0.0737
Epoch 57/100
475/475 [==============================] - 0s 810us/step - loss: 0.0362 - val_loss: 0.0726
Epoch 58/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0356 - val_loss: 0.0743
Epoch 59/100
475/475 [==============================] - 0s 852us/step - loss: 0.0347 - val_loss: 0.0732
Epoch 60/100
475/475 [==============================] - 0s 918us/step - loss: 0.0354 - val_loss: 0.0747
Epoch 61/100
475/475 [==============================] - 0s 827us/step - loss: 0.0351 - val_loss: 0.0723
Epoch 62/100
475/475 [==============================] - 0s 788us/step - loss: 0.0356 - val_loss: 0.0718
Epoch 63/100
475/475 [==============================] - 0s 850us/step - loss: 0.0353 - val_loss: 0.0730
Epoch 64/100
475/475 [==============================] - 0s 800us/step - loss: 0.0346 - val_loss: 0.0744
Epoch 65/100
475/475 [==============================] - 0s 787us/step - loss: 0.0353 - val_loss: 0.0732
Epoch 66/100
475/475 [==============================] - 0s 768us/step - loss: 0.0343 - val_loss: 0.0734
Epoch 67/100
475/475 [==============================] - 0s 794us/step - loss: 0.0355 - val_loss: 0.0738
Epoch 68/100
475/475 [==============================] - 0s 810us/step - loss: 0.0341 - val_loss: 0.0740
Epoch 69/100
475/475 [==============================] - 0s 808us/step - loss: 0.0352 - val_loss: 0.0738
Epoch 70/100
475/475 [==============================] - 0s 795us/step - loss: 0.0352 - val_loss: 0.0736
Epoch 71/100
475/475 [==============================] - 0s 872us/step - loss: 0.0347 - val_loss: 0.0735
Epoch 72/100
475/475 [==============================] - 0s 809us/step - loss: 0.0347 - val_loss: 0.0730
Epoch 73/100
475/475 [==============================] - 0s 796us/step - loss: 0.0344 - val_loss: 0.0740
Epoch 74/100
475/475 [==============================] - 0s 784us/step - loss: 0.0342 - val_loss: 0.0727
Epoch 75/100
475/475 [==============================] - 0s 814us/step - loss: 0.0337 - val_loss: 0.0743
Epoch 76/100
475/475 [==============================] - 0s 810us/step - loss: 0.0341 - val_loss: 0.0739
Epoch 77/100
475/475 [==============================] - 0s 790us/step - loss: 0.0340 - val_loss: 0.0735
Epoch 78/100
475/475 [==============================] - 0s 780us/step - loss: 0.0343 - val_loss: 0.0737
Epoch 79/100
475/475 [==============================] - 0s 801us/step - loss: 0.0350 - val_loss: 0.0747
Epoch 80/100
475/475 [==============================] - 0s 813us/step - loss: 0.0344 - val_loss: 0.0727
Epoch 81/100
475/475 [==============================] - 0s 805us/step - loss: 0.0340 - val_loss: 0.0744
Epoch 82/100
475/475 [==============================] - 0s 790us/step - loss: 0.0339 - val_loss: 0.0730
Epoch 83/100
475/475 [==============================] - 0s 824us/step - loss: 0.0341 - val_loss: 0.0739
Epoch 84/100
475/475 [==============================] - 0s 796us/step - loss: 0.0340 - val_loss: 0.0736
Epoch 85/100
475/475 [==============================] - 0s 782us/step - loss: 0.0337 - val_loss: 0.0730
Epoch 86/100
475/475 [==============================] - 0s 797us/step - loss: 0.0339 - val_loss: 0.0735
Epoch 87/100
475/475 [==============================] - 0s 800us/step - loss: 0.0337 - val_loss: 0.0734
Epoch 88/100
475/475 [==============================] - 0s 771us/step - loss: 0.0334 - val_loss: 0.0728
Epoch 89/100
475/475 [==============================] - 0s 821us/step - loss: 0.0341 - val_loss: 0.0737
Epoch 90/100
475/475 [==============================] - 0s 785us/step - loss: 0.0334 - val_loss: 0.0728
Epoch 91/100
475/475 [==============================] - 0s 790us/step - loss: 0.0334 - val_loss: 0.0729
Epoch 92/100
475/475 [==============================] - 0s 788us/step - loss: 0.0337 - val_loss: 0.0732
Epoch 93/100
475/475 [==============================] - 0s 959us/step - loss: 0.0329 - val_loss: 0.0741
Epoch 94/100
475/475 [==============================] - 0s 860us/step - loss: 0.0333 - val_loss: 0.0725
Epoch 95/100
475/475 [==============================] - 0s 835us/step - loss: 0.0332 - val_loss: 0.0725
Epoch 96/100
475/475 [==============================] - 0s 818us/step - loss: 0.0335 - val_loss: 0.0729
Epoch 97/100
475/475 [==============================] - 0s 846us/step - loss: 0.0334 - val_loss: 0.0720
Epoch 98/100
475/475 [==============================] - 0s 823us/step - loss: 0.0334 - val_loss: 0.0733
Epoch 99/100
475/475 [==============================] - 0s 790us/step - loss: 0.0330 - val_loss: 0.0730
Epoch 100/100
475/475 [==============================] - 0s 782us/step - loss: 0.0327 - val_loss: 0.0725

In [45]: more_dropout_model = keras.Sequential([
    ...:       layers.Dense(128, activation='relu', input_shape = (571,)),
    ...:       layers.Dropout(0.5),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [46]: more_dropout_model.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [47]: more_dropout_history = more_dropout_model.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 933us/step - loss: 0.2050 - val_loss: 0.1025
Epoch 2/100
475/475 [==============================] - 0s 800us/step - loss: 0.1046 - val_loss: 0.0878
Epoch 3/100
475/475 [==============================] - 0s 811us/step - loss: 0.0875 - val_loss: 0.0846
Epoch 4/100
475/475 [==============================] - 0s 836us/step - loss: 0.0788 - val_loss: 0.0809
Epoch 5/100
475/475 [==============================] - 0s 815us/step - loss: 0.0741 - val_loss: 0.0816
Epoch 6/100
475/475 [==============================] - 0s 844us/step - loss: 0.0716 - val_loss: 0.0766
Epoch 7/100
475/475 [==============================] - 0s 843us/step - loss: 0.0691 - val_loss: 0.0762
Epoch 8/100
475/475 [==============================] - 0s 822us/step - loss: 0.0650 - val_loss: 0.0753
Epoch 9/100
475/475 [==============================] - 0s 829us/step - loss: 0.0650 - val_loss: 0.0757
Epoch 10/100
475/475 [==============================] - 0s 829us/step - loss: 0.0634 - val_loss: 0.0753
Epoch 11/100
475/475 [==============================] - 0s 827us/step - loss: 0.0630 - val_loss: 0.0740
Epoch 12/100
475/475 [==============================] - 0s 823us/step - loss: 0.0619 - val_loss: 0.0751
Epoch 13/100
475/475 [==============================] - 0s 801us/step - loss: 0.0605 - val_loss: 0.0750
Epoch 14/100
475/475 [==============================] - 0s 802us/step - loss: 0.0607 - val_loss: 0.0754
Epoch 15/100
475/475 [==============================] - 0s 805us/step - loss: 0.0604 - val_loss: 0.0747
Epoch 16/100
475/475 [==============================] - 0s 813us/step - loss: 0.0603 - val_loss: 0.0733
Epoch 17/100
475/475 [==============================] - 0s 822us/step - loss: 0.0593 - val_loss: 0.0748
Epoch 18/100
475/475 [==============================] - 0s 929us/step - loss: 0.0591 - val_loss: 0.0761
Epoch 19/100
475/475 [==============================] - 0s 838us/step - loss: 0.0583 - val_loss: 0.0755
Epoch 20/100
475/475 [==============================] - 0s 800us/step - loss: 0.0577 - val_loss: 0.0742
Epoch 21/100
475/475 [==============================] - 0s 793us/step - loss: 0.0575 - val_loss: 0.0745
Epoch 22/100
475/475 [==============================] - 0s 798us/step - loss: 0.0573 - val_loss: 0.0755
Epoch 23/100
475/475 [==============================] - 0s 807us/step - loss: 0.0575 - val_loss: 0.0751
Epoch 24/100
475/475 [==============================] - 0s 778us/step - loss: 0.0579 - val_loss: 0.0746
Epoch 25/100
475/475 [==============================] - 0s 778us/step - loss: 0.0571 - val_loss: 0.0741
Epoch 26/100
475/475 [==============================] - 0s 774us/step - loss: 0.0562 - val_loss: 0.0750
Epoch 27/100
475/475 [==============================] - 0s 769us/step - loss: 0.0565 - val_loss: 0.0752
Epoch 28/100
475/475 [==============================] - 0s 793us/step - loss: 0.0570 - val_loss: 0.0751
Epoch 29/100
475/475 [==============================] - 0s 789us/step - loss: 0.0562 - val_loss: 0.0758
Epoch 30/100
475/475 [==============================] - 0s 790us/step - loss: 0.0556 - val_loss: 0.0732
Epoch 31/100
475/475 [==============================] - 0s 787us/step - loss: 0.0553 - val_loss: 0.0721
Epoch 32/100
475/475 [==============================] - 0s 809us/step - loss: 0.0552 - val_loss: 0.0741
Epoch 33/100
475/475 [==============================] - 0s 799us/step - loss: 0.0553 - val_loss: 0.0732
Epoch 34/100
475/475 [==============================] - 0s 796us/step - loss: 0.0555 - val_loss: 0.0726
Epoch 35/100
475/475 [==============================] - 0s 789us/step - loss: 0.0553 - val_loss: 0.0735
Epoch 36/100
475/475 [==============================] - 0s 842us/step - loss: 0.0550 - val_loss: 0.0759
Epoch 37/100
475/475 [==============================] - 0s 792us/step - loss: 0.0546 - val_loss: 0.0735
Epoch 38/100
475/475 [==============================] - 0s 793us/step - loss: 0.0542 - val_loss: 0.0722
Epoch 39/100
475/475 [==============================] - 0s 806us/step - loss: 0.0541 - val_loss: 0.0740
Epoch 40/100
475/475 [==============================] - 0s 780us/step - loss: 0.0552 - val_loss: 0.0740
Epoch 41/100
475/475 [==============================] - 0s 779us/step - loss: 0.0530 - val_loss: 0.0753
Epoch 42/100
475/475 [==============================] - 0s 788us/step - loss: 0.0540 - val_loss: 0.0728
Epoch 43/100
475/475 [==============================] - 0s 789us/step - loss: 0.0541 - val_loss: 0.0743
Epoch 44/100
475/475 [==============================] - 0s 776us/step - loss: 0.0542 - val_loss: 0.0732
Epoch 45/100
475/475 [==============================] - 0s 777us/step - loss: 0.0536 - val_loss: 0.0734
Epoch 46/100
475/475 [==============================] - 0s 782us/step - loss: 0.0538 - val_loss: 0.0729
Epoch 47/100
475/475 [==============================] - 0s 809us/step - loss: 0.0534 - val_loss: 0.0740
Epoch 48/100
475/475 [==============================] - 0s 942us/step - loss: 0.0530 - val_loss: 0.0731
Epoch 49/100
475/475 [==============================] - 0s 856us/step - loss: 0.0533 - val_loss: 0.0713
Epoch 50/100
475/475 [==============================] - 0s 803us/step - loss: 0.0529 - val_loss: 0.0741
Epoch 51/100
475/475 [==============================] - 0s 785us/step - loss: 0.0535 - val_loss: 0.0718
Epoch 52/100
475/475 [==============================] - 0s 842us/step - loss: 0.0528 - val_loss: 0.0751
Epoch 53/100
475/475 [==============================] - 0s 830us/step - loss: 0.0520 - val_loss: 0.0736
Epoch 54/100
475/475 [==============================] - 0s 814us/step - loss: 0.0526 - val_loss: 0.0721
Epoch 55/100
475/475 [==============================] - 0s 825us/step - loss: 0.0527 - val_loss: 0.0732
Epoch 56/100
475/475 [==============================] - 0s 861us/step - loss: 0.0519 - val_loss: 0.0743
Epoch 57/100
475/475 [==============================] - 0s 866us/step - loss: 0.0526 - val_loss: 0.0728
Epoch 58/100
475/475 [==============================] - 0s 786us/step - loss: 0.0524 - val_loss: 0.0732
Epoch 59/100
475/475 [==============================] - 0s 795us/step - loss: 0.0523 - val_loss: 0.0757
Epoch 60/100
475/475 [==============================] - 0s 852us/step - loss: 0.0525 - val_loss: 0.0743
Epoch 61/100
475/475 [==============================] - 0s 828us/step - loss: 0.0516 - val_loss: 0.0726
Epoch 62/100
475/475 [==============================] - 0s 826us/step - loss: 0.0510 - val_loss: 0.0740
Epoch 63/100
475/475 [==============================] - 0s 824us/step - loss: 0.0516 - val_loss: 0.0723
Epoch 64/100
475/475 [==============================] - 0s 826us/step - loss: 0.0519 - val_loss: 0.0721
Epoch 65/100
475/475 [==============================] - 0s 803us/step - loss: 0.0511 - val_loss: 0.0749
Epoch 66/100
475/475 [==============================] - 0s 795us/step - loss: 0.0520 - val_loss: 0.0742
Epoch 67/100
475/475 [==============================] - 0s 929us/step - loss: 0.0516 - val_loss: 0.0753
Epoch 68/100
475/475 [==============================] - 0s 898us/step - loss: 0.0521 - val_loss: 0.0758
Epoch 69/100
475/475 [==============================] - 0s 821us/step - loss: 0.0517 - val_loss: 0.0742
Epoch 70/100
475/475 [==============================] - 0s 801us/step - loss: 0.0511 - val_loss: 0.0751
Epoch 71/100
475/475 [==============================] - 0s 867us/step - loss: 0.0504 - val_loss: 0.0727
Epoch 72/100
475/475 [==============================] - 0s 834us/step - loss: 0.0516 - val_loss: 0.0752
Epoch 73/100
475/475 [==============================] - 0s 835us/step - loss: 0.0507 - val_loss: 0.0726
Epoch 74/100
475/475 [==============================] - 0s 797us/step - loss: 0.0510 - val_loss: 0.0744
Epoch 75/100
475/475 [==============================] - 0s 800us/step - loss: 0.0513 - val_loss: 0.0744
Epoch 76/100
475/475 [==============================] - 0s 856us/step - loss: 0.0504 - val_loss: 0.0743
Epoch 77/100
475/475 [==============================] - 0s 842us/step - loss: 0.0517 - val_loss: 0.0739
Epoch 78/100
475/475 [==============================] - 0s 862us/step - loss: 0.0508 - val_loss: 0.0745
Epoch 79/100
475/475 [==============================] - 0s 949us/step - loss: 0.0505 - val_loss: 0.0743
Epoch 80/100
475/475 [==============================] - 0s 870us/step - loss: 0.0496 - val_loss: 0.0737
Epoch 81/100
475/475 [==============================] - 0s 884us/step - loss: 0.0505 - val_loss: 0.0740
Epoch 82/100
475/475 [==============================] - 0s 884us/step - loss: 0.0504 - val_loss: 0.0724
Epoch 83/100
475/475 [==============================] - 0s 795us/step - loss: 0.0513 - val_loss: 0.0731
Epoch 84/100
475/475 [==============================] - 0s 802us/step - loss: 0.0510 - val_loss: 0.0759
Epoch 85/100
475/475 [==============================] - 0s 792us/step - loss: 0.0502 - val_loss: 0.0740
Epoch 86/100
475/475 [==============================] - 0s 802us/step - loss: 0.0507 - val_loss: 0.0725
Epoch 87/100
475/475 [==============================] - 0s 808us/step - loss: 0.0505 - val_loss: 0.0725
Epoch 88/100
475/475 [==============================] - 0s 809us/step - loss: 0.0502 - val_loss: 0.0746
Epoch 89/100
475/475 [==============================] - 0s 812us/step - loss: 0.0508 - val_loss: 0.0752
Epoch 90/100
475/475 [==============================] - 0s 811us/step - loss: 0.0511 - val_loss: 0.0724
Epoch 91/100
475/475 [==============================] - 0s 783us/step - loss: 0.0502 - val_loss: 0.0732
Epoch 92/100
475/475 [==============================] - 0s 821us/step - loss: 0.0494 - val_loss: 0.0734
Epoch 93/100
475/475 [==============================] - 0s 885us/step - loss: 0.0503 - val_loss: 0.0735
Epoch 94/100
475/475 [==============================] - 0s 859us/step - loss: 0.0505 - val_loss: 0.0727
Epoch 95/100
475/475 [==============================] - 0s 846us/step - loss: 0.0496 - val_loss: 0.0724
Epoch 96/100
475/475 [==============================] - 0s 785us/step - loss: 0.0499 - val_loss: 0.0739
Epoch 97/100
475/475 [==============================] - 0s 788us/step - loss: 0.0501 - val_loss: 0.0723
Epoch 98/100
475/475 [==============================] - 0s 843us/step - loss: 0.0490 - val_loss: 0.0726
Epoch 99/100
475/475 [==============================] - 0s 907us/step - loss: 0.0493 - val_loss: 0.0723
Epoch 100/100
475/475 [==============================] - 0s 824us/step - loss: 0.0499 - val_loss: 0.0723

In [48]: bigger_model = keras.Sequential([
    ...:       layers.Dense(128, activation='relu', input_shape = (571,)),
    ...:       layers.Dense(128, activation='relu'),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [49]: bigger_model.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [50]: bigger_history = bigger_model.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 1ms/step - loss: 0.1580 - val_loss: 0.0886
Epoch 2/100
475/475 [==============================] - 0s 915us/step - loss: 0.0640 - val_loss: 0.0832
Epoch 3/100
475/475 [==============================] - 0s 905us/step - loss: 0.0534 - val_loss: 0.0784
Epoch 4/100
475/475 [==============================] - 0s 911us/step - loss: 0.0477 - val_loss: 0.0791
Epoch 5/100
475/475 [==============================] - 0s 897us/step - loss: 0.0440 - val_loss: 0.0800
Epoch 6/100
475/475 [==============================] - 0s 933us/step - loss: 0.0399 - val_loss: 0.0731
Epoch 7/100
475/475 [==============================] - 0s 929us/step - loss: 0.0383 - val_loss: 0.0778
Epoch 8/100
475/475 [==============================] - 0s 907us/step - loss: 0.0368 - val_loss: 0.0731
Epoch 9/100
475/475 [==============================] - 0s 905us/step - loss: 0.0352 - val_loss: 0.0742
Epoch 10/100
475/475 [==============================] - 0s 955us/step - loss: 0.0336 - val_loss: 0.0718
Epoch 11/100
475/475 [==============================] - 0s 902us/step - loss: 0.0327 - val_loss: 0.0716
Epoch 12/100
475/475 [==============================] - 0s 892us/step - loss: 0.0310 - val_loss: 0.0732
Epoch 13/100
475/475 [==============================] - 0s 888us/step - loss: 0.0304 - val_loss: 0.0737
Epoch 14/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0299 - val_loss: 0.0717
Epoch 15/100
475/475 [==============================] - 0s 947us/step - loss: 0.0286 - val_loss: 0.0719
Epoch 16/100
475/475 [==============================] - 0s 907us/step - loss: 0.0277 - val_loss: 0.0731
Epoch 17/100
475/475 [==============================] - 0s 880us/step - loss: 0.0270 - val_loss: 0.0708
Epoch 18/100
475/475 [==============================] - 0s 887us/step - loss: 0.0271 - val_loss: 0.0704
Epoch 19/100
475/475 [==============================] - 0s 909us/step - loss: 0.0257 - val_loss: 0.0722
Epoch 20/100
475/475 [==============================] - 0s 899us/step - loss: 0.0250 - val_loss: 0.0721
Epoch 21/100
475/475 [==============================] - 0s 881us/step - loss: 0.0249 - val_loss: 0.0698
Epoch 22/100
475/475 [==============================] - 0s 904us/step - loss: 0.0247 - val_loss: 0.0703
Epoch 23/100
475/475 [==============================] - 0s 912us/step - loss: 0.0237 - val_loss: 0.0722
Epoch 24/100
475/475 [==============================] - 0s 890us/step - loss: 0.0236 - val_loss: 0.0714
Epoch 25/100
475/475 [==============================] - 0s 887us/step - loss: 0.0227 - val_loss: 0.0698
Epoch 26/100
475/475 [==============================] - 0s 918us/step - loss: 0.0227 - val_loss: 0.0710
Epoch 27/100
475/475 [==============================] - 0s 906us/step - loss: 0.0220 - val_loss: 0.0713
Epoch 28/100
475/475 [==============================] - 0s 908us/step - loss: 0.0217 - val_loss: 0.0701
Epoch 29/100
475/475 [==============================] - 0s 885us/step - loss: 0.0217 - val_loss: 0.0709
Epoch 30/100
475/475 [==============================] - 0s 912us/step - loss: 0.0208 - val_loss: 0.0717
Epoch 31/100
475/475 [==============================] - 0s 908us/step - loss: 0.0205 - val_loss: 0.0701
Epoch 32/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0716
Epoch 33/100
475/475 [==============================] - 0s 960us/step - loss: 0.0197 - val_loss: 0.0699
Epoch 34/100
475/475 [==============================] - 0s 894us/step - loss: 0.0201 - val_loss: 0.0707
Epoch 35/100
475/475 [==============================] - 0s 896us/step - loss: 0.0193 - val_loss: 0.0701
Epoch 36/100
475/475 [==============================] - 0s 978us/step - loss: 0.0196 - val_loss: 0.0705
Epoch 37/100
475/475 [==============================] - 0s 891us/step - loss: 0.0192 - val_loss: 0.0698
Epoch 38/100
475/475 [==============================] - 0s 912us/step - loss: 0.0189 - val_loss: 0.0722
Epoch 39/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0182 - val_loss: 0.0712
Epoch 40/100
475/475 [==============================] - 0s 957us/step - loss: 0.0185 - val_loss: 0.0720
Epoch 41/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0180 - val_loss: 0.0700
Epoch 42/100
475/475 [==============================] - 0s 993us/step - loss: 0.0175 - val_loss: 0.0699
Epoch 43/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0718
Epoch 44/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0172 - val_loss: 0.0708
Epoch 45/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0712
Epoch 46/100
475/475 [==============================] - 0s 901us/step - loss: 0.0174 - val_loss: 0.0715
Epoch 47/100
475/475 [==============================] - 0s 892us/step - loss: 0.0168 - val_loss: 0.0720
Epoch 48/100
475/475 [==============================] - 0s 881us/step - loss: 0.0165 - val_loss: 0.0716
Epoch 49/100
475/475 [==============================] - 0s 910us/step - loss: 0.0168 - val_loss: 0.0709
Epoch 50/100
475/475 [==============================] - 0s 905us/step - loss: 0.0161 - val_loss: 0.0716
Epoch 51/100
475/475 [==============================] - 0s 926us/step - loss: 0.0161 - val_loss: 0.0737
Epoch 52/100
475/475 [==============================] - 0s 898us/step - loss: 0.0165 - val_loss: 0.0711
Epoch 53/100
475/475 [==============================] - 0s 925us/step - loss: 0.0157 - val_loss: 0.0712
Epoch 54/100
475/475 [==============================] - 0s 877us/step - loss: 0.0160 - val_loss: 0.0702
Epoch 55/100
475/475 [==============================] - 0s 890us/step - loss: 0.0154 - val_loss: 0.0717
Epoch 56/100
475/475 [==============================] - 0s 894us/step - loss: 0.0159 - val_loss: 0.0721
Epoch 57/100
475/475 [==============================] - 0s 1000us/step - loss: 0.0151 - val_loss: 0.0717
Epoch 58/100
475/475 [==============================] - 0s 919us/step - loss: 0.0152 - val_loss: 0.0707
Epoch 59/100
475/475 [==============================] - 0s 944us/step - loss: 0.0150 - val_loss: 0.0702
Epoch 60/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.0709
Epoch 61/100
475/475 [==============================] - 0s 960us/step - loss: 0.0147 - val_loss: 0.0711
Epoch 62/100
475/475 [==============================] - 0s 983us/step - loss: 0.0146 - val_loss: 0.0710
Epoch 63/100
475/475 [==============================] - 0s 882us/step - loss: 0.0145 - val_loss: 0.0713
Epoch 64/100
475/475 [==============================] - 0s 890us/step - loss: 0.0140 - val_loss: 0.0709
Epoch 65/100
475/475 [==============================] - 0s 893us/step - loss: 0.0145 - val_loss: 0.0699
Epoch 66/100
475/475 [==============================] - 0s 873us/step - loss: 0.0139 - val_loss: 0.0712
Epoch 67/100
475/475 [==============================] - 0s 979us/step - loss: 0.0137 - val_loss: 0.0711
Epoch 68/100
475/475 [==============================] - 0s 926us/step - loss: 0.0140 - val_loss: 0.0701
Epoch 69/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.0701
Epoch 70/100
475/475 [==============================] - 0s 918us/step - loss: 0.0139 - val_loss: 0.0699
Epoch 71/100
475/475 [==============================] - 0s 919us/step - loss: 0.0136 - val_loss: 0.0715
Epoch 72/100
475/475 [==============================] - 0s 932us/step - loss: 0.0134 - val_loss: 0.0717
Epoch 73/100
475/475 [==============================] - 0s 926us/step - loss: 0.0137 - val_loss: 0.0718
Epoch 74/100
475/475 [==============================] - 0s 909us/step - loss: 0.0130 - val_loss: 0.0706
Epoch 75/100
475/475 [==============================] - 0s 881us/step - loss: 0.0134 - val_loss: 0.0705
Epoch 76/100
475/475 [==============================] - 0s 912us/step - loss: 0.0132 - val_loss: 0.0713
Epoch 77/100
475/475 [==============================] - 0s 915us/step - loss: 0.0132 - val_loss: 0.0713
Epoch 78/100
475/475 [==============================] - 0s 894us/step - loss: 0.0136 - val_loss: 0.0707
Epoch 79/100
475/475 [==============================] - 0s 902us/step - loss: 0.0133 - val_loss: 0.0709
Epoch 80/100
475/475 [==============================] - 0s 909us/step - loss: 0.0132 - val_loss: 0.0714
Epoch 81/100
475/475 [==============================] - 0s 912us/step - loss: 0.0131 - val_loss: 0.0707
Epoch 82/100
475/475 [==============================] - 0s 925us/step - loss: 0.0129 - val_loss: 0.0723
Epoch 83/100
475/475 [==============================] - 0s 923us/step - loss: 0.0129 - val_loss: 0.0716
Epoch 84/100
475/475 [==============================] - 0s 918us/step - loss: 0.0126 - val_loss: 0.0703
Epoch 85/100
475/475 [==============================] - 0s 917us/step - loss: 0.0124 - val_loss: 0.0704
Epoch 86/100
475/475 [==============================] - 0s 923us/step - loss: 0.0125 - val_loss: 0.0702
Epoch 87/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.0718
Epoch 88/100
475/475 [==============================] - 0s 895us/step - loss: 0.0123 - val_loss: 0.0715
Epoch 89/100
475/475 [==============================] - 0s 891us/step - loss: 0.0123 - val_loss: 0.0710
Epoch 90/100
475/475 [==============================] - 0s 906us/step - loss: 0.0121 - val_loss: 0.0704
Epoch 91/100
475/475 [==============================] - 0s 947us/step - loss: 0.0120 - val_loss: 0.0708
Epoch 92/100
475/475 [==============================] - 0s 922us/step - loss: 0.0125 - val_loss: 0.0707
Epoch 93/100
475/475 [==============================] - 0s 915us/step - loss: 0.0120 - val_loss: 0.0703
Epoch 94/100
475/475 [==============================] - 0s 901us/step - loss: 0.0121 - val_loss: 0.0702
Epoch 95/100
475/475 [==============================] - 0s 931us/step - loss: 0.0119 - val_loss: 0.0710
Epoch 96/100
475/475 [==============================] - 0s 935us/step - loss: 0.0115 - val_loss: 0.0708
Epoch 97/100
475/475 [==============================] - 0s 892us/step - loss: 0.0118 - val_loss: 0.0702
Epoch 98/100
475/475 [==============================] - 0s 904us/step - loss: 0.0117 - val_loss: 0.0709
Epoch 99/100
475/475 [==============================] - 0s 906us/step - loss: 0.0116 - val_loss: 0.0702
Epoch 100/100
475/475 [==============================] - 0s 907us/step - loss: 0.0117 - val_loss: 0.0704

In [51]: bigger_model2 = keras.Sequential([
    ...:       layers.Dense(600, activation='relu', input_shape = (571,)),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [52]: bigger_model2.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [53]: bigger_history2 = bigger_model2.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 1ms/step - loss: 0.1502 - val_loss: 0.0869
Epoch 2/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0643 - val_loss: 0.0816
Epoch 3/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0547 - val_loss: 0.0793
Epoch 4/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0498 - val_loss: 0.0800
Epoch 5/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0450 - val_loss: 0.0760
Epoch 6/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0430 - val_loss: 0.0752
Epoch 7/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0399 - val_loss: 0.0768
Epoch 8/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0384 - val_loss: 0.0745
Epoch 9/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0367 - val_loss: 0.0733
Epoch 10/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0347 - val_loss: 0.0755
Epoch 11/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0338 - val_loss: 0.0727
Epoch 12/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0327 - val_loss: 0.0740
Epoch 13/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0317 - val_loss: 0.0755
Epoch 14/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0309 - val_loss: 0.0742
Epoch 15/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0301 - val_loss: 0.0744
Epoch 16/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0299 - val_loss: 0.0731
Epoch 17/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0287 - val_loss: 0.0727
Epoch 18/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0275 - val_loss: 0.0726
Epoch 19/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0267 - val_loss: 0.0719
Epoch 20/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0263 - val_loss: 0.0726
Epoch 21/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0258 - val_loss: 0.0744
Epoch 22/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0256 - val_loss: 0.0726
Epoch 23/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0249 - val_loss: 0.0733
Epoch 24/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0246 - val_loss: 0.0726
Epoch 25/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0236 - val_loss: 0.0735
Epoch 26/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0238 - val_loss: 0.0757
Epoch 27/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0232 - val_loss: 0.0758
Epoch 28/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0225 - val_loss: 0.0736
Epoch 29/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0221 - val_loss: 0.0743
Epoch 30/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0219 - val_loss: 0.0735
Epoch 31/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0217 - val_loss: 0.0755
Epoch 32/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0216 - val_loss: 0.0738
Epoch 33/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0215 - val_loss: 0.0741
Epoch 34/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0208 - val_loss: 0.0749
Epoch 35/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0731
Epoch 36/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0741
Epoch 37/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0754
Epoch 38/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.0742
Epoch 39/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0198 - val_loss: 0.0747
Epoch 40/100
475/475 [==============================] - 0s 994us/step - loss: 0.0197 - val_loss: 0.0750
Epoch 41/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0749
Epoch 42/100
475/475 [==============================] - 0s 998us/step - loss: 0.0189 - val_loss: 0.0766
Epoch 43/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0194 - val_loss: 0.0746
Epoch 44/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0188 - val_loss: 0.0745
Epoch 45/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0751
Epoch 46/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0182 - val_loss: 0.0755
Epoch 47/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0178 - val_loss: 0.0762
Epoch 48/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0186 - val_loss: 0.0758
Epoch 49/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0177 - val_loss: 0.0746
Epoch 50/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0177 - val_loss: 0.0744
Epoch 51/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0174 - val_loss: 0.0747
Epoch 52/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0171 - val_loss: 0.0755
Epoch 53/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0173 - val_loss: 0.0747
Epoch 54/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0172 - val_loss: 0.0744
Epoch 55/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0167 - val_loss: 0.0745
Epoch 56/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0170 - val_loss: 0.0755
Epoch 57/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0172 - val_loss: 0.0746
Epoch 58/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0166 - val_loss: 0.0755
Epoch 59/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0166 - val_loss: 0.0759
Epoch 60/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0167 - val_loss: 0.0747
Epoch 61/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0167 - val_loss: 0.0749
Epoch 62/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0746
Epoch 63/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0160 - val_loss: 0.0752
Epoch 64/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0157 - val_loss: 0.0762
Epoch 65/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0161 - val_loss: 0.0755
Epoch 66/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0153 - val_loss: 0.0761
Epoch 67/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0155 - val_loss: 0.0760
Epoch 68/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0153 - val_loss: 0.0762
Epoch 69/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0155 - val_loss: 0.0759
Epoch 70/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0152 - val_loss: 0.0749
Epoch 71/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0148 - val_loss: 0.0755
Epoch 72/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0156 - val_loss: 0.0744
Epoch 73/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0148 - val_loss: 0.0759
Epoch 74/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0149 - val_loss: 0.0749
Epoch 75/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0146 - val_loss: 0.0750
Epoch 76/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0148 - val_loss: 0.0753
Epoch 77/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0146 - val_loss: 0.0765
Epoch 78/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0145 - val_loss: 0.0753
Epoch 79/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0148 - val_loss: 0.0755
Epoch 80/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0141 - val_loss: 0.0763
Epoch 81/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0148 - val_loss: 0.0746
Epoch 82/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0140 - val_loss: 0.0752
Epoch 83/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0143 - val_loss: 0.0764
Epoch 84/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0140 - val_loss: 0.0751
Epoch 85/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0140 - val_loss: 0.0762
Epoch 86/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0140 - val_loss: 0.0759
Epoch 87/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0144 - val_loss: 0.0751
Epoch 88/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0141 - val_loss: 0.0770
Epoch 89/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0142 - val_loss: 0.0759
Epoch 90/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0140 - val_loss: 0.0766
Epoch 91/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0139 - val_loss: 0.0766
Epoch 92/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0138 - val_loss: 0.0755
Epoch 93/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0135 - val_loss: 0.0760
Epoch 94/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0136 - val_loss: 0.0762
Epoch 95/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0138 - val_loss: 0.0763
Epoch 96/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0139 - val_loss: 0.0768
Epoch 97/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0138 - val_loss: 0.0756
Epoch 98/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0134 - val_loss: 0.0745
Epoch 99/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0131 - val_loss: 0.0767
Epoch 100/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0133 - val_loss: 0.0765

In [54]: dropout_bigger_model2 = keras.Sequential([
    ...:       layers.Dense(600, activation='relu', input_shape = (571,)),
    ...:       layers.Dropout(0.5),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [55]: dropout_bigger_model2.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [56]: dropout_bigger_history2 = dropout_bigger_model2.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 1ms/step - loss: 0.1851 - val_loss: 0.0960
Epoch 2/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0878 - val_loss: 0.0834
Epoch 3/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0760 - val_loss: 0.0812
Epoch 4/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0681 - val_loss: 0.0797
Epoch 5/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0647 - val_loss: 0.0789
Epoch 6/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0612 - val_loss: 0.0763
Epoch 7/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0590 - val_loss: 0.0742
Epoch 8/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0577 - val_loss: 0.0764
Epoch 9/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0558 - val_loss: 0.0740
Epoch 10/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0544 - val_loss: 0.0752
Epoch 11/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0540 - val_loss: 0.0743
Epoch 12/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0534 - val_loss: 0.0726
Epoch 13/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0518 - val_loss: 0.0717
Epoch 14/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0734
Epoch 15/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0508 - val_loss: 0.0731
Epoch 16/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0510 - val_loss: 0.0730
Epoch 17/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0496 - val_loss: 0.0737
Epoch 18/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0486 - val_loss: 0.0729
Epoch 19/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0723
Epoch 20/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0482 - val_loss: 0.0722
Epoch 21/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0484 - val_loss: 0.0728
Epoch 22/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0471 - val_loss: 0.0705
Epoch 23/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0469 - val_loss: 0.0712
Epoch 24/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0472 - val_loss: 0.0722
Epoch 25/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0470 - val_loss: 0.0716
Epoch 26/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0468 - val_loss: 0.0733
Epoch 27/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0461 - val_loss: 0.0707
Epoch 28/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0449 - val_loss: 0.0693
Epoch 29/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0461 - val_loss: 0.0723
Epoch 30/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0459 - val_loss: 0.0701
Epoch 31/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0454 - val_loss: 0.0720
Epoch 32/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0451 - val_loss: 0.0718
Epoch 33/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0453 - val_loss: 0.0709
Epoch 34/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0448 - val_loss: 0.0729
Epoch 35/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0454 - val_loss: 0.0738
Epoch 36/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0452 - val_loss: 0.0715
Epoch 37/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0438 - val_loss: 0.0704
Epoch 38/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0438 - val_loss: 0.0730
Epoch 39/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0440 - val_loss: 0.0706
Epoch 40/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0436 - val_loss: 0.0690
Epoch 41/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0435 - val_loss: 0.0720
Epoch 42/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0436 - val_loss: 0.0712
Epoch 43/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0428 - val_loss: 0.0718
Epoch 44/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0431 - val_loss: 0.0709
Epoch 45/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0430 - val_loss: 0.0706
Epoch 46/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0423 - val_loss: 0.0723
Epoch 47/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0428 - val_loss: 0.0719
Epoch 48/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0423 - val_loss: 0.0707
Epoch 49/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0422 - val_loss: 0.0710
Epoch 50/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0421 - val_loss: 0.0724
Epoch 51/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0418 - val_loss: 0.0722
Epoch 52/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0416 - val_loss: 0.0696
Epoch 53/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0418 - val_loss: 0.0705
Epoch 54/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0422 - val_loss: 0.0716
Epoch 55/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0419 - val_loss: 0.0700
Epoch 56/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0415 - val_loss: 0.0725
Epoch 57/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0421 - val_loss: 0.0733
Epoch 58/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0415 - val_loss: 0.0712
Epoch 59/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0414 - val_loss: 0.0723
Epoch 60/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0413 - val_loss: 0.0730
Epoch 61/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0417 - val_loss: 0.0720
Epoch 62/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0423 - val_loss: 0.0717
Epoch 63/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0408 - val_loss: 0.0736
Epoch 64/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0417 - val_loss: 0.0732
Epoch 65/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0410 - val_loss: 0.0722
Epoch 66/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0407 - val_loss: 0.0731
Epoch 67/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0414 - val_loss: 0.0735
Epoch 68/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0407 - val_loss: 0.0719
Epoch 69/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0413 - val_loss: 0.0738
Epoch 70/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0405 - val_loss: 0.0713
Epoch 71/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0409 - val_loss: 0.0726
Epoch 72/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0402 - val_loss: 0.0703
Epoch 73/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0415 - val_loss: 0.0704
Epoch 74/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0406 - val_loss: 0.0711
Epoch 75/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0409 - val_loss: 0.0715
Epoch 76/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0407 - val_loss: 0.0721
Epoch 77/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0722
Epoch 78/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0406 - val_loss: 0.0723
Epoch 79/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0395 - val_loss: 0.0725
Epoch 80/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0408 - val_loss: 0.0725
Epoch 81/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0407 - val_loss: 0.0735
Epoch 82/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0401 - val_loss: 0.0724
Epoch 83/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0400 - val_loss: 0.0730
Epoch 84/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0398 - val_loss: 0.0724
Epoch 85/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0402 - val_loss: 0.0714
Epoch 86/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0404 - val_loss: 0.0713
Epoch 87/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0716
Epoch 88/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0712
Epoch 89/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0717
Epoch 90/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0393 - val_loss: 0.0700
Epoch 91/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0396 - val_loss: 0.0720
Epoch 92/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0403 - val_loss: 0.0707
Epoch 93/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0406 - val_loss: 0.0719
Epoch 94/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0395 - val_loss: 0.0726
Epoch 95/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0405 - val_loss: 0.0724
Epoch 96/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0401 - val_loss: 0.0721
Epoch 97/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0399 - val_loss: 0.0727
Epoch 98/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0393 - val_loss: 0.0730
Epoch 99/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0401 - val_loss: 0.0719
Epoch 100/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0391 - val_loss: 0.0708

In [57]: bigger_model = keras.Sequential([
    ...:       layers.Dense(128, activation='relu', input_shape = (571,)),
    ...:       layers.Dropout(0.5),
    ...:       layers.Dense(128, activation='relu'),
    ...:       layers.Dropout(0.5),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [58]: bigger_model = keras.Sequential([
    ...:       layers.Dense(128, activation='relu', input_shape = (571,)),
    ...:       layers.Dense(128, activation='relu'),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [59]: bigger_model.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [60]: bigger_history = bigger_model.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 1ms/step - loss: 0.1494 - val_loss: 0.0916
Epoch 2/100
475/475 [==============================] - 0s 900us/step - loss: 0.0648 - val_loss: 0.0855
Epoch 3/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0541 - val_loss: 0.0827
Epoch 4/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0494 - val_loss: 0.0792
Epoch 5/100
475/475 [==============================] - 0s 983us/step - loss: 0.0449 - val_loss: 0.0779
Epoch 6/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0777
Epoch 7/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0402 - val_loss: 0.0754
Epoch 8/100
475/475 [==============================] - 0s 929us/step - loss: 0.0367 - val_loss: 0.0758
Epoch 9/100
475/475 [==============================] - 0s 998us/step - loss: 0.0358 - val_loss: 0.0763
Epoch 10/100
475/475 [==============================] - 0s 987us/step - loss: 0.0356 - val_loss: 0.0745
Epoch 11/100
475/475 [==============================] - 0s 977us/step - loss: 0.0336 - val_loss: 0.0752
Epoch 12/100
475/475 [==============================] - 0s 981us/step - loss: 0.0318 - val_loss: 0.0727
Epoch 13/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.0731
Epoch 14/100
475/475 [==============================] - 0s 871us/step - loss: 0.0303 - val_loss: 0.0723
Epoch 15/100
475/475 [==============================] - 0s 909us/step - loss: 0.0295 - val_loss: 0.0731
Epoch 16/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0282 - val_loss: 0.0740
Epoch 17/100
475/475 [==============================] - 0s 989us/step - loss: 0.0275 - val_loss: 0.0740
Epoch 18/100
475/475 [==============================] - 0s 943us/step - loss: 0.0272 - val_loss: 0.0726
Epoch 19/100
475/475 [==============================] - 0s 928us/step - loss: 0.0270 - val_loss: 0.0722
Epoch 20/100
475/475 [==============================] - 0s 962us/step - loss: 0.0256 - val_loss: 0.0716
Epoch 21/100
475/475 [==============================] - 0s 927us/step - loss: 0.0255 - val_loss: 0.0721
Epoch 22/100
475/475 [==============================] - 0s 893us/step - loss: 0.0246 - val_loss: 0.0725
Epoch 23/100
475/475 [==============================] - 0s 890us/step - loss: 0.0243 - val_loss: 0.0730
Epoch 24/100
475/475 [==============================] - 0s 910us/step - loss: 0.0241 - val_loss: 0.0738
Epoch 25/100
475/475 [==============================] - 0s 893us/step - loss: 0.0236 - val_loss: 0.0733
Epoch 26/100
475/475 [==============================] - 0s 877us/step - loss: 0.0231 - val_loss: 0.0726
Epoch 27/100
475/475 [==============================] - 0s 873us/step - loss: 0.0222 - val_loss: 0.0719
Epoch 28/100
475/475 [==============================] - 0s 900us/step - loss: 0.0217 - val_loss: 0.0722
Epoch 29/100
475/475 [==============================] - 0s 890us/step - loss: 0.0221 - val_loss: 0.0733
Epoch 30/100
475/475 [==============================] - 0s 884us/step - loss: 0.0214 - val_loss: 0.0732
Epoch 31/100
475/475 [==============================] - 0s 872us/step - loss: 0.0211 - val_loss: 0.0720
Epoch 32/100
475/475 [==============================] - 0s 922us/step - loss: 0.0211 - val_loss: 0.0728
Epoch 33/100
475/475 [==============================] - 0s 878us/step - loss: 0.0202 - val_loss: 0.0728
Epoch 34/100
475/475 [==============================] - 0s 889us/step - loss: 0.0201 - val_loss: 0.0723
Epoch 35/100
475/475 [==============================] - 0s 877us/step - loss: 0.0198 - val_loss: 0.0736
Epoch 36/100
475/475 [==============================] - 0s 890us/step - loss: 0.0192 - val_loss: 0.0718
Epoch 37/100
475/475 [==============================] - 0s 987us/step - loss: 0.0194 - val_loss: 0.0722
Epoch 38/100
475/475 [==============================] - 0s 973us/step - loss: 0.0190 - val_loss: 0.0737
Epoch 39/100
475/475 [==============================] - 0s 936us/step - loss: 0.0185 - val_loss: 0.0729
Epoch 40/100
475/475 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0723
Epoch 41/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0183 - val_loss: 0.0713
Epoch 42/100
475/475 [==============================] - 0s 937us/step - loss: 0.0180 - val_loss: 0.0725
Epoch 43/100
475/475 [==============================] - 0s 902us/step - loss: 0.0180 - val_loss: 0.0713
Epoch 44/100
475/475 [==============================] - 0s 883us/step - loss: 0.0176 - val_loss: 0.0717
Epoch 45/100
475/475 [==============================] - 0s 875us/step - loss: 0.0176 - val_loss: 0.0729
Epoch 46/100
475/475 [==============================] - 0s 893us/step - loss: 0.0174 - val_loss: 0.0732
Epoch 47/100
475/475 [==============================] - 0s 900us/step - loss: 0.0172 - val_loss: 0.0720
Epoch 48/100
475/475 [==============================] - 0s 884us/step - loss: 0.0172 - val_loss: 0.0713
Epoch 49/100
475/475 [==============================] - 0s 999us/step - loss: 0.0167 - val_loss: 0.0717
Epoch 50/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0161 - val_loss: 0.0719
Epoch 51/100
475/475 [==============================] - 0s 951us/step - loss: 0.0164 - val_loss: 0.0719
Epoch 52/100
475/475 [==============================] - 0s 966us/step - loss: 0.0161 - val_loss: 0.0722
Epoch 53/100
475/475 [==============================] - 0s 956us/step - loss: 0.0163 - val_loss: 0.0721
Epoch 54/100
475/475 [==============================] - 0s 930us/step - loss: 0.0157 - val_loss: 0.0718
Epoch 55/100
475/475 [==============================] - 0s 887us/step - loss: 0.0154 - val_loss: 0.0722
Epoch 56/100
475/475 [==============================] - 0s 937us/step - loss: 0.0159 - val_loss: 0.0721
Epoch 57/100
475/475 [==============================] - 0s 901us/step - loss: 0.0154 - val_loss: 0.0714
Epoch 58/100
475/475 [==============================] - 0s 894us/step - loss: 0.0150 - val_loss: 0.0719
Epoch 59/100
475/475 [==============================] - 0s 930us/step - loss: 0.0150 - val_loss: 0.0716
Epoch 60/100
475/475 [==============================] - 0s 917us/step - loss: 0.0150 - val_loss: 0.0717
Epoch 61/100
475/475 [==============================] - 0s 894us/step - loss: 0.0149 - val_loss: 0.0722
Epoch 62/100
475/475 [==============================] - 0s 915us/step - loss: 0.0150 - val_loss: 0.0716
Epoch 63/100
475/475 [==============================] - 0s 909us/step - loss: 0.0146 - val_loss: 0.0707
Epoch 64/100
475/475 [==============================] - 0s 892us/step - loss: 0.0147 - val_loss: 0.0710
Epoch 65/100
475/475 [==============================] - 0s 894us/step - loss: 0.0141 - val_loss: 0.0715
Epoch 66/100
475/475 [==============================] - 0s 919us/step - loss: 0.0144 - val_loss: 0.0715
Epoch 67/100
475/475 [==============================] - 0s 893us/step - loss: 0.0140 - val_loss: 0.0709
Epoch 68/100
475/475 [==============================] - 0s 906us/step - loss: 0.0144 - val_loss: 0.0717
Epoch 69/100
475/475 [==============================] - 0s 924us/step - loss: 0.0139 - val_loss: 0.0714
Epoch 70/100
475/475 [==============================] - 0s 898us/step - loss: 0.0137 - val_loss: 0.0725
Epoch 71/100
475/475 [==============================] - 0s 921us/step - loss: 0.0135 - val_loss: 0.0715
Epoch 72/100
475/475 [==============================] - 0s 915us/step - loss: 0.0135 - val_loss: 0.0709
Epoch 73/100
475/475 [==============================] - 0s 892us/step - loss: 0.0135 - val_loss: 0.0716
Epoch 74/100
475/475 [==============================] - 0s 978us/step - loss: 0.0132 - val_loss: 0.0723
Epoch 75/100
475/475 [==============================] - 0s 914us/step - loss: 0.0136 - val_loss: 0.0725
Epoch 76/100
475/475 [==============================] - 0s 897us/step - loss: 0.0135 - val_loss: 0.0713
Epoch 77/100
475/475 [==============================] - 0s 945us/step - loss: 0.0131 - val_loss: 0.0713
Epoch 78/100
475/475 [==============================] - 0s 898us/step - loss: 0.0129 - val_loss: 0.0721
Epoch 79/100
475/475 [==============================] - 0s 937us/step - loss: 0.0131 - val_loss: 0.0723
Epoch 80/100
475/475 [==============================] - 0s 926us/step - loss: 0.0127 - val_loss: 0.0717
Epoch 81/100
475/475 [==============================] - 0s 897us/step - loss: 0.0129 - val_loss: 0.0715
Epoch 82/100
475/475 [==============================] - 0s 902us/step - loss: 0.0127 - val_loss: 0.0717
Epoch 83/100
475/475 [==============================] - 0s 922us/step - loss: 0.0130 - val_loss: 0.0719
Epoch 84/100
475/475 [==============================] - 0s 897us/step - loss: 0.0128 - val_loss: 0.0718
Epoch 85/100
475/475 [==============================] - 0s 932us/step - loss: 0.0124 - val_loss: 0.0714
Epoch 86/100
475/475 [==============================] - 0s 913us/step - loss: 0.0124 - val_loss: 0.0717
Epoch 87/100
475/475 [==============================] - 0s 891us/step - loss: 0.0120 - val_loss: 0.0717
Epoch 88/100
475/475 [==============================] - 0s 921us/step - loss: 0.0123 - val_loss: 0.0711
Epoch 89/100
475/475 [==============================] - 0s 911us/step - loss: 0.0123 - val_loss: 0.0716
Epoch 90/100
475/475 [==============================] - 0s 897us/step - loss: 0.0123 - val_loss: 0.0709
Epoch 91/100
475/475 [==============================] - 0s 933us/step - loss: 0.0123 - val_loss: 0.0718
Epoch 92/100
475/475 [==============================] - 0s 910us/step - loss: 0.0124 - val_loss: 0.0721
Epoch 93/100
475/475 [==============================] - 0s 889us/step - loss: 0.0121 - val_loss: 0.0713
Epoch 94/100
475/475 [==============================] - 0s 915us/step - loss: 0.0121 - val_loss: 0.0719
Epoch 95/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0119 - val_loss: 0.0718
Epoch 96/100
475/475 [==============================] - 0s 936us/step - loss: 0.0121 - val_loss: 0.0721
Epoch 97/100
475/475 [==============================] - 0s 898us/step - loss: 0.0121 - val_loss: 0.0720
Epoch 98/100
475/475 [==============================] - 0s 929us/step - loss: 0.0117 - val_loss: 0.0711
Epoch 99/100
475/475 [==============================] - 0s 898us/step - loss: 0.0117 - val_loss: 0.0713
Epoch 100/100
475/475 [==============================] - 0s 887us/step - loss: 0.0118 - val_loss: 0.0716

In [61]: dropout_bigger_model = keras.Sequential([
    ...:       layers.Dense(128, activation='relu', input_shape = (571,)),
    ...:       layers.Dropout(0.5),
    ...:       layers.Dense(128, activation='relu'),
    ...:       layers.Dropout(0.5),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [62]: dropout_bigger_model.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [63]: dropout_bigger_history = dropout_bigger_model.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 1ms/step - loss: 0.2276 - val_loss: 0.1108
Epoch 2/100
475/475 [==============================] - 0s 906us/step - loss: 0.1223 - val_loss: 0.0922
Epoch 3/100
475/475 [==============================] - 0s 897us/step - loss: 0.1020 - val_loss: 0.0872
Epoch 4/100
475/475 [==============================] - 0s 884us/step - loss: 0.0886 - val_loss: 0.0836
Epoch 5/100
475/475 [==============================] - 0s 930us/step - loss: 0.0830 - val_loss: 0.0838
Epoch 6/100
475/475 [==============================] - 0s 908us/step - loss: 0.0789 - val_loss: 0.0829
Epoch 7/100
475/475 [==============================] - 0s 932us/step - loss: 0.0746 - val_loss: 0.0802
Epoch 8/100
475/475 [==============================] - 0s 898us/step - loss: 0.0719 - val_loss: 0.0815
Epoch 9/100
475/475 [==============================] - 0s 890us/step - loss: 0.0697 - val_loss: 0.0796
Epoch 10/100
475/475 [==============================] - 0s 916us/step - loss: 0.0685 - val_loss: 0.0792
Epoch 11/100
475/475 [==============================] - 0s 921us/step - loss: 0.0675 - val_loss: 0.0776
Epoch 12/100
475/475 [==============================] - 0s 897us/step - loss: 0.0672 - val_loss: 0.0775
Epoch 13/100
475/475 [==============================] - 0s 937us/step - loss: 0.0644 - val_loss: 0.0829
Epoch 14/100
475/475 [==============================] - 0s 922us/step - loss: 0.0645 - val_loss: 0.0789
Epoch 15/100
475/475 [==============================] - 0s 892us/step - loss: 0.0642 - val_loss: 0.0770
Epoch 16/100
475/475 [==============================] - 0s 916us/step - loss: 0.0636 - val_loss: 0.0801
Epoch 17/100
475/475 [==============================] - 0s 919us/step - loss: 0.0627 - val_loss: 0.0784
Epoch 18/100
475/475 [==============================] - 0s 892us/step - loss: 0.0620 - val_loss: 0.0779
Epoch 19/100
475/475 [==============================] - 0s 897us/step - loss: 0.0610 - val_loss: 0.0799
Epoch 20/100
475/475 [==============================] - 0s 898us/step - loss: 0.0597 - val_loss: 0.0758
Epoch 21/100
475/475 [==============================] - 0s 914us/step - loss: 0.0614 - val_loss: 0.0775
Epoch 22/100
475/475 [==============================] - 0s 923us/step - loss: 0.0607 - val_loss: 0.0778
Epoch 23/100
475/475 [==============================] - 0s 903us/step - loss: 0.0603 - val_loss: 0.0751
Epoch 24/100
475/475 [==============================] - 0s 911us/step - loss: 0.0599 - val_loss: 0.0770
Epoch 25/100
475/475 [==============================] - 0s 964us/step - loss: 0.0599 - val_loss: 0.0796
Epoch 26/100
475/475 [==============================] - 0s 906us/step - loss: 0.0594 - val_loss: 0.0815
Epoch 27/100
475/475 [==============================] - 0s 882us/step - loss: 0.0593 - val_loss: 0.0780
Epoch 28/100
475/475 [==============================] - 0s 954us/step - loss: 0.0582 - val_loss: 0.0775
Epoch 29/100
475/475 [==============================] - 0s 909us/step - loss: 0.0577 - val_loss: 0.0794
Epoch 30/100
475/475 [==============================] - 0s 910us/step - loss: 0.0581 - val_loss: 0.0800
Epoch 31/100
475/475 [==============================] - 0s 894us/step - loss: 0.0575 - val_loss: 0.0787
Epoch 32/100
475/475 [==============================] - 0s 913us/step - loss: 0.0578 - val_loss: 0.0755
Epoch 33/100
475/475 [==============================] - 0s 893us/step - loss: 0.0569 - val_loss: 0.0741
Epoch 34/100
475/475 [==============================] - 0s 915us/step - loss: 0.0566 - val_loss: 0.0764
Epoch 35/100
475/475 [==============================] - 0s 909us/step - loss: 0.0561 - val_loss: 0.0770
Epoch 36/100
475/475 [==============================] - 0s 890us/step - loss: 0.0564 - val_loss: 0.0761
Epoch 37/100
475/475 [==============================] - 0s 912us/step - loss: 0.0560 - val_loss: 0.0742
Epoch 38/100
475/475 [==============================] - 0s 910us/step - loss: 0.0564 - val_loss: 0.0755
Epoch 39/100
475/475 [==============================] - 0s 898us/step - loss: 0.0563 - val_loss: 0.0785
Epoch 40/100
475/475 [==============================] - 0s 928us/step - loss: 0.0555 - val_loss: 0.0758
Epoch 41/100
475/475 [==============================] - 0s 916us/step - loss: 0.0559 - val_loss: 0.0784
Epoch 42/100
475/475 [==============================] - 0s 897us/step - loss: 0.0544 - val_loss: 0.0775
Epoch 43/100
475/475 [==============================] - 0s 924us/step - loss: 0.0554 - val_loss: 0.0780
Epoch 44/100
475/475 [==============================] - 0s 910us/step - loss: 0.0557 - val_loss: 0.0780
Epoch 45/100
475/475 [==============================] - 0s 901us/step - loss: 0.0545 - val_loss: 0.0785
Epoch 46/100
475/475 [==============================] - 0s 890us/step - loss: 0.0549 - val_loss: 0.0751
Epoch 47/100
475/475 [==============================] - 0s 892us/step - loss: 0.0548 - val_loss: 0.0785
Epoch 48/100
475/475 [==============================] - 0s 930us/step - loss: 0.0553 - val_loss: 0.0766
Epoch 49/100
475/475 [==============================] - 0s 895us/step - loss: 0.0546 - val_loss: 0.0795
Epoch 50/100
475/475 [==============================] - 0s 909us/step - loss: 0.0545 - val_loss: 0.0771
Epoch 51/100
475/475 [==============================] - 0s 945us/step - loss: 0.0542 - val_loss: 0.0777
Epoch 52/100
475/475 [==============================] - 0s 925us/step - loss: 0.0530 - val_loss: 0.0794
Epoch 53/100
475/475 [==============================] - 0s 903us/step - loss: 0.0536 - val_loss: 0.0784
Epoch 54/100
475/475 [==============================] - 0s 895us/step - loss: 0.0535 - val_loss: 0.0771
Epoch 55/100
475/475 [==============================] - 0s 909us/step - loss: 0.0534 - val_loss: 0.0843
Epoch 56/100
475/475 [==============================] - 0s 918us/step - loss: 0.0539 - val_loss: 0.0818
Epoch 57/100
475/475 [==============================] - 0s 901us/step - loss: 0.0539 - val_loss: 0.0835
Epoch 58/100
475/475 [==============================] - 0s 924us/step - loss: 0.0537 - val_loss: 0.0816
Epoch 59/100
475/475 [==============================] - 0s 910us/step - loss: 0.0531 - val_loss: 0.0775
Epoch 60/100
475/475 [==============================] - 0s 951us/step - loss: 0.0540 - val_loss: 0.0782
Epoch 61/100
475/475 [==============================] - 0s 911us/step - loss: 0.0524 - val_loss: 0.0798
Epoch 62/100
475/475 [==============================] - 0s 900us/step - loss: 0.0531 - val_loss: 0.0777
Epoch 63/100
475/475 [==============================] - 0s 887us/step - loss: 0.0536 - val_loss: 0.0834
Epoch 64/100
475/475 [==============================] - 0s 913us/step - loss: 0.0530 - val_loss: 0.0800
Epoch 65/100
475/475 [==============================] - 0s 916us/step - loss: 0.0534 - val_loss: 0.0767
Epoch 66/100
475/475 [==============================] - 0s 903us/step - loss: 0.0535 - val_loss: 0.0776
Epoch 67/100
475/475 [==============================] - 0s 927us/step - loss: 0.0535 - val_loss: 0.0791
Epoch 68/100
475/475 [==============================] - 0s 912us/step - loss: 0.0525 - val_loss: 0.0801
Epoch 69/100
475/475 [==============================] - 0s 895us/step - loss: 0.0525 - val_loss: 0.0825
Epoch 70/100
475/475 [==============================] - 0s 982us/step - loss: 0.0533 - val_loss: 0.0813
Epoch 71/100
475/475 [==============================] - 0s 908us/step - loss: 0.0520 - val_loss: 0.0804
Epoch 72/100
475/475 [==============================] - 0s 914us/step - loss: 0.0515 - val_loss: 0.0804
Epoch 73/100
475/475 [==============================] - 0s 907us/step - loss: 0.0520 - val_loss: 0.0779
Epoch 74/100
475/475 [==============================] - 0s 902us/step - loss: 0.0525 - val_loss: 0.0788
Epoch 75/100
475/475 [==============================] - 0s 927us/step - loss: 0.0515 - val_loss: 0.0783
Epoch 76/100
475/475 [==============================] - 0s 903us/step - loss: 0.0511 - val_loss: 0.0756
Epoch 77/100
475/475 [==============================] - 0s 891us/step - loss: 0.0523 - val_loss: 0.0836
Epoch 78/100
475/475 [==============================] - 0s 934us/step - loss: 0.0518 - val_loss: 0.0807
Epoch 79/100
475/475 [==============================] - 0s 907us/step - loss: 0.0515 - val_loss: 0.0815
Epoch 80/100
475/475 [==============================] - 0s 903us/step - loss: 0.0516 - val_loss: 0.0778
Epoch 81/100
475/475 [==============================] - 0s 905us/step - loss: 0.0517 - val_loss: 0.0767
Epoch 82/100
475/475 [==============================] - 0s 910us/step - loss: 0.0515 - val_loss: 0.0812
Epoch 83/100
475/475 [==============================] - 0s 901us/step - loss: 0.0524 - val_loss: 0.0805
Epoch 84/100
475/475 [==============================] - 0s 929us/step - loss: 0.0510 - val_loss: 0.0771
Epoch 85/100
475/475 [==============================] - 0s 926us/step - loss: 0.0520 - val_loss: 0.0845
Epoch 86/100
475/475 [==============================] - 0s 892us/step - loss: 0.0515 - val_loss: 0.0793
Epoch 87/100
475/475 [==============================] - 0s 902us/step - loss: 0.0509 - val_loss: 0.0832
Epoch 88/100
475/475 [==============================] - 0s 928us/step - loss: 0.0516 - val_loss: 0.0822
Epoch 89/100
475/475 [==============================] - 0s 899us/step - loss: 0.0514 - val_loss: 0.0863
Epoch 90/100
475/475 [==============================] - 0s 928us/step - loss: 0.0513 - val_loss: 0.0807
Epoch 91/100
475/475 [==============================] - 0s 919us/step - loss: 0.0517 - val_loss: 0.0820
Epoch 92/100
475/475 [==============================] - 0s 896us/step - loss: 0.0516 - val_loss: 0.0791
Epoch 93/100
475/475 [==============================] - 0s 928us/step - loss: 0.0512 - val_loss: 0.0808
Epoch 94/100
475/475 [==============================] - 0s 920us/step - loss: 0.0504 - val_loss: 0.0815
Epoch 95/100
475/475 [==============================] - 0s 929us/step - loss: 0.0510 - val_loss: 0.0863
Epoch 96/100
475/475 [==============================] - 0s 920us/step - loss: 0.0509 - val_loss: 0.0793
Epoch 97/100
475/475 [==============================] - 0s 905us/step - loss: 0.0501 - val_loss: 0.0817
Epoch 98/100
475/475 [==============================] - 0s 922us/step - loss: 0.0504 - val_loss: 0.0791
Epoch 99/100
475/475 [==============================] - 0s 925us/step - loss: 0.0503 - val_loss: 0.0800
Epoch 100/100
475/475 [==============================] - 0s 899us/step - loss: 0.0505 - val_loss: 0.0798

In [64]: bigger_model3 = keras.Sequential([
    ...:       layers.Dense(600, activation='relu', input_shape = (571,)),
    ...:       layers.Dense(600, activation='relu'),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [65]: bigger_model3.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [66]: bigger_history3 = bigger_model3.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 3ms/step - loss: 0.1302 - val_loss: 0.0908
Epoch 2/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0645 - val_loss: 0.0799
Epoch 3/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0546 - val_loss: 0.0751
Epoch 4/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0464 - val_loss: 0.0726
Epoch 5/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0423 - val_loss: 0.0704
Epoch 6/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0392 - val_loss: 0.0751
Epoch 7/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0378 - val_loss: 0.0706
Epoch 8/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0351 - val_loss: 0.0733
Epoch 9/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0334 - val_loss: 0.0697
Epoch 10/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0322 - val_loss: 0.0712
Epoch 11/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0309 - val_loss: 0.0707
Epoch 12/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0296 - val_loss: 0.0702
Epoch 13/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0284 - val_loss: 0.0693
Epoch 14/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0286 - val_loss: 0.0698
Epoch 15/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0269 - val_loss: 0.0672
Epoch 16/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0258 - val_loss: 0.0685
Epoch 17/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0255 - val_loss: 0.0687
Epoch 18/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0246 - val_loss: 0.0688
Epoch 19/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0236 - val_loss: 0.0679
Epoch 20/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0228 - val_loss: 0.0683
Epoch 21/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0226 - val_loss: 0.0688
Epoch 22/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0222 - val_loss: 0.0672
Epoch 23/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0216 - val_loss: 0.0680
Epoch 24/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0212 - val_loss: 0.0667
Epoch 25/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0207 - val_loss: 0.0676
Epoch 26/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0200 - val_loss: 0.0705
Epoch 27/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0199 - val_loss: 0.0689
Epoch 28/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0192 - val_loss: 0.0667
Epoch 29/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0185 - val_loss: 0.0673
Epoch 30/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0184 - val_loss: 0.0685
Epoch 31/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0675
Epoch 32/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0179 - val_loss: 0.0676
Epoch 33/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0172 - val_loss: 0.0662
Epoch 34/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0172 - val_loss: 0.0670
Epoch 35/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0166 - val_loss: 0.0679
Epoch 36/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0167 - val_loss: 0.0677
Epoch 37/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0162 - val_loss: 0.0685
Epoch 38/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0164 - val_loss: 0.0669
Epoch 39/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0161 - val_loss: 0.0677
Epoch 40/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0158 - val_loss: 0.0665
Epoch 41/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0152 - val_loss: 0.0672
Epoch 42/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0152 - val_loss: 0.0675
Epoch 43/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0149 - val_loss: 0.0681
Epoch 44/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0154 - val_loss: 0.0669
Epoch 45/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0145 - val_loss: 0.0681
Epoch 46/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0147 - val_loss: 0.0677
Epoch 47/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0143 - val_loss: 0.0668
Epoch 48/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0143 - val_loss: 0.0677
Epoch 49/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0143 - val_loss: 0.0683
Epoch 50/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0139 - val_loss: 0.0683
Epoch 51/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0141 - val_loss: 0.0672
Epoch 52/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0137 - val_loss: 0.0675
Epoch 53/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0135 - val_loss: 0.0674
Epoch 54/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0136 - val_loss: 0.0661
Epoch 55/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0133 - val_loss: 0.0664
Epoch 56/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0131 - val_loss: 0.0674
Epoch 57/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0127 - val_loss: 0.0661
Epoch 58/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0131 - val_loss: 0.0667
Epoch 59/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0128 - val_loss: 0.0672
Epoch 60/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0125 - val_loss: 0.0678
Epoch 61/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0127 - val_loss: 0.0668
Epoch 62/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0125 - val_loss: 0.0675
Epoch 63/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0125 - val_loss: 0.0667
Epoch 64/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0126 - val_loss: 0.0681
Epoch 65/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0120 - val_loss: 0.0666
Epoch 66/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0674
Epoch 67/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0118 - val_loss: 0.0680
Epoch 68/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0658
Epoch 69/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0117 - val_loss: 0.0666
Epoch 70/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0117 - val_loss: 0.0662
Epoch 71/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0114 - val_loss: 0.0669
Epoch 72/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0118 - val_loss: 0.0665
Epoch 73/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0114 - val_loss: 0.0668
Epoch 74/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0114 - val_loss: 0.0682
Epoch 75/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0113 - val_loss: 0.0675
Epoch 76/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0668
Epoch 77/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0112 - val_loss: 0.0680
Epoch 78/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0114 - val_loss: 0.0670
Epoch 79/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0111 - val_loss: 0.0674
Epoch 80/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0110 - val_loss: 0.0670
Epoch 81/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0109 - val_loss: 0.0654
Epoch 82/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0109 - val_loss: 0.0669
Epoch 83/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0668
Epoch 84/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0109 - val_loss: 0.0668
Epoch 85/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0106 - val_loss: 0.0663
Epoch 86/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0105 - val_loss: 0.0666
Epoch 87/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0105 - val_loss: 0.0669
Epoch 88/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0106 - val_loss: 0.0658
Epoch 89/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0664
Epoch 90/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0664
Epoch 91/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0676
Epoch 92/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0661
Epoch 93/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0661
Epoch 94/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0101 - val_loss: 0.0669
Epoch 95/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0105 - val_loss: 0.0673
Epoch 96/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0674
Epoch 97/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0101 - val_loss: 0.0668
Epoch 98/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0101 - val_loss: 0.0667
Epoch 99/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0666
Epoch 100/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0667

In [67]: smaller_model3 = keras.Sequential([
    ...:       layers.Dense(64, activation='relu', input_shape = (571,)),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [68]: smaller_model = keras.Sequential([
    ...:       layers.Dense(64, activation='relu', input_shape = (571,)),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [69]: smaller_model.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [70]: smaller_history = smaller_model.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 953us/step - loss: 0.1665 - val_loss: 0.0942
Epoch 2/100
475/475 [==============================] - 0s 792us/step - loss: 0.0697 - val_loss: 0.0906
Epoch 3/100
475/475 [==============================] - 0s 771us/step - loss: 0.0589 - val_loss: 0.0857
Epoch 4/100
475/475 [==============================] - 0s 771us/step - loss: 0.0536 - val_loss: 0.0842
Epoch 5/100
475/475 [==============================] - 0s 781us/step - loss: 0.0495 - val_loss: 0.0795
Epoch 6/100
475/475 [==============================] - 0s 765us/step - loss: 0.0465 - val_loss: 0.0798
Epoch 7/100
475/475 [==============================] - 0s 765us/step - loss: 0.0440 - val_loss: 0.0789
Epoch 8/100
475/475 [==============================] - 0s 759us/step - loss: 0.0422 - val_loss: 0.0777
Epoch 9/100
475/475 [==============================] - 0s 776us/step - loss: 0.0401 - val_loss: 0.0764
Epoch 10/100
475/475 [==============================] - 0s 788us/step - loss: 0.0382 - val_loss: 0.0766
Epoch 11/100
475/475 [==============================] - 0s 794us/step - loss: 0.0381 - val_loss: 0.0757
Epoch 12/100
475/475 [==============================] - 0s 794us/step - loss: 0.0365 - val_loss: 0.0763
Epoch 13/100
475/475 [==============================] - 0s 788us/step - loss: 0.0364 - val_loss: 0.0760
Epoch 14/100
475/475 [==============================] - 0s 767us/step - loss: 0.0349 - val_loss: 0.0758
Epoch 15/100
475/475 [==============================] - 0s 779us/step - loss: 0.0342 - val_loss: 0.0760
Epoch 16/100
475/475 [==============================] - 0s 771us/step - loss: 0.0333 - val_loss: 0.0756
Epoch 17/100
475/475 [==============================] - 0s 767us/step - loss: 0.0325 - val_loss: 0.0757
Epoch 18/100
475/475 [==============================] - 0s 765us/step - loss: 0.0320 - val_loss: 0.0748
Epoch 19/100
475/475 [==============================] - 0s 766us/step - loss: 0.0314 - val_loss: 0.0755
Epoch 20/100
475/475 [==============================] - 0s 774us/step - loss: 0.0307 - val_loss: 0.0763
Epoch 21/100
475/475 [==============================] - 0s 773us/step - loss: 0.0302 - val_loss: 0.0752
Epoch 22/100
475/475 [==============================] - 0s 776us/step - loss: 0.0294 - val_loss: 0.0758
Epoch 23/100
475/475 [==============================] - 0s 758us/step - loss: 0.0292 - val_loss: 0.0767
Epoch 24/100
475/475 [==============================] - 0s 779us/step - loss: 0.0288 - val_loss: 0.0748
Epoch 25/100
475/475 [==============================] - 0s 784us/step - loss: 0.0281 - val_loss: 0.0761
Epoch 26/100
475/475 [==============================] - 0s 759us/step - loss: 0.0281 - val_loss: 0.0746
Epoch 27/100
475/475 [==============================] - 0s 769us/step - loss: 0.0275 - val_loss: 0.0747
Epoch 28/100
475/475 [==============================] - 0s 778us/step - loss: 0.0278 - val_loss: 0.0754
Epoch 29/100
475/475 [==============================] - 0s 760us/step - loss: 0.0271 - val_loss: 0.0765
Epoch 30/100
475/475 [==============================] - 0s 778us/step - loss: 0.0270 - val_loss: 0.0768
Epoch 31/100
475/475 [==============================] - 0s 779us/step - loss: 0.0269 - val_loss: 0.0756
Epoch 32/100
475/475 [==============================] - 0s 763us/step - loss: 0.0268 - val_loss: 0.0762
Epoch 33/100
475/475 [==============================] - 0s 773us/step - loss: 0.0259 - val_loss: 0.0759
Epoch 34/100
475/475 [==============================] - 0s 764us/step - loss: 0.0258 - val_loss: 0.0774
Epoch 35/100
475/475 [==============================] - 0s 771us/step - loss: 0.0253 - val_loss: 0.0765
Epoch 36/100
475/475 [==============================] - 0s 764us/step - loss: 0.0253 - val_loss: 0.0769
Epoch 37/100
475/475 [==============================] - 0s 770us/step - loss: 0.0248 - val_loss: 0.0766
Epoch 38/100
475/475 [==============================] - 0s 767us/step - loss: 0.0249 - val_loss: 0.0764
Epoch 39/100
475/475 [==============================] - 0s 780us/step - loss: 0.0244 - val_loss: 0.0772
Epoch 40/100
475/475 [==============================] - 0s 775us/step - loss: 0.0244 - val_loss: 0.0753
Epoch 41/100
475/475 [==============================] - 0s 770us/step - loss: 0.0241 - val_loss: 0.0756
Epoch 42/100
475/475 [==============================] - 0s 770us/step - loss: 0.0246 - val_loss: 0.0756
Epoch 43/100
475/475 [==============================] - 0s 797us/step - loss: 0.0241 - val_loss: 0.0770
Epoch 44/100
475/475 [==============================] - 0s 764us/step - loss: 0.0241 - val_loss: 0.0767
Epoch 45/100
475/475 [==============================] - 0s 766us/step - loss: 0.0238 - val_loss: 0.0762
Epoch 46/100
475/475 [==============================] - 0s 756us/step - loss: 0.0236 - val_loss: 0.0760
Epoch 47/100
475/475 [==============================] - 0s 768us/step - loss: 0.0234 - val_loss: 0.0758
Epoch 48/100
475/475 [==============================] - 0s 769us/step - loss: 0.0230 - val_loss: 0.0764
Epoch 49/100
475/475 [==============================] - 0s 769us/step - loss: 0.0233 - val_loss: 0.0760
Epoch 50/100
475/475 [==============================] - 0s 774us/step - loss: 0.0222 - val_loss: 0.0775
Epoch 51/100
475/475 [==============================] - 0s 768us/step - loss: 0.0235 - val_loss: 0.0760
Epoch 52/100
475/475 [==============================] - 0s 788us/step - loss: 0.0221 - val_loss: 0.0772
Epoch 53/100
475/475 [==============================] - 0s 780us/step - loss: 0.0220 - val_loss: 0.0774
Epoch 54/100
475/475 [==============================] - 0s 772us/step - loss: 0.0220 - val_loss: 0.0775
Epoch 55/100
475/475 [==============================] - 0s 772us/step - loss: 0.0223 - val_loss: 0.0771
Epoch 56/100
475/475 [==============================] - 0s 767us/step - loss: 0.0218 - val_loss: 0.0779
Epoch 57/100
475/475 [==============================] - 0s 759us/step - loss: 0.0214 - val_loss: 0.0785
Epoch 58/100
475/475 [==============================] - 0s 769us/step - loss: 0.0214 - val_loss: 0.0782
Epoch 59/100
475/475 [==============================] - 0s 766us/step - loss: 0.0219 - val_loss: 0.0782
Epoch 60/100
475/475 [==============================] - 0s 776us/step - loss: 0.0212 - val_loss: 0.0773
Epoch 61/100
475/475 [==============================] - 0s 794us/step - loss: 0.0212 - val_loss: 0.0779
Epoch 62/100
475/475 [==============================] - 0s 762us/step - loss: 0.0213 - val_loss: 0.0775
Epoch 63/100
475/475 [==============================] - 0s 771us/step - loss: 0.0212 - val_loss: 0.0772
Epoch 64/100
475/475 [==============================] - 0s 768us/step - loss: 0.0212 - val_loss: 0.0779
Epoch 65/100
475/475 [==============================] - 0s 761us/step - loss: 0.0207 - val_loss: 0.0772
Epoch 66/100
475/475 [==============================] - 0s 770us/step - loss: 0.0210 - val_loss: 0.0786
Epoch 67/100
475/475 [==============================] - 0s 771us/step - loss: 0.0206 - val_loss: 0.0790
Epoch 68/100
475/475 [==============================] - 0s 768us/step - loss: 0.0208 - val_loss: 0.0783
Epoch 69/100
475/475 [==============================] - 0s 782us/step - loss: 0.0201 - val_loss: 0.0779
Epoch 70/100
475/475 [==============================] - 0s 780us/step - loss: 0.0206 - val_loss: 0.0780
Epoch 71/100
475/475 [==============================] - 0s 761us/step - loss: 0.0199 - val_loss: 0.0779
Epoch 72/100
475/475 [==============================] - 0s 764us/step - loss: 0.0201 - val_loss: 0.0787
Epoch 73/100
475/475 [==============================] - 0s 787us/step - loss: 0.0199 - val_loss: 0.0783
Epoch 74/100
475/475 [==============================] - 0s 757us/step - loss: 0.0196 - val_loss: 0.0783
Epoch 75/100
475/475 [==============================] - 0s 766us/step - loss: 0.0201 - val_loss: 0.0781
Epoch 76/100
475/475 [==============================] - 0s 795us/step - loss: 0.0199 - val_loss: 0.0791
Epoch 77/100
475/475 [==============================] - 0s 765us/step - loss: 0.0192 - val_loss: 0.0786
Epoch 78/100
475/475 [==============================] - 0s 775us/step - loss: 0.0196 - val_loss: 0.0788
Epoch 79/100
475/475 [==============================] - 0s 780us/step - loss: 0.0193 - val_loss: 0.0788
Epoch 80/100
475/475 [==============================] - 0s 760us/step - loss: 0.0198 - val_loss: 0.0784
Epoch 81/100
475/475 [==============================] - 0s 774us/step - loss: 0.0193 - val_loss: 0.0787
Epoch 82/100
475/475 [==============================] - 0s 779us/step - loss: 0.0199 - val_loss: 0.0792
Epoch 83/100
475/475 [==============================] - 0s 825us/step - loss: 0.0195 - val_loss: 0.0784
Epoch 84/100
475/475 [==============================] - 0s 844us/step - loss: 0.0192 - val_loss: 0.0788
Epoch 85/100
475/475 [==============================] - 0s 756us/step - loss: 0.0193 - val_loss: 0.0787
Epoch 86/100
475/475 [==============================] - 0s 761us/step - loss: 0.0191 - val_loss: 0.0790
Epoch 87/100
475/475 [==============================] - 0s 766us/step - loss: 0.0189 - val_loss: 0.0794
Epoch 88/100
475/475 [==============================] - 0s 771us/step - loss: 0.0189 - val_loss: 0.0805
Epoch 89/100
475/475 [==============================] - 0s 773us/step - loss: 0.0187 - val_loss: 0.0798
Epoch 90/100
475/475 [==============================] - 0s 755us/step - loss: 0.0184 - val_loss: 0.0779
Epoch 91/100
475/475 [==============================] - 0s 774us/step - loss: 0.0189 - val_loss: 0.0790
Epoch 92/100
475/475 [==============================] - 0s 768us/step - loss: 0.0187 - val_loss: 0.0793
Epoch 93/100
475/475 [==============================] - 0s 758us/step - loss: 0.0184 - val_loss: 0.0783
Epoch 94/100
475/475 [==============================] - 0s 764us/step - loss: 0.0186 - val_loss: 0.0799
Epoch 95/100
475/475 [==============================] - 0s 761us/step - loss: 0.0184 - val_loss: 0.0789
Epoch 96/100
475/475 [==============================] - 0s 760us/step - loss: 0.0180 - val_loss: 0.0794
Epoch 97/100
475/475 [==============================] - 0s 797us/step - loss: 0.0184 - val_loss: 0.0790
Epoch 98/100
475/475 [==============================] - 0s 769us/step - loss: 0.0182 - val_loss: 0.0791
Epoch 99/100
475/475 [==============================] - 0s 764us/step - loss: 0.0181 - val_loss: 0.0790
Epoch 100/100
475/475 [==============================] - 0s 778us/step - loss: 0.0180 - val_loss: 0.0789

In [71]: dropout_bigger_model3 = keras.Sequential([
    ...:       layers.Dense(600, activation='relu', input_shape = (571,)),
    ...:       layers.Dropout(0.5),
    ...:       layers.Dense(600, activation='relu'),
    ...:       layers.Dropout(0.5),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [72]: dropout_bigger_model3.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [73]: dropout_bigger_history3 = dropout_bigger_model3.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 2s 3ms/step - loss: 0.1716 - val_loss: 0.1006
Epoch 2/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0983 - val_loss: 0.0990
Epoch 3/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0830 - val_loss: 0.0861
Epoch 4/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0753 - val_loss: 0.0792
Epoch 5/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0708 - val_loss: 0.0834
Epoch 6/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0665 - val_loss: 0.0811
Epoch 7/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0644 - val_loss: 0.0778
Epoch 8/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0628 - val_loss: 0.0780
Epoch 9/100
475/475 [==============================] - 2s 3ms/step - loss: 0.0613 - val_loss: 0.0774
Epoch 10/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0598 - val_loss: 0.0761
Epoch 11/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0589 - val_loss: 0.0780
Epoch 12/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0579 - val_loss: 0.0726
Epoch 13/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0568 - val_loss: 0.0749
Epoch 14/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0560 - val_loss: 0.0833
Epoch 15/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0558 - val_loss: 0.0747
Epoch 16/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0552 - val_loss: 0.0854
Epoch 17/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0530 - val_loss: 0.0712
Epoch 18/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0526 - val_loss: 0.0727
Epoch 19/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0542 - val_loss: 0.0796
Epoch 20/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0522 - val_loss: 0.0762
Epoch 21/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0528 - val_loss: 0.0764
Epoch 22/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0530 - val_loss: 0.0736
Epoch 23/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0532 - val_loss: 0.0722
Epoch 24/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0511 - val_loss: 0.0736
Epoch 25/100
475/475 [==============================] - 2s 3ms/step - loss: 0.0513 - val_loss: 0.0744
Epoch 26/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0510 - val_loss: 0.0758
Epoch 27/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0511 - val_loss: 0.0706
Epoch 28/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0508 - val_loss: 0.0762
Epoch 29/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0498 - val_loss: 0.0770
Epoch 30/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0506 - val_loss: 0.0769
Epoch 31/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0497 - val_loss: 0.0716
Epoch 32/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0499 - val_loss: 0.0760
Epoch 33/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0497 - val_loss: 0.0735
Epoch 34/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0497 - val_loss: 0.0741
Epoch 35/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0499 - val_loss: 0.0733
Epoch 36/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0485 - val_loss: 0.0810
Epoch 37/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0486 - val_loss: 0.0764
Epoch 38/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0493 - val_loss: 0.0723
Epoch 39/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0483 - val_loss: 0.0799
Epoch 40/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0483 - val_loss: 0.0742
Epoch 41/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0486 - val_loss: 0.0742
Epoch 42/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0487 - val_loss: 0.0780
Epoch 43/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0484 - val_loss: 0.0770
Epoch 44/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0481 - val_loss: 0.0822
Epoch 45/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0480 - val_loss: 0.0784
Epoch 46/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0475 - val_loss: 0.0783
Epoch 47/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0473 - val_loss: 0.0754
Epoch 48/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0482 - val_loss: 0.0760
Epoch 49/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0489 - val_loss: 0.0760
Epoch 50/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0481 - val_loss: 0.0824
Epoch 51/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0478 - val_loss: 0.0744
Epoch 52/100
475/475 [==============================] - 2s 3ms/step - loss: 0.0476 - val_loss: 0.0809
Epoch 53/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0473 - val_loss: 0.0835
Epoch 54/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0469 - val_loss: 0.0822
Epoch 55/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0462 - val_loss: 0.0817
Epoch 56/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0478 - val_loss: 0.0765
Epoch 57/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0477 - val_loss: 0.0811
Epoch 58/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0464 - val_loss: 0.0791
Epoch 59/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0465 - val_loss: 0.0782
Epoch 60/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0470 - val_loss: 0.0766
Epoch 61/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0454 - val_loss: 0.0745
Epoch 62/100
475/475 [==============================] - 2s 3ms/step - loss: 0.0469 - val_loss: 0.0785
Epoch 63/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0462 - val_loss: 0.0790
Epoch 64/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0469 - val_loss: 0.0769
Epoch 65/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0463 - val_loss: 0.0796
Epoch 66/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0460 - val_loss: 0.0773
Epoch 67/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0462 - val_loss: 0.0829
Epoch 68/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0454 - val_loss: 0.0781
Epoch 69/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0471 - val_loss: 0.0805
Epoch 70/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0456 - val_loss: 0.0764
Epoch 71/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0466 - val_loss: 0.0774
Epoch 72/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0452 - val_loss: 0.0806
Epoch 73/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0456 - val_loss: 0.0784
Epoch 74/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0454 - val_loss: 0.0825
Epoch 75/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0453 - val_loss: 0.0761
Epoch 76/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0452 - val_loss: 0.0811
Epoch 77/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0449 - val_loss: 0.0827
Epoch 78/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0453 - val_loss: 0.0838
Epoch 79/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0450 - val_loss: 0.0790
Epoch 80/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0455 - val_loss: 0.0747
Epoch 81/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0455 - val_loss: 0.0791
Epoch 82/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0453 - val_loss: 0.0845
Epoch 83/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0458 - val_loss: 0.0795
Epoch 84/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0462 - val_loss: 0.0786
Epoch 85/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0449 - val_loss: 0.0789
Epoch 86/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0453 - val_loss: 0.0797
Epoch 87/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0445 - val_loss: 0.0781
Epoch 88/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0450 - val_loss: 0.0829
Epoch 89/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0448 - val_loss: 0.0815
Epoch 90/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0445 - val_loss: 0.0800
Epoch 91/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0446 - val_loss: 0.0827
Epoch 92/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0451 - val_loss: 0.0798
Epoch 93/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0449 - val_loss: 0.0787
Epoch 94/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0448 - val_loss: 0.0777
Epoch 95/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0437 - val_loss: 0.0831
Epoch 96/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0459 - val_loss: 0.0835
Epoch 97/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0453 - val_loss: 0.0869
Epoch 98/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0448 - val_loss: 0.0803
Epoch 99/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0446 - val_loss: 0.0850
Epoch 100/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0446 - val_loss: 0.0801

In [74]: bigger_model4 = keras.Sequential([
    ...:       layers.Dense(600, activation='relu', input_shape = (571,)),
    ...:       layers.Dense(600, activation='relu'),
    ...:       layers.Dense(600, activation='relu'),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [75]: bigger_model4.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [76]: bigger_history4 = bigger_model4.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 2s 4ms/step - loss: 0.1263 - val_loss: 0.0882
Epoch 2/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0646 - val_loss: 0.0779
Epoch 3/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0529 - val_loss: 0.0755
Epoch 4/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0465 - val_loss: 0.0712
Epoch 5/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0424 - val_loss: 0.0697
Epoch 6/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0383 - val_loss: 0.0691
Epoch 7/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0363 - val_loss: 0.0681
Epoch 8/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0329 - val_loss: 0.0662
Epoch 9/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0323 - val_loss: 0.0678
Epoch 10/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0310 - val_loss: 0.0670
Epoch 11/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0288 - val_loss: 0.0644
Epoch 12/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0280 - val_loss: 0.0664
Epoch 13/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0263 - val_loss: 0.0676
Epoch 14/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0252 - val_loss: 0.0659
Epoch 15/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0247 - val_loss: 0.0679
Epoch 16/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0235 - val_loss: 0.0641
Epoch 17/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0228 - val_loss: 0.0652
Epoch 18/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0223 - val_loss: 0.0651
Epoch 19/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0226 - val_loss: 0.0644
Epoch 20/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0210 - val_loss: 0.0647
Epoch 21/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0206 - val_loss: 0.0629
Epoch 22/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0194 - val_loss: 0.0650
Epoch 23/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0191 - val_loss: 0.0649
Epoch 24/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0192 - val_loss: 0.0639
Epoch 25/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0175 - val_loss: 0.0639
Epoch 26/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0174 - val_loss: 0.0637
Epoch 27/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0168 - val_loss: 0.0640
Epoch 28/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0167 - val_loss: 0.0638
Epoch 29/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0160 - val_loss: 0.0642
Epoch 30/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0163 - val_loss: 0.0624
Epoch 31/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0155 - val_loss: 0.0644
Epoch 32/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0152 - val_loss: 0.0633
Epoch 33/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0147 - val_loss: 0.0637
Epoch 34/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0147 - val_loss: 0.0646
Epoch 35/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0138 - val_loss: 0.0636
Epoch 36/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0137 - val_loss: 0.0637
Epoch 37/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0135 - val_loss: 0.0633
Epoch 38/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0140 - val_loss: 0.0632
Epoch 39/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0136 - val_loss: 0.0632
Epoch 40/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0131 - val_loss: 0.0631
Epoch 41/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0131 - val_loss: 0.0650
Epoch 42/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0124 - val_loss: 0.0640
Epoch 43/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0125 - val_loss: 0.0632
Epoch 44/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0120 - val_loss: 0.0640
Epoch 45/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0124 - val_loss: 0.0633
Epoch 46/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0123 - val_loss: 0.0625
Epoch 47/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0117 - val_loss: 0.0628
Epoch 48/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0118 - val_loss: 0.0632
Epoch 49/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0119 - val_loss: 0.0630
Epoch 50/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0110 - val_loss: 0.0647
Epoch 51/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0119 - val_loss: 0.0632
Epoch 52/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0109 - val_loss: 0.0625
Epoch 53/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0107 - val_loss: 0.0637
Epoch 54/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0102 - val_loss: 0.0637
Epoch 55/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0109 - val_loss: 0.0633
Epoch 56/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0105 - val_loss: 0.0624
Epoch 57/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0103 - val_loss: 0.0622
Epoch 58/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0101 - val_loss: 0.0616
Epoch 59/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0097 - val_loss: 0.0631
Epoch 60/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0097 - val_loss: 0.0621
Epoch 61/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0097 - val_loss: 0.0629
Epoch 62/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0096 - val_loss: 0.0631
Epoch 63/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0097 - val_loss: 0.0624
Epoch 64/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0093 - val_loss: 0.0631
Epoch 65/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0094 - val_loss: 0.0628
Epoch 66/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0091 - val_loss: 0.0620
Epoch 67/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0096 - val_loss: 0.0629
Epoch 68/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0097 - val_loss: 0.0618
Epoch 69/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0092 - val_loss: 0.0625
Epoch 70/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0089 - val_loss: 0.0620
Epoch 71/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0088 - val_loss: 0.0626
Epoch 72/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0087 - val_loss: 0.0623
Epoch 73/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0090 - val_loss: 0.0619
Epoch 74/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0083 - val_loss: 0.0622
Epoch 75/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0083 - val_loss: 0.0614
Epoch 76/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0085 - val_loss: 0.0614
Epoch 77/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0088 - val_loss: 0.0618
Epoch 78/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0085 - val_loss: 0.0623
Epoch 79/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0081 - val_loss: 0.0619
Epoch 80/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0081 - val_loss: 0.0625
Epoch 81/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0085 - val_loss: 0.0625
Epoch 82/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0080 - val_loss: 0.0622
Epoch 83/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0078 - val_loss: 0.0628
Epoch 84/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0079 - val_loss: 0.0618
Epoch 85/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0080 - val_loss: 0.0616
Epoch 86/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0077 - val_loss: 0.0617
Epoch 87/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0078 - val_loss: 0.0616
Epoch 88/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0080 - val_loss: 0.0616
Epoch 89/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0074 - val_loss: 0.0618
Epoch 90/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0074 - val_loss: 0.0629
Epoch 91/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0080 - val_loss: 0.0613
Epoch 92/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0075 - val_loss: 0.0615
Epoch 93/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0076 - val_loss: 0.0613
Epoch 94/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0075 - val_loss: 0.0609
Epoch 95/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0074 - val_loss: 0.0625
Epoch 96/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0074 - val_loss: 0.0616
Epoch 97/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0072 - val_loss: 0.0609
Epoch 98/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0073 - val_loss: 0.0616
Epoch 99/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0071 - val_loss: 0.0614
Epoch 100/100
475/475 [==============================] - 2s 4ms/step - loss: 0.0069 - val_loss: 0.0616

In [77]: bigger_model5 = keras.Sequential([
    ...:       layers.Dense(1200, activation='relu', input_shape = (571,)),
    ...:       layers.Dense(1200, activation='relu'),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [78]: bigger_model5.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [79]: bigger_history5 = bigger_model5.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 4s 9ms/step - loss: 0.1477 - val_loss: 0.0878
Epoch 2/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0648 - val_loss: 0.0797
Epoch 3/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0528 - val_loss: 0.0751
Epoch 4/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0476 - val_loss: 0.0715
Epoch 5/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0433 - val_loss: 0.0731
Epoch 6/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0416 - val_loss: 0.0717
Epoch 7/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0371 - val_loss: 0.0727
Epoch 8/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0362 - val_loss: 0.0726
Epoch 9/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0340 - val_loss: 0.0712
Epoch 10/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0328 - val_loss: 0.0703
Epoch 11/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0325 - val_loss: 0.0695
Epoch 12/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0305 - val_loss: 0.0684
Epoch 13/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0294 - val_loss: 0.0717
Epoch 14/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0281 - val_loss: 0.0709
Epoch 15/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0266 - val_loss: 0.0706
Epoch 16/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0263 - val_loss: 0.0689
Epoch 17/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0252 - val_loss: 0.0689
Epoch 18/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0250 - val_loss: 0.0720
Epoch 19/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0238 - val_loss: 0.0688
Epoch 20/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0231 - val_loss: 0.0688
Epoch 21/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0222 - val_loss: 0.0710
Epoch 22/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0215 - val_loss: 0.0676
Epoch 23/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0208 - val_loss: 0.0686
Epoch 24/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0205 - val_loss: 0.0677
Epoch 25/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0205 - val_loss: 0.0674
Epoch 26/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0201 - val_loss: 0.0683
Epoch 27/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0199 - val_loss: 0.0677
Epoch 28/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0188 - val_loss: 0.0691
Epoch 29/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0185 - val_loss: 0.0688
Epoch 30/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0186 - val_loss: 0.0688
Epoch 31/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0177 - val_loss: 0.0695
Epoch 32/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0174 - val_loss: 0.0682
Epoch 33/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0172 - val_loss: 0.0671
Epoch 34/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0171 - val_loss: 0.0689
Epoch 35/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0167 - val_loss: 0.0682
Epoch 36/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0159 - val_loss: 0.0692
Epoch 37/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0160 - val_loss: 0.0701
Epoch 38/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0160 - val_loss: 0.0691
Epoch 39/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0154 - val_loss: 0.0686
Epoch 40/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0150 - val_loss: 0.0706
Epoch 41/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0156 - val_loss: 0.0683
Epoch 42/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0148 - val_loss: 0.0688
Epoch 43/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0146 - val_loss: 0.0678
Epoch 44/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0144 - val_loss: 0.0678
Epoch 45/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0144 - val_loss: 0.0690
Epoch 46/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0145 - val_loss: 0.0691
Epoch 47/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0142 - val_loss: 0.0680
Epoch 48/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0139 - val_loss: 0.0679
Epoch 49/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0139 - val_loss: 0.0685
Epoch 50/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0137 - val_loss: 0.0683
Epoch 51/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0135 - val_loss: 0.0678
Epoch 52/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0133 - val_loss: 0.0688
Epoch 53/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0134 - val_loss: 0.0689
Epoch 54/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0130 - val_loss: 0.0684
Epoch 55/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0135 - val_loss: 0.0682
Epoch 56/100
475/475 [==============================] - 4s 8ms/step - loss: 0.0129 - val_loss: 0.0684
Epoch 57/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0125 - val_loss: 0.0675
Epoch 58/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0127 - val_loss: 0.0681
Epoch 59/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0125 - val_loss: 0.0685
Epoch 60/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0125 - val_loss: 0.0686
Epoch 61/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0121 - val_loss: 0.0700
Epoch 62/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0124 - val_loss: 0.0672
Epoch 63/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0120 - val_loss: 0.0677
Epoch 64/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0118 - val_loss: 0.0683
Epoch 65/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0120 - val_loss: 0.0679
Epoch 66/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0117 - val_loss: 0.0684
Epoch 67/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0116 - val_loss: 0.0679
Epoch 68/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0113 - val_loss: 0.0684
Epoch 69/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0115 - val_loss: 0.0679
Epoch 70/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0114 - val_loss: 0.0699
Epoch 71/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0112 - val_loss: 0.0679
Epoch 72/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0108 - val_loss: 0.0686
Epoch 73/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0108 - val_loss: 0.0674
Epoch 74/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0110 - val_loss: 0.0681
Epoch 75/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0108 - val_loss: 0.0682
Epoch 76/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0109 - val_loss: 0.0679
Epoch 77/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0103 - val_loss: 0.0677
Epoch 78/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0106 - val_loss: 0.0678
Epoch 79/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0106 - val_loss: 0.0685
Epoch 80/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0107 - val_loss: 0.0683
Epoch 81/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0107 - val_loss: 0.0674
Epoch 82/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0104 - val_loss: 0.0674
Epoch 83/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0103 - val_loss: 0.0686
Epoch 84/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0104 - val_loss: 0.0683
Epoch 85/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0100 - val_loss: 0.0676
Epoch 86/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0104 - val_loss: 0.0675
Epoch 87/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0103 - val_loss: 0.0677
Epoch 88/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0099 - val_loss: 0.0679
Epoch 89/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0102 - val_loss: 0.0678
Epoch 90/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0100 - val_loss: 0.0677
Epoch 91/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0100 - val_loss: 0.0690
Epoch 92/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0099 - val_loss: 0.0674
Epoch 93/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0099 - val_loss: 0.0684
Epoch 94/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0097 - val_loss: 0.0675
Epoch 95/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0097 - val_loss: 0.0679
Epoch 96/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0098 - val_loss: 0.0672
Epoch 97/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0094 - val_loss: 0.0685
Epoch 98/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0093 - val_loss: 0.0672
Epoch 99/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0093 - val_loss: 0.0680
Epoch 100/100
475/475 [==============================] - 4s 9ms/step - loss: 0.0096 - val_loss: 0.0683

In [80]: bigger_model6 = keras.Sequential([
    ...:       layers.Dense(300, activation='relu', input_shape = (571,)),
    ...:       layers.Dense(300, activation='relu'),
    ...:       layers.Dense(300, activation='relu'),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [81]: bigger_model6.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [82]: bigger_history6 = bigger_model6.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 2ms/step - loss: 0.1338 - val_loss: 0.0833
Epoch 2/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0653 - val_loss: 0.0781
Epoch 3/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0519 - val_loss: 0.0750
Epoch 4/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0449 - val_loss: 0.0719
Epoch 5/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0427 - val_loss: 0.0701
Epoch 6/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0383 - val_loss: 0.0701
Epoch 7/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0701
Epoch 8/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0339 - val_loss: 0.0666
Epoch 9/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0318 - val_loss: 0.0674
Epoch 10/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0306 - val_loss: 0.0662
Epoch 11/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0300 - val_loss: 0.0663
Epoch 12/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0274 - val_loss: 0.0651
Epoch 13/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0276 - val_loss: 0.0663
Epoch 14/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0254 - val_loss: 0.0652
Epoch 15/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0255 - val_loss: 0.0661
Epoch 16/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0247 - val_loss: 0.0650
Epoch 17/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0232 - val_loss: 0.0642
Epoch 18/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0230 - val_loss: 0.0655
Epoch 19/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0222 - val_loss: 0.0655
Epoch 20/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0218 - val_loss: 0.0667
Epoch 21/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0212 - val_loss: 0.0669
Epoch 22/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0210 - val_loss: 0.0640
Epoch 23/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0204 - val_loss: 0.0641
Epoch 24/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0197 - val_loss: 0.0654
Epoch 25/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0189 - val_loss: 0.0643
Epoch 26/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0194 - val_loss: 0.0657
Epoch 27/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0188 - val_loss: 0.0634
Epoch 28/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0179 - val_loss: 0.0650
Epoch 29/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0173 - val_loss: 0.0644
Epoch 30/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0174 - val_loss: 0.0649
Epoch 31/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0168 - val_loss: 0.0646
Epoch 32/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0170 - val_loss: 0.0649
Epoch 33/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0174 - val_loss: 0.0648
Epoch 34/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0161 - val_loss: 0.0635
Epoch 35/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0159 - val_loss: 0.0642
Epoch 36/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0156 - val_loss: 0.0634
Epoch 37/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0157 - val_loss: 0.0645
Epoch 38/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0150 - val_loss: 0.0637
Epoch 39/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0148 - val_loss: 0.0646
Epoch 40/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0146 - val_loss: 0.0642
Epoch 41/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0142 - val_loss: 0.0631
Epoch 42/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0142 - val_loss: 0.0635
Epoch 43/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0141 - val_loss: 0.0645
Epoch 44/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0143 - val_loss: 0.0635
Epoch 45/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0136 - val_loss: 0.0638
Epoch 46/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0136 - val_loss: 0.0635
Epoch 47/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0132 - val_loss: 0.0641
Epoch 48/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0130 - val_loss: 0.0631
Epoch 49/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0129 - val_loss: 0.0631
Epoch 50/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0127 - val_loss: 0.0632
Epoch 51/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0126 - val_loss: 0.0629
Epoch 52/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0130 - val_loss: 0.0635
Epoch 53/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0121 - val_loss: 0.0632
Epoch 54/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0123 - val_loss: 0.0637
Epoch 55/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0119 - val_loss: 0.0639
Epoch 56/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0122 - val_loss: 0.0624
Epoch 57/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0120 - val_loss: 0.0622
Epoch 58/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0115 - val_loss: 0.0631
Epoch 59/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0114 - val_loss: 0.0634
Epoch 60/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0115 - val_loss: 0.0629
Epoch 61/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0114 - val_loss: 0.0624
Epoch 62/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0113 - val_loss: 0.0630
Epoch 63/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0109 - val_loss: 0.0631
Epoch 64/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0110 - val_loss: 0.0630
Epoch 65/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0109 - val_loss: 0.0626
Epoch 66/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0104 - val_loss: 0.0632
Epoch 67/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0105 - val_loss: 0.0639
Epoch 68/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0103 - val_loss: 0.0642
Epoch 69/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0103 - val_loss: 0.0641
Epoch 70/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0104 - val_loss: 0.0632
Epoch 71/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0097 - val_loss: 0.0631
Epoch 72/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0102 - val_loss: 0.0628
Epoch 73/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0098 - val_loss: 0.0636
Epoch 74/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0101 - val_loss: 0.0631
Epoch 75/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0635
Epoch 76/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0097 - val_loss: 0.0635
Epoch 77/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0098 - val_loss: 0.0629
Epoch 78/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0095 - val_loss: 0.0616
Epoch 79/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0630
Epoch 80/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0093 - val_loss: 0.0632
Epoch 81/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0092 - val_loss: 0.0624
Epoch 82/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0089 - val_loss: 0.0635
Epoch 83/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0093 - val_loss: 0.0630
Epoch 84/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0092 - val_loss: 0.0625
Epoch 85/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0634
Epoch 86/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0093 - val_loss: 0.0628
Epoch 87/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0629
Epoch 88/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0627
Epoch 89/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0630
Epoch 90/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0090 - val_loss: 0.0620
Epoch 91/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0086 - val_loss: 0.0629
Epoch 92/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0626
Epoch 93/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0085 - val_loss: 0.0624
Epoch 94/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0629
Epoch 95/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0084 - val_loss: 0.0638
Epoch 96/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0084 - val_loss: 0.0625
Epoch 97/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0629
Epoch 98/100
475/475 [==============================] - 1s 1ms/step - loss: 0.0082 - val_loss: 0.0631
Epoch 99/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0630
Epoch 100/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0631

In [83]: bigger_model7 = keras.Sequential([
    ...:       layers.Dense(300, activation='relu', input_shape = (571,)),
    ...:       layers.Dense(300, activation='relu'),
    ...:       layers.Dense(300, activation='relu'),
    ...:       layers.Dense(300, activation='relu'),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [84]: bigger_model7.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [85]: bigger_history7 = bigger_model7.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 2ms/step - loss: 0.1355 - val_loss: 0.0816
Epoch 2/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0612 - val_loss: 0.0739
Epoch 3/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0512 - val_loss: 0.0825
Epoch 4/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0457 - val_loss: 0.0707
Epoch 5/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0413 - val_loss: 0.0724
Epoch 6/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0372 - val_loss: 0.0688
Epoch 7/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0345 - val_loss: 0.0655
Epoch 8/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0326 - val_loss: 0.0679
Epoch 9/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0307 - val_loss: 0.0653
Epoch 10/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0291 - val_loss: 0.0648
Epoch 11/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0278 - val_loss: 0.0643
Epoch 12/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0262 - val_loss: 0.0647
Epoch 13/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0249 - val_loss: 0.0639
Epoch 14/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0246 - val_loss: 0.0627
Epoch 15/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0229 - val_loss: 0.0620
Epoch 16/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0222 - val_loss: 0.0631
Epoch 17/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0220 - val_loss: 0.0621
Epoch 18/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0208 - val_loss: 0.0622
Epoch 19/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0198 - val_loss: 0.0619
Epoch 20/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0200 - val_loss: 0.0629
Epoch 21/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0194 - val_loss: 0.0625
Epoch 22/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0188 - val_loss: 0.0603
Epoch 23/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0180 - val_loss: 0.0614
Epoch 24/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0175 - val_loss: 0.0610
Epoch 25/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0173 - val_loss: 0.0611
Epoch 26/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0165 - val_loss: 0.0616
Epoch 27/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0167 - val_loss: 0.0603
Epoch 28/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0156 - val_loss: 0.0623
Epoch 29/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0159 - val_loss: 0.0616
Epoch 30/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0149 - val_loss: 0.0601
Epoch 31/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0149 - val_loss: 0.0587
Epoch 32/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0147 - val_loss: 0.0600
Epoch 33/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0142 - val_loss: 0.0599
Epoch 34/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0137 - val_loss: 0.0629
Epoch 35/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0141 - val_loss: 0.0595
Epoch 36/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0136 - val_loss: 0.0612
Epoch 37/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0128 - val_loss: 0.0614
Epoch 38/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0130 - val_loss: 0.0600
Epoch 39/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0131 - val_loss: 0.0594
Epoch 40/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0131 - val_loss: 0.0615
Epoch 41/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0123 - val_loss: 0.0596
Epoch 42/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0123 - val_loss: 0.0600
Epoch 43/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0115 - val_loss: 0.0604
Epoch 44/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0120 - val_loss: 0.0598
Epoch 45/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0115 - val_loss: 0.0606
Epoch 46/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0114 - val_loss: 0.0592
Epoch 47/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0115 - val_loss: 0.0586
Epoch 48/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0110 - val_loss: 0.0608
Epoch 49/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0112 - val_loss: 0.0602
Epoch 50/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0104 - val_loss: 0.0587
Epoch 51/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0103 - val_loss: 0.0600
Epoch 52/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0601
Epoch 53/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0106 - val_loss: 0.0610
Epoch 54/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0106 - val_loss: 0.0599
Epoch 55/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0097 - val_loss: 0.0590
Epoch 56/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0098 - val_loss: 0.0592
Epoch 57/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0608
Epoch 58/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0097 - val_loss: 0.0604
Epoch 59/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0092 - val_loss: 0.0607
Epoch 60/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0098 - val_loss: 0.0602
Epoch 61/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0097 - val_loss: 0.0602
Epoch 62/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0598
Epoch 63/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0604
Epoch 64/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0588
Epoch 65/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0596
Epoch 66/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.0600
Epoch 67/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.0609
Epoch 68/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0596
Epoch 69/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0601
Epoch 70/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0606
Epoch 71/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0591
Epoch 72/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0603
Epoch 73/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0599
Epoch 74/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0084 - val_loss: 0.0605
Epoch 75/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0085 - val_loss: 0.0591
Epoch 76/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0605
Epoch 77/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0601
Epoch 78/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0085 - val_loss: 0.0593
Epoch 79/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0593
Epoch 80/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0595
Epoch 81/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0085 - val_loss: 0.0599
Epoch 82/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0075 - val_loss: 0.0593
Epoch 83/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0598
Epoch 84/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0590
Epoch 85/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0587
Epoch 86/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.0605
Epoch 87/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0073 - val_loss: 0.0596
Epoch 88/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0075 - val_loss: 0.0621
Epoch 89/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0608
Epoch 90/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0072 - val_loss: 0.0604
Epoch 91/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0075 - val_loss: 0.0599
Epoch 92/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0077 - val_loss: 0.0604
Epoch 93/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0073 - val_loss: 0.0591
Epoch 94/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0076 - val_loss: 0.0606
Epoch 95/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0606
Epoch 96/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0074 - val_loss: 0.0610
Epoch 97/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0073 - val_loss: 0.0591
Epoch 98/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0076 - val_loss: 0.0598
Epoch 99/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0069 - val_loss: 0.0601
Epoch 100/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0068 - val_loss: 0.0601

In [86]: dropout_bigger_model7 = keras.Sequential([
    ...:       layers.Dense(300, activation='relu', input_shape = (571,)),
    ...:       layers.Dropout(0.2),
    ...:       layers.Dense(300, activation='relu'),
    ...:       layers.Dropout(0.2),
    ...:       layers.Dense(300, activation='relu'),
    ...:       layers.Dropout(0.2),
    ...:       layers.Dense(300, activation='relu'),
    ...:       layers.Dropout(0.2),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [87]: dropout_bigger_model7.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [88]: dropout_bigger_history7 = dropout_bigger_model7.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 1s 2ms/step - loss: 0.1500 - val_loss: 0.0897
Epoch 2/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0842 - val_loss: 0.0846
Epoch 3/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0721 - val_loss: 0.0752
Epoch 4/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0657 - val_loss: 0.0744
Epoch 5/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0594 - val_loss: 0.0699
Epoch 6/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0567 - val_loss: 0.0712
Epoch 7/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0541 - val_loss: 0.0685
Epoch 8/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0494 - val_loss: 0.0702
Epoch 9/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0483 - val_loss: 0.0679
Epoch 10/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0469 - val_loss: 0.0697
Epoch 11/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0455 - val_loss: 0.0665
Epoch 12/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0444 - val_loss: 0.0643
Epoch 13/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0421 - val_loss: 0.0652
Epoch 14/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0422 - val_loss: 0.0715
Epoch 15/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0419 - val_loss: 0.0643
Epoch 16/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0408 - val_loss: 0.0638
Epoch 17/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0409 - val_loss: 0.0631
Epoch 18/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0390 - val_loss: 0.0652
Epoch 19/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0391 - val_loss: 0.0656
Epoch 20/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0378 - val_loss: 0.0640
Epoch 21/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0378 - val_loss: 0.0662
Epoch 22/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0375 - val_loss: 0.0619
Epoch 23/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0365 - val_loss: 0.0641
Epoch 24/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0358 - val_loss: 0.0651
Epoch 25/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0365 - val_loss: 0.0615
Epoch 26/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0358 - val_loss: 0.0645
Epoch 27/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0344 - val_loss: 0.0634
Epoch 28/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0343 - val_loss: 0.0631
Epoch 29/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0349 - val_loss: 0.0627
Epoch 30/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0344 - val_loss: 0.0651
Epoch 31/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0345 - val_loss: 0.0646
Epoch 32/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0338 - val_loss: 0.0625
Epoch 33/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0336 - val_loss: 0.0643
Epoch 34/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0342 - val_loss: 0.0650
Epoch 35/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0330 - val_loss: 0.0651
Epoch 36/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0332 - val_loss: 0.0623
Epoch 37/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0333 - val_loss: 0.0661
Epoch 38/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0323 - val_loss: 0.0640
Epoch 39/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0317 - val_loss: 0.0688
Epoch 40/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0319 - val_loss: 0.0615
Epoch 41/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0321 - val_loss: 0.0666
Epoch 42/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0315 - val_loss: 0.0624
Epoch 43/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0308 - val_loss: 0.0625
Epoch 44/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0314 - val_loss: 0.0597
Epoch 45/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0317 - val_loss: 0.0624
Epoch 46/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0309 - val_loss: 0.0611
Epoch 47/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0313 - val_loss: 0.0602
Epoch 48/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0303 - val_loss: 0.0610
Epoch 49/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0308 - val_loss: 0.0596
Epoch 50/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0309 - val_loss: 0.0663
Epoch 51/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0310 - val_loss: 0.0627
Epoch 52/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0302 - val_loss: 0.0607
Epoch 53/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0297 - val_loss: 0.0623
Epoch 54/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0294 - val_loss: 0.0635
Epoch 55/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0300 - val_loss: 0.0620
Epoch 56/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0295 - val_loss: 0.0611
Epoch 57/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0297 - val_loss: 0.0639
Epoch 58/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0292 - val_loss: 0.0606
Epoch 59/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0287 - val_loss: 0.0607
Epoch 60/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0292 - val_loss: 0.0613
Epoch 61/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0298 - val_loss: 0.0586
Epoch 62/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0292 - val_loss: 0.0619
Epoch 63/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0287 - val_loss: 0.0618
Epoch 64/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0294 - val_loss: 0.0627
Epoch 65/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0286 - val_loss: 0.0658
Epoch 66/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0280 - val_loss: 0.0607
Epoch 67/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0289 - val_loss: 0.0611
Epoch 68/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0284 - val_loss: 0.0605
Epoch 69/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0284 - val_loss: 0.0618
Epoch 70/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0280 - val_loss: 0.0611
Epoch 71/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0274 - val_loss: 0.0624
Epoch 72/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0279 - val_loss: 0.0626
Epoch 73/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0278 - val_loss: 0.0644
Epoch 74/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0280 - val_loss: 0.0639
Epoch 75/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0274 - val_loss: 0.0617
Epoch 76/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0282 - val_loss: 0.0610
Epoch 77/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0267 - val_loss: 0.0631
Epoch 78/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0277 - val_loss: 0.0640
Epoch 79/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0270 - val_loss: 0.0613
Epoch 80/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0265 - val_loss: 0.0641
Epoch 81/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0278 - val_loss: 0.0643
Epoch 82/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0276 - val_loss: 0.0617
Epoch 83/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0264 - val_loss: 0.0637
Epoch 84/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0272 - val_loss: 0.0650
Epoch 85/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0270 - val_loss: 0.0661
Epoch 86/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0276 - val_loss: 0.0632
Epoch 87/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0266 - val_loss: 0.0646
Epoch 88/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0263 - val_loss: 0.0628
Epoch 89/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0262 - val_loss: 0.0630
Epoch 90/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0263 - val_loss: 0.0610
Epoch 91/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0258 - val_loss: 0.0617
Epoch 92/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0265 - val_loss: 0.0675
Epoch 93/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0262 - val_loss: 0.0656
Epoch 94/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0262 - val_loss: 0.0615
Epoch 95/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0260 - val_loss: 0.0632
Epoch 96/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0260 - val_loss: 0.0609
Epoch 97/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0265 - val_loss: 0.0622
Epoch 98/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0255 - val_loss: 0.0615
Epoch 99/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0250 - val_loss: 0.0629
Epoch 100/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0256 - val_loss: 0.0634

In [89]: bigger_model8 = keras.Sequential([
    ...:       layers.Dense(300, activation='relu', input_shape = (571,)),
    ...:       layers.Dense(300, activation='relu'),
    ...:       layers.Dense(300, activation='relu'),
    ...:       layers.Dense(300, activation='relu'),
    ...:       layers.Dense(300, activation='relu'),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [90]: bigger_model8.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [91]: bigger_history8 = bigger_model8.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 2s 2ms/step - loss: 0.1316 - val_loss: 0.0821
Epoch 2/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0636 - val_loss: 0.0780
Epoch 3/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0525 - val_loss: 0.0851
Epoch 4/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0455 - val_loss: 0.0696
Epoch 5/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0400 - val_loss: 0.0652
Epoch 6/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0357 - val_loss: 0.0643
Epoch 7/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0337 - val_loss: 0.0644
Epoch 8/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0324 - val_loss: 0.0624
Epoch 9/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0300 - val_loss: 0.0648
Epoch 10/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0281 - val_loss: 0.0622
Epoch 11/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0273 - val_loss: 0.0609
Epoch 12/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0255 - val_loss: 0.0625
Epoch 13/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0243 - val_loss: 0.0610
Epoch 14/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0235 - val_loss: 0.0629
Epoch 15/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0228 - val_loss: 0.0598
Epoch 16/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0217 - val_loss: 0.0596
Epoch 17/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0206 - val_loss: 0.0603
Epoch 18/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0208 - val_loss: 0.0611
Epoch 19/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0191 - val_loss: 0.0586
Epoch 20/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0182 - val_loss: 0.0593
Epoch 21/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0182 - val_loss: 0.0588
Epoch 22/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0170 - val_loss: 0.0598
Epoch 23/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0170 - val_loss: 0.0578
Epoch 24/100
475/475 [==============================] - 2s 3ms/step - loss: 0.0157 - val_loss: 0.0592
Epoch 25/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0158 - val_loss: 0.0586
Epoch 26/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0154 - val_loss: 0.0599
Epoch 27/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0155 - val_loss: 0.0581
Epoch 28/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0151 - val_loss: 0.0603
Epoch 29/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0145 - val_loss: 0.0610
Epoch 30/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0145 - val_loss: 0.0614
Epoch 31/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0140 - val_loss: 0.0605
Epoch 32/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0139 - val_loss: 0.0604
Epoch 33/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0130 - val_loss: 0.0579
Epoch 34/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0131 - val_loss: 0.0582
Epoch 35/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0129 - val_loss: 0.0581
Epoch 36/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0127 - val_loss: 0.0575
Epoch 37/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0119 - val_loss: 0.0603
Epoch 38/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0116 - val_loss: 0.0609
Epoch 39/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0122 - val_loss: 0.0583
Epoch 40/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0592
Epoch 41/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0121 - val_loss: 0.0597
Epoch 42/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0120 - val_loss: 0.0600
Epoch 43/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0113 - val_loss: 0.0583
Epoch 44/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0110 - val_loss: 0.0589
Epoch 45/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0114 - val_loss: 0.0605
Epoch 46/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0113 - val_loss: 0.0595
Epoch 47/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0108 - val_loss: 0.0594
Epoch 48/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0591
Epoch 49/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0584
Epoch 50/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0100 - val_loss: 0.0606
Epoch 51/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0107 - val_loss: 0.0596
Epoch 52/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0108 - val_loss: 0.0592
Epoch 53/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0105 - val_loss: 0.0586
Epoch 54/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0106 - val_loss: 0.0574
Epoch 55/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0101 - val_loss: 0.0600
Epoch 56/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0103 - val_loss: 0.0597
Epoch 57/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0094 - val_loss: 0.0581
Epoch 58/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0097 - val_loss: 0.0599
Epoch 59/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0093 - val_loss: 0.0608
Epoch 60/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0098 - val_loss: 0.0591
Epoch 61/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0092 - val_loss: 0.0596
Epoch 62/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0092 - val_loss: 0.0612
Epoch 63/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.0596
Epoch 64/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0094 - val_loss: 0.0606
Epoch 65/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0093 - val_loss: 0.0598
Epoch 66/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0086 - val_loss: 0.0587
Epoch 67/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0084 - val_loss: 0.0583
Epoch 68/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0086 - val_loss: 0.0585
Epoch 69/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0580
Epoch 70/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0594
Epoch 71/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0590
Epoch 72/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0584
Epoch 73/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0089 - val_loss: 0.0605
Epoch 74/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0086 - val_loss: 0.0592
Epoch 75/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0596
Epoch 76/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0084 - val_loss: 0.0589
Epoch 77/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0081 - val_loss: 0.0598
Epoch 78/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0086 - val_loss: 0.0596
Epoch 79/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0577
Epoch 80/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0086 - val_loss: 0.0605
Epoch 81/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0083 - val_loss: 0.0598
Epoch 82/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0082 - val_loss: 0.0605
Epoch 83/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0573
Epoch 84/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0585
Epoch 85/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0086 - val_loss: 0.0588
Epoch 86/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0583
Epoch 87/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0582
Epoch 88/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0086 - val_loss: 0.0586
Epoch 89/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0584
Epoch 90/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0592
Epoch 91/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0595
Epoch 92/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0074 - val_loss: 0.0611
Epoch 93/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0597
Epoch 94/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0585
Epoch 95/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0593
Epoch 96/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0602
Epoch 97/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0075 - val_loss: 0.0606
Epoch 98/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0614
Epoch 99/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0604
Epoch 100/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0075 - val_loss: 0.0603

In [92]: bigger_model9 = keras.Sequential([
    ...:       layers.Dense(600, activation='relu', input_shape = (571,)),
    ...:       layers.Dense(600, activation='relu'),
    ...:       layers.Dense(600, activation='relu'),
    ...:       layers.Dense(600, activation='relu'),
    ...:       layers.Dense(1)
    ...:   ])
    ...: 

In [93]: bigger_model9.compile(loss='mean_absolute_error',
    ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
    ...: 

In [94]: bigger_history9 = bigger_model9.fit(
    ...:     train_boards, train_labels,
    ...:     epochs=100,
    ...:     # Calculate validation results on 20% of the training data
    ...:     validation_split = 0.2)
    ...: 
Epoch 1/100
475/475 [==============================] - 3s 5ms/step - loss: 0.1264 - val_loss: 0.0847
Epoch 2/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0622 - val_loss: 0.0730
Epoch 3/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0510 - val_loss: 0.0706
Epoch 4/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0438 - val_loss: 0.0759
Epoch 5/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0401 - val_loss: 0.0662
Epoch 6/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0352 - val_loss: 0.0656
Epoch 7/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0328 - val_loss: 0.0639
Epoch 8/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0317 - val_loss: 0.0650
Epoch 9/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0286 - val_loss: 0.0612
Epoch 10/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0273 - val_loss: 0.0653
Epoch 11/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0270 - val_loss: 0.0609
Epoch 12/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0246 - val_loss: 0.0592
Epoch 13/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0231 - val_loss: 0.0593
Epoch 14/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0228 - val_loss: 0.0627
Epoch 15/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0219 - val_loss: 0.0600
Epoch 16/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0204 - val_loss: 0.0605
Epoch 17/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0206 - val_loss: 0.0595
Epoch 18/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0196 - val_loss: 0.0606
Epoch 19/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0185 - val_loss: 0.0598
Epoch 20/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0175 - val_loss: 0.0592
Epoch 21/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0175 - val_loss: 0.0586
Epoch 22/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0164 - val_loss: 0.0586
Epoch 23/100
475/475 [==============================] - 3s 5ms/step - loss: 0.0160 - val_loss: 0.0582
Epoch 24/100
475/475 [==============================] - 3s 5ms/step - loss: 0.0153 - val_loss: 0.0599
Epoch 25/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0158 - val_loss: 0.0596
Epoch 26/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0152 - val_loss: 0.0607
Epoch 27/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0150 - val_loss: 0.0594
Epoch 28/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0147 - val_loss: 0.0594
Epoch 29/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0132 - val_loss: 0.0584
Epoch 30/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0135 - val_loss: 0.0589
Epoch 31/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0133 - val_loss: 0.0588
Epoch 32/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0134 - val_loss: 0.0602
Epoch 33/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0128 - val_loss: 0.0589
Epoch 34/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0131 - val_loss: 0.0601
Epoch 35/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0123 - val_loss: 0.0586
Epoch 36/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0132 - val_loss: 0.0587
Epoch 37/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0128 - val_loss: 0.0577
Epoch 38/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0121 - val_loss: 0.0594
Epoch 39/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0120 - val_loss: 0.0586
Epoch 40/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0112 - val_loss: 0.0591
Epoch 41/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0113 - val_loss: 0.0578
Epoch 42/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0114 - val_loss: 0.0584
Epoch 43/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0111 - val_loss: 0.0584
Epoch 44/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0111 - val_loss: 0.0577
Epoch 45/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0103 - val_loss: 0.0588
Epoch 46/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0107 - val_loss: 0.0585
Epoch 47/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0106 - val_loss: 0.0575
Epoch 48/100
475/475 [==============================] - 3s 5ms/step - loss: 0.0106 - val_loss: 0.0574
Epoch 49/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0103 - val_loss: 0.0576
Epoch 50/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0104 - val_loss: 0.0578
Epoch 51/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0104 - val_loss: 0.0569
Epoch 52/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0099 - val_loss: 0.0570
Epoch 53/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0104 - val_loss: 0.0576
Epoch 54/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0096 - val_loss: 0.0576
Epoch 55/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0097 - val_loss: 0.0572
Epoch 56/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0099 - val_loss: 0.0579
Epoch 57/100
475/475 [==============================] - 3s 5ms/step - loss: 0.0095 - val_loss: 0.0579
Epoch 58/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0095 - val_loss: 0.0576
Epoch 59/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0091 - val_loss: 0.0572
Epoch 60/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0093 - val_loss: 0.0569
Epoch 61/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0094 - val_loss: 0.0588
Epoch 62/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0099 - val_loss: 0.0581
Epoch 63/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0090 - val_loss: 0.0612
Epoch 64/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0086 - val_loss: 0.0566
Epoch 65/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0090 - val_loss: 0.0561
Epoch 66/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0086 - val_loss: 0.0587
Epoch 67/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0098 - val_loss: 0.0589
Epoch 68/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0088 - val_loss: 0.0567
Epoch 69/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0090 - val_loss: 0.0569
Epoch 70/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0090 - val_loss: 0.0584
Epoch 71/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0079 - val_loss: 0.0571
Epoch 72/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0086 - val_loss: 0.0571
Epoch 73/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0089 - val_loss: 0.0587
Epoch 74/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0086 - val_loss: 0.0592
Epoch 75/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0083 - val_loss: 0.0568
Epoch 76/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0077 - val_loss: 0.0572
Epoch 77/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0076 - val_loss: 0.0577
Epoch 78/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0081 - val_loss: 0.0592
Epoch 79/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0079 - val_loss: 0.0570
Epoch 80/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0079 - val_loss: 0.0578
Epoch 81/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0077 - val_loss: 0.0565
Epoch 82/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0077 - val_loss: 0.0587
Epoch 83/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0076 - val_loss: 0.0580
Epoch 84/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0073 - val_loss: 0.0588
Epoch 85/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0077 - val_loss: 0.0576
Epoch 86/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0077 - val_loss: 0.0588
Epoch 87/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0081 - val_loss: 0.0598
Epoch 88/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0079 - val_loss: 0.0580
Epoch 89/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0073 - val_loss: 0.0585
Epoch 90/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0075 - val_loss: 0.0571
Epoch 91/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0081 - val_loss: 0.0581
Epoch 92/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0075 - val_loss: 0.0576
Epoch 93/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0073 - val_loss: 0.0584
Epoch 94/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0074 - val_loss: 0.0574
Epoch 95/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0072 - val_loss: 0.0571
Epoch 96/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0069 - val_loss: 0.0583
Epoch 97/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0070 - val_loss: 0.0587
Epoch 98/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0074 - val_loss: 0.0580
Epoch 99/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0077 - val_loss: 0.0576
Epoch 100/100
475/475 [==============================] - 2s 5ms/step - loss: 0.0076 - val_loss: 0.0582

In [95]: bigger_model7.summary
Out[95]: <bound method Model.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x1ab08c5b0>>

In [96]: bigger_model7.summary()
Model: "sequential_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_56 (Dense)             (None, 300)               171600    
_________________________________________________________________
dense_57 (Dense)             (None, 300)               90300     
_________________________________________________________________
dense_58 (Dense)             (None, 300)               90300     
_________________________________________________________________
dense_59 (Dense)             (None, 300)               90300     
_________________________________________________________________
dense_60 (Dense)             (None, 1)                 301       
=================================================================
Total params: 442,801
Trainable params: 442,801
Non-trainable params: 0
_________________________________________________________________

In [97]: bigger_model8.summary()
Model: "sequential_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_66 (Dense)             (None, 300)               171600    
_________________________________________________________________
dense_67 (Dense)             (None, 300)               90300     
_________________________________________________________________
dense_68 (Dense)             (None, 300)               90300     
_________________________________________________________________
dense_69 (Dense)             (None, 300)               90300     
_________________________________________________________________
dense_70 (Dense)             (None, 300)               90300     
_________________________________________________________________
dense_71 (Dense)             (None, 1)                 301       
=================================================================
Total params: 533,101
Trainable params: 533,101
Non-trainable params: 0
_________________________________________________________________

In [98]: bigger_model9.summary()
Model: "sequential_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_72 (Dense)             (None, 600)               343200    
_________________________________________________________________
dense_73 (Dense)             (None, 600)               360600    
_________________________________________________________________
dense_74 (Dense)             (None, 600)               360600    
_________________________________________________________________
dense_75 (Dense)             (None, 600)               360600    
_________________________________________________________________
dense_76 (Dense)             (None, 1)                 601       
=================================================================
Total params: 1,425,601
Trainable params: 1,425,601
Non-trainable params: 0
_________________________________________________________________

In [99]: chosen_model = bigger_model7

In [100]: test_results = chosen_model.evaluate(test_boards, test_labels)
146/146 [==============================] - 0s 726us/step - loss: 0.0649

In [101]: type(test_results)
Out[101]: float

In [102]: test_results
Out[102]: 0.06490730494260788

In [103]: predictions = chosen_model.predict(test_boards)

In [104]: predictions.shape
Out[104]: (4667, 1)

In [105]: test_labels[0:10}
  File "<ipython-input-105-7d3a4bfbcf4b>", line 1
    test_labels[0:10}
                    ^
SyntaxError: closing parenthesis '}' does not match opening parenthesis '['


In [106]: test_labels[0:10]
Out[106]: 
array([0.167, 0.278, 0.111, 0.278, 0.056, 0.278, 0.   , 0.   , 0.611,
       0.278])

In [107]: predictions[0:10]
Out[107]: 
array([[0.292],
       [0.332],
       [0.055],
       [0.311],
       [0.054],
       [0.33 ],
       [0.005],
       [0.003],
       [0.613],
       [0.277]], dtype=float32)

In [108]: chosen_model.save('saved_model/2021-04-07-model')
2021-04-07 14:40:30.958737: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
INFO:tensorflow:Assets written to: saved_model/2021-04-07-model/assets

In [109]: new_model = tf.keras.models.load_model('saved_model/2021-04-07-model')

In [110]: new_model.summary
Out[110]: <bound method Model.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x1ab5c4970>>

In [111]: new_model.summary()
Model: "sequential_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_56 (Dense)             (None, 300)               171600    
_________________________________________________________________
dense_57 (Dense)             (None, 300)               90300     
_________________________________________________________________
dense_58 (Dense)             (None, 300)               90300     
_________________________________________________________________
dense_59 (Dense)             (None, 300)               90300     
_________________________________________________________________
dense_60 (Dense)             (None, 1)                 301       
=================================================================
Total params: 442,801
Trainable params: 442,801
Non-trainable params: 0
_________________________________________________________________

In [112]: new_model.evaluate(test_boards, test_labels)
146/146 [==============================] - 0s 755us/step - loss: 0.0649
Out[112]: 0.06490730494260788

In [113]: soft_bigger_model7 = keras.Sequential([
     ...:       layers.Dense(300, activation='relu', input_shape = (571,)),
     ...:       layers.Dense(300, activation='relu'),
     ...:       layers.Dense(300, activation='relu'),
     ...:       layers.Dense(300, activation='relu'),
     ...:       layers.Softmax()
     ...:   ])
     ...: 

In [114]: soft_bigger_model7.compile(loss='mean_absolute_error',
     ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
     ...: 

In [115]: soft_bigger_history7 = soft_bigger_model7.fit(
     ...:     train_boards, train_labels,
     ...:     epochs=100,
     ...:     # Calculate validation results on 20% of the training data
     ...:     validation_split = 0.2)
     ...: 
Epoch 1/100
475/475 [==============================] - 2s 3ms/step - loss: 0.5248 - val_loss: 0.5182
Epoch 2/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5264 - val_loss: 0.5182
Epoch 3/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5272 - val_loss: 0.5182
Epoch 4/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5239 - val_loss: 0.5182
Epoch 5/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5256 - val_loss: 0.5182
Epoch 6/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5261 - val_loss: 0.5182
Epoch 7/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5213 - val_loss: 0.5182
Epoch 8/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5241 - val_loss: 0.5182
Epoch 9/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5245 - val_loss: 0.5182
Epoch 10/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5259 - val_loss: 0.5182
Epoch 11/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5245 - val_loss: 0.5182
Epoch 12/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5235 - val_loss: 0.5182
Epoch 13/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5252 - val_loss: 0.5182
Epoch 14/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5270 - val_loss: 0.5182
Epoch 15/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5249 - val_loss: 0.5182
Epoch 16/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5258 - val_loss: 0.5182
Epoch 17/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5271 - val_loss: 0.5182
Epoch 18/100
475/475 [==============================] - 2s 3ms/step - loss: 0.5241 - val_loss: 0.5182
Epoch 19/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5253 - val_loss: 0.5182
Epoch 20/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5263 - val_loss: 0.5182
Epoch 21/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5240 - val_loss: 0.5182
Epoch 22/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5248 - val_loss: 0.5182
Epoch 23/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5242 - val_loss: 0.5182
Epoch 24/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5255 - val_loss: 0.5182
Epoch 25/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5241 - val_loss: 0.5182
Epoch 26/100
377/475 [======================>.......] - ETA: 0s - loss: 0.5298^C---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
<ipython-input-115-7ec4e6f2ff96> in <module>
----> 1 soft_bigger_history7 = soft_bigger_model7.fit(
      2     train_boards, train_labels,
      3     epochs=100,
      4     # Calculate validation results on 20% of the training data
      5     validation_split = 0.2)

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1186               logs = tmp_logs  # No error, now safe to assign to logs.
   1187               end_step = step + data_handler.step_increment
-> 1188               callbacks.on_train_batch_end(end_step, logs)
   1189               if self.stop_training:
   1190                 break

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py in on_train_batch_end(self, batch, logs)
    454     """
    455     if self._should_call_train_batch_hooks:
--> 456       self._call_batch_hook(ModeKeys.TRAIN, 'end', batch, logs=logs)
    457 
    458   def on_test_batch_begin(self, batch, logs=None):

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py in _call_batch_hook(self, mode, hook, batch, logs)
    296       self._call_batch_begin_hook(mode, batch, logs)
    297     elif hook == 'end':
--> 298       self._call_batch_end_hook(mode, batch, logs)
    299     else:
    300       raise ValueError('Unrecognized hook: {}'.format(hook))

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py in _call_batch_end_hook(self, mode, batch, logs)
    316       self._batch_times.append(batch_time)
    317 
--> 318     self._call_batch_hook_helper(hook_name, batch, logs)
    319 
    320     if len(self._batch_times) >= self._num_batches_for_timing_check:

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py in _call_batch_hook_helper(self, hook_name, batch, logs)
    356       hook = getattr(callback, hook_name)
    357       if getattr(callback, '_supports_tf_logs', False):
--> 358         hook(batch, logs)
    359       else:
    360         if numpy_logs is None:  # Only convert once.

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py in on_train_batch_end(self, batch, logs)
   1062 
   1063   def on_train_batch_end(self, batch, logs=None):
-> 1064     self._batch_update_progbar(batch, logs)
   1065 
   1066   def on_test_batch_end(self, batch, logs=None):

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py in _batch_update_progbar(self, batch, logs)
   1126     if self.verbose == 1:
   1127       # Only block async when verbose = 1.
-> 1128       logs = tf_utils.sync_to_numpy_or_python_type(logs)
   1129       self.progbar.update(self.seen, list(logs.items()), finalize=False)
   1130 

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/keras/utils/tf_utils.py in sync_to_numpy_or_python_type(tensors)
    517     return t  # Don't turn ragged or sparse tensors to NumPy.
    518 
--> 519   return nest.map_structure(_to_single_numpy_or_python_type, tensors)
    520 
    521 

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/util/nest.py in map_structure(func, *structure, **kwargs)
    865 
    866   return pack_sequence_as(
--> 867       structure[0], [func(*x) for x in entries],
    868       expand_composites=expand_composites)
    869 

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/util/nest.py in <listcomp>(.0)
    865 
    866   return pack_sequence_as(
--> 867       structure[0], [func(*x) for x in entries],
    868       expand_composites=expand_composites)
    869 

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/keras/utils/tf_utils.py in _to_single_numpy_or_python_type(t)
    514     if isinstance(t, ops.Tensor):
    515       x = t.numpy()
--> 516       return x.item() if np.ndim(x) == 0 else x
    517     return t  # Don't turn ragged or sparse tensors to NumPy.
    518 

<__array_function__ internals> in ndim(*args, **kwargs)

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/numpy/core/fromnumeric.py in ndim(a)
   3137     shape : dimensions of array
   3138     ndarray.shape : dimensions of array
-> 3139     ndarray.size : number of elements in array
   3140 
   3141     Examples

KeyboardInterrupt: 

In [116]: soft_bigger_model7 = keras.Sequential([
     ...:       layers.Dense(300, activation='relu', input_shape = (571,)),
     ...:       layers.Dense(300, activation='relu'),
     ...:       layers.Dense(300, activation='relu'),
     ...:       layers.Dense(300, activation='softmax'),
     ...:   ])
     ...: 

In [117]: soft_bigger_model7.compile(loss='mean_absolute_error',
     ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
     ...: 

In [118]: soft_bigger_history7 = soft_bigger_model7.fit(
     ...:     train_boards, train_labels,
     ...:     epochs=100,
     ...:     # Calculate validation results on 20% of the training data
     ...:     validation_split = 0.2)
     ...: 
Epoch 1/100
475/475 [==============================] - 2s 3ms/step - loss: 0.5201 - val_loss: 0.5182
Epoch 2/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5263 - val_loss: 0.5182
Epoch 3/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5256 - val_loss: 0.5182
Epoch 4/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5244 - val_loss: 0.5182
Epoch 5/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5239 - val_loss: 0.5182
Epoch 6/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5273 - val_loss: 0.5182
Epoch 7/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5259 - val_loss: 0.5182
Epoch 8/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5253 - val_loss: 0.5182
Epoch 9/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5266 - val_loss: 0.5182
Epoch 10/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5275 - val_loss: 0.5182
Epoch 11/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5260 - val_loss: 0.5182
Epoch 12/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5239 - val_loss: 0.5182
Epoch 13/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5232 - val_loss: 0.5182
Epoch 14/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5249 - val_loss: 0.5182
Epoch 15/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5270 - val_loss: 0.5182
Epoch 16/100
475/475 [==============================] - 1s 2ms/step - loss: 0.5267 - val_loss: 0.5182
Epoch 17/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5257 - val_loss: 0.5182
Epoch 18/100
475/475 [==============================] - 1s 3ms/step - loss: 0.5243 - val_loss: 0.5182
Epoch 19/100
 65/475 [===>..........................] - ETA: 0s - loss: 0.5178^C---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
<ipython-input-118-7ec4e6f2ff96> in <module>
----> 1 soft_bigger_history7 = soft_bigger_model7.fit(
      2     train_boards, train_labels,
      3     epochs=100,
      4     # Calculate validation results on 20% of the training data
      5     validation_split = 0.2)

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1181                 _r=1):
   1182               callbacks.on_train_batch_begin(step)
-> 1183               tmp_logs = self.train_function(iterator)
   1184               if data_handler.should_sync:
   1185                 context.async_wait()

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    870     tracing_count = self.experimental_get_tracing_count()
    871     with trace.Trace(self._name) as tm:
--> 872       result = self._call(*args, **kwds)
    873       compiler = "xla" if self._jit_compile else "nonXla"
    874       new_tracing_count = self.experimental_get_tracing_count()

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    898       # In this case we have created variables on the first call, so we run the
    899       # defunned version which is guaranteed to never create variables.
--> 900       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
    901     elif self._stateful_fn is not None:
    902       # Release the lock early so that multiple threads can perform the call

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   3021       (graph_function,
   3022        filtered_flat_args) = self._maybe_define_function(args, kwargs)
-> 3023     return graph_function._call_flat(
   3024         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
   3025 

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1958         and executing_eagerly):
   1959       # No tape is watching; skip to running the function.
-> 1960       return self._build_call_outputs(self._inference_function.call(
   1961           ctx, args, cancellation_manager=cancellation_manager))
   1962     forward_backward = self._select_forward_and_backward_functions(

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    589       with _InterpolateFunctionError(self):
    590         if cancellation_manager is None:
--> 591           outputs = execute.execute(
    592               str(self.signature.name),
    593               num_outputs=self._num_outputs,

/usr/local/anaconda3/envs/sage/lib/python3.9/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     57   try:
     58     ctx.ensure_initialized()
---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:

KeyboardInterrupt: 

In [119]: relu_bigger_model7 = keras.Sequential([
     ...:       layers.Dense(300, activation='relu', input_shape = (571,)),
     ...:       layers.Dense(300, activation='relu'),
     ...:       layers.Dense(300, activation='relu'),
     ...:       layers.Dense(300, activation='relu'),
     ...:       layers.Dense(1)
     ...:       layers.ReLU(max_value=1.0)
     ...:   ])
     ...: 
  File "<ipython-input-119-740b607e6b61>", line 7
    layers.ReLU(max_value=1.0)
    ^
SyntaxError: invalid syntax


In [120]: relu_bigger_model7 = keras.Sequential([
     ...:       layers.Dense(300, activation='relu', input_shape = (571,)),
     ...:       layers.Dense(300, activation='relu'),
     ...:       layers.Dense(300, activation='relu'),
     ...:       layers.Dense(300, activation='relu'),
     ...:       layers.Dense(1),
     ...:       layers.ReLU(max_value=1.0)
     ...:   ])
     ...: 

In [121]: relu_bigger_model7.compile(loss='mean_absolute_error',
     ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
     ...: 

In [122]: relu_bigger_history7 = relu_bigger_model7.fit(
     ...:     train_boards, train_labels,
     ...:     epochs=100,
     ...:     # Calculate validation results on 20% of the training data
     ...:     validation_split = 0.2)
     ...: 
Epoch 1/100
475/475 [==============================] - 2s 3ms/step - loss: 0.1294 - val_loss: 0.0885
Epoch 2/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0633 - val_loss: 0.0755
Epoch 3/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0510 - val_loss: 0.0721
Epoch 4/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0449 - val_loss: 0.0721
Epoch 5/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0393 - val_loss: 0.0672
Epoch 6/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0365 - val_loss: 0.0680
Epoch 7/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0351 - val_loss: 0.0695
Epoch 8/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0316 - val_loss: 0.0666
Epoch 9/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0302 - val_loss: 0.0640
Epoch 10/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0290 - val_loss: 0.0648
Epoch 11/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0269 - val_loss: 0.0665
Epoch 12/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0256 - val_loss: 0.0648
Epoch 13/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0252 - val_loss: 0.0632
Epoch 14/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0237 - val_loss: 0.0628
Epoch 15/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0227 - val_loss: 0.0642
Epoch 16/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0224 - val_loss: 0.0628
Epoch 17/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0211 - val_loss: 0.0613
Epoch 18/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0209 - val_loss: 0.0629
Epoch 19/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0201 - val_loss: 0.0619
Epoch 20/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0186 - val_loss: 0.0604
Epoch 21/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0185 - val_loss: 0.0635
Epoch 22/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0178 - val_loss: 0.0626
Epoch 23/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0178 - val_loss: 0.0603
Epoch 24/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0175 - val_loss: 0.0606
Epoch 25/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0161 - val_loss: 0.0597
Epoch 26/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0162 - val_loss: 0.0617
Epoch 27/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0152 - val_loss: 0.0602
Epoch 28/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0158 - val_loss: 0.0592
Epoch 29/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0154 - val_loss: 0.0608
Epoch 30/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0146 - val_loss: 0.0605
Epoch 31/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0145 - val_loss: 0.0602
Epoch 32/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0142 - val_loss: 0.0593
Epoch 33/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0136 - val_loss: 0.0585
Epoch 34/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0138 - val_loss: 0.0594
Epoch 35/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0134 - val_loss: 0.0594
Epoch 36/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0125 - val_loss: 0.0594
Epoch 37/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0131 - val_loss: 0.0596
Epoch 38/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0127 - val_loss: 0.0604
Epoch 39/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0127 - val_loss: 0.0598
Epoch 40/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0122 - val_loss: 0.0598
Epoch 41/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0583
Epoch 42/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0116 - val_loss: 0.0592
Epoch 43/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0115 - val_loss: 0.0597
Epoch 44/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0594
Epoch 45/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0114 - val_loss: 0.0584
Epoch 46/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0111 - val_loss: 0.0600
Epoch 47/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0112 - val_loss: 0.0611
Epoch 48/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0115 - val_loss: 0.0602
Epoch 49/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0580
Epoch 50/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0101 - val_loss: 0.0593
Epoch 51/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0101 - val_loss: 0.0595
Epoch 52/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0101 - val_loss: 0.0595
Epoch 53/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0102 - val_loss: 0.0594
Epoch 54/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0096 - val_loss: 0.0593
Epoch 55/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0101 - val_loss: 0.0583
Epoch 56/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0094 - val_loss: 0.0603
Epoch 57/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0102 - val_loss: 0.0580
Epoch 58/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0097 - val_loss: 0.0581
Epoch 59/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0600
Epoch 60/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0094 - val_loss: 0.0585
Epoch 61/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0094 - val_loss: 0.0581
Epoch 62/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0097 - val_loss: 0.0591
Epoch 63/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0094 - val_loss: 0.0585
Epoch 64/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0090 - val_loss: 0.0573
Epoch 65/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0093 - val_loss: 0.0589
Epoch 66/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0592
Epoch 67/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.0596
Epoch 68/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.0598
Epoch 69/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0085 - val_loss: 0.0594
Epoch 70/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.0591
Epoch 71/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0084 - val_loss: 0.0607
Epoch 72/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0086 - val_loss: 0.0586
Epoch 73/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0594
Epoch 74/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0085 - val_loss: 0.0587
Epoch 75/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0578
Epoch 76/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0085 - val_loss: 0.0594
Epoch 77/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0085 - val_loss: 0.0601
Epoch 78/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0084 - val_loss: 0.0589
Epoch 79/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0081 - val_loss: 0.0596
Epoch 80/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0084 - val_loss: 0.0597
Epoch 81/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0076 - val_loss: 0.0586
Epoch 82/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.0581
Epoch 83/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0585
Epoch 84/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0593
Epoch 85/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0077 - val_loss: 0.0598
Epoch 86/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0075 - val_loss: 0.0594
Epoch 87/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0072 - val_loss: 0.0591
Epoch 88/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0077 - val_loss: 0.0590
Epoch 89/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.0592
Epoch 90/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0076 - val_loss: 0.0585
Epoch 91/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0072 - val_loss: 0.0586
Epoch 92/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0595
Epoch 93/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0080 - val_loss: 0.0590
Epoch 94/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0069 - val_loss: 0.0581
Epoch 95/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0075 - val_loss: 0.0583
Epoch 96/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0611
Epoch 97/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0075 - val_loss: 0.0599
Epoch 98/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0592
Epoch 99/100
475/475 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0589
Epoch 100/100
475/475 [==============================] - 1s 2ms/step - loss: 0.0073 - val_loss: 0.0593

In [123]: relu_bigger_model7.save('saved_model/2021-04-07-relu-model')
INFO:tensorflow:Assets written to: saved_model/2021-04-07-relu-model/assets

In [124]: less_data_model = keras.Sequential([
     ...:       layers.Dense(300, activation='relu', input_shape = (571,)),
     ...:       layers.Dense(300, activation='relu'),
     ...:       layers.Dense(300, activation='relu'),
     ...:       layers.Dense(300, activation='relu'),
     ...:       layers.Dense(1),
     ...:       layers.ReLU(max_value=1.0)
     ...:   ])
     ...: 

In [125]: less_data_model.compile(loss='mean_absolute_error',
     ...:                 optimizer=tf.keras.optimizers.Adam(0.001))
     ...: 

In [126]: less_data_history= less_data_model.fit(
     ...:     train_boards[:1000], train_labels[:1000],
     ...:     epochs=100,
     ...:     # Calculate validation results on 20% of the training data
     ...:     validation_split = 0.2)
     ...: 
Epoch 1/100
25/25 [==============================] - 1s 7ms/step - loss: 0.2827 - val_loss: 0.2432
Epoch 2/100
25/25 [==============================] - 0s 3ms/step - loss: 0.1142 - val_loss: 0.1205
Epoch 3/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0897 - val_loss: 0.1203
Epoch 4/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.1446
Epoch 5/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.1230
Epoch 6/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.1335
Epoch 7/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.1292
Epoch 8/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0450 - val_loss: 0.1319
Epoch 9/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0369 - val_loss: 0.1179
Epoch 10/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.1220
Epoch 11/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.1362
Epoch 12/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.1252
Epoch 13/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0342 - val_loss: 0.1276
Epoch 14/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.1222
Epoch 15/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.1208
Epoch 16/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.1126
Epoch 17/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.1325
Epoch 18/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.1213
Epoch 19/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.1189
Epoch 20/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.1301
Epoch 21/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.1114
Epoch 22/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.1120
Epoch 23/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.1252
Epoch 24/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.1121
Epoch 25/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.1208
Epoch 26/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.1290
Epoch 27/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.1211
Epoch 28/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.1230
Epoch 29/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.1212
Epoch 30/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.1212
Epoch 31/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.1139
Epoch 32/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.1211
Epoch 33/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.1199
Epoch 34/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.1121
Epoch 35/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.1250
Epoch 36/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.1077
Epoch 37/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.1159
Epoch 38/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.1177
Epoch 39/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.1183
Epoch 40/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.1157
Epoch 41/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.1118
Epoch 42/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.1141
Epoch 43/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1187
Epoch 44/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.1164
Epoch 45/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1135
Epoch 46/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.1247
Epoch 47/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.1162
Epoch 48/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.1255
Epoch 49/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.1172
Epoch 50/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.1138
Epoch 51/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.1193
Epoch 52/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1125
Epoch 53/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.1087
Epoch 54/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.1154
Epoch 55/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.1179
Epoch 56/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1204
Epoch 57/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.1144
Epoch 58/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.1179
Epoch 59/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1141
Epoch 60/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.1237
Epoch 61/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1181
Epoch 62/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.1129
Epoch 63/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1161
Epoch 64/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.1158
Epoch 65/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1164
Epoch 66/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.1223
Epoch 67/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.1185
Epoch 68/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.1158
Epoch 69/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1176
Epoch 70/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.1158
Epoch 71/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.1186
Epoch 72/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.1148
Epoch 73/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.1229
Epoch 74/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.1143
Epoch 75/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1201
Epoch 76/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.1120
Epoch 77/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.1186
Epoch 78/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1179
Epoch 79/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.1153
Epoch 80/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.1172
Epoch 81/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.1139
Epoch 82/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.1153
Epoch 83/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.1116
Epoch 84/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.1123
Epoch 85/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.1137
Epoch 86/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.1165
Epoch 87/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.1088
Epoch 88/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.1116
Epoch 89/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.1140
Epoch 90/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.1179
Epoch 91/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.1142
Epoch 92/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.1127
Epoch 93/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.1221
Epoch 94/100
25/25 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.1158
Epoch 95/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.1152
Epoch 96/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.1155
Epoch 97/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.1145
Epoch 98/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.1133
Epoch 99/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.1128
Epoch 100/100
25/25 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.1233

In [127]: less_data_model.evaluate(test_boards, test_labels)
146/146 [==============================] - 0s 747us/step - loss: 0.1194
Out[127]: 0.11936090886592865

In [128]: less_data_history= less_data_model.fit(
     ...:     train_boards[:5000], train_labels[:5000],
     ...:     epochs=100,
     ...:     # Calculate validation results on 20% of the training data
     ...:     validation_split = 0.2)
     ...: 
Epoch 1/100
125/125 [==============================] - 0s 3ms/step - loss: 0.0726 - val_loss: 0.0951
Epoch 2/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0859
Epoch 3/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0842
Epoch 4/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0347 - val_loss: 0.0817
Epoch 5/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.0785
Epoch 6/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0804
Epoch 7/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0796
Epoch 8/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0812
Epoch 9/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0792
Epoch 10/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0773
Epoch 11/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0805
Epoch 12/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0814
Epoch 13/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0788
Epoch 14/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0776
Epoch 15/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0789
Epoch 16/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0780
Epoch 17/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0794
Epoch 18/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0767
Epoch 19/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0776
Epoch 20/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0783
Epoch 21/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0769
Epoch 22/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0792
Epoch 23/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0754
Epoch 24/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0768
Epoch 25/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0774
Epoch 26/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0765
Epoch 27/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0775
Epoch 28/100
125/125 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0785
Epoch 29/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0762
Epoch 30/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0769
Epoch 31/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0772
Epoch 32/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0771
Epoch 33/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0768
Epoch 34/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0794
Epoch 35/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0761
Epoch 36/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0778
Epoch 37/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0777
Epoch 38/100
125/125 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0776
Epoch 39/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0758
Epoch 40/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0768
Epoch 41/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0776
Epoch 42/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0763
Epoch 43/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0761
Epoch 44/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0744
Epoch 45/100
125/125 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0771
Epoch 46/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0770
Epoch 47/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0716
Epoch 48/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0742
Epoch 49/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0773
Epoch 50/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.0753
Epoch 51/100
125/125 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0765
Epoch 52/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0763
Epoch 53/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0756
Epoch 54/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0762
Epoch 55/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0763
Epoch 56/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0760
Epoch 57/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0754
Epoch 58/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0769
Epoch 59/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0752
Epoch 60/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0750
Epoch 61/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0753
Epoch 62/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0738
Epoch 63/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0748
Epoch 64/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0746
Epoch 65/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0746
Epoch 66/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0758
Epoch 67/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0770
Epoch 68/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0748
Epoch 69/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0752
Epoch 70/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0747
Epoch 71/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0762
Epoch 72/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0755
Epoch 73/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0755
Epoch 74/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0768
Epoch 75/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0749
Epoch 76/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0745
Epoch 77/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0760
Epoch 78/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0773
Epoch 79/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0781
Epoch 80/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0749
Epoch 81/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0779
Epoch 82/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0776
Epoch 83/100
125/125 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0736
Epoch 84/100
125/125 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0783
Epoch 85/100
125/125 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0757
Epoch 86/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0793
Epoch 87/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0763
Epoch 88/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0773
Epoch 89/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0773
Epoch 90/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0782
Epoch 91/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0745
Epoch 92/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0758
Epoch 93/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0757
Epoch 94/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0750
Epoch 95/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0757
Epoch 96/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0739
Epoch 97/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0760
Epoch 98/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0751
Epoch 99/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0757
Epoch 100/100
125/125 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0749

In [129]: less_data_model.evaluate(test_boards, test_labels)
146/146 [==============================] - 0s 882us/step - loss: 0.0860
Out[129]: 0.08600863814353943

In [130]: from Board import main
---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-130-9f5a9a88b41f> in <module>
----> 1 from Board import main

ModuleNotFoundError: No module named 'Board'

In [131]: from main import Board

In [132]: b = Board

In [133]: l = ['G8', 'G7', 'F8', 'E5', 'I11', 'I9', 'SE ', 'J11', 'W NW N ', 'C5', 'F9', 'H9', 'G10', 'B3', 'I12', 'B
     ...: 6', 'K14', 'M14', 'L15', 'M15', 'M16', 'N16', 'N15', 'N14', 'SE SE SE W NE S ', 'N14', 'W ', 'N12', 'W ', '
     ...: D4', 'N12', 'E ', 'N14', 'E ', 'N16', 'F2']

In [134]: for i in l:
     ...:     b = b.get_all_moves()[i]
     ...: 
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-134-f5d341e81a6a> in <module>
      1 for i in l:
----> 2     b = b.get_all_moves()[i]
      3 

TypeError: get_all_moves() missing 1 required positional argument: 'self'

In [135]: b
Out[135]: main.Board

In [136]: b = Board()

In [137]: for i in l:
     ...:     b = b.get_all_moves()[i]
     ...: 

In [138]: b
Out[138]: <main.Board at 0x1ab985220>

In [139]: b.pretty_print_details()
          1111111111
 1234567890123456789
A+++++++++++++++++++
B+++++++++++++++++
C++++++++++++++++++
D++++++++++++++++++
E++++++++++++++++++
F++++++++++++++++++
G++++++++++++++++++
H++++++++++++++++++
I+++++++++++++++++++
J+++++++++++++++++++
K+++++++++++++++++++
L+++++++++++++++++++
M+++++++++++++++++++
N+++++++++++++++++
O+++++++++++++++++++
Side to move: Left
Moves made: 36
Ball at: [13 14]


In [140]: vec = b.get_vector()

In [141]: vec
Out[141]: 
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])

In [142]: vec = vec[np.newaxis, ...]  # Needs to be 2d

In [143]: vec
Out[143]: 
array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])

In [144]: less_data_model.predict(vec)
Out[144]: array([[0.461]], dtype=float32)

In [145]: bigger_model7.predict(vec)
Out[145]: array([[0.028]], dtype=float32)

In [146]: b = Board

In [147]: b = Board()

In [148]: l = ['H9', 'I7', 'I9', 'I12', 'W SE ', 'H9', 'L11', 'J5', 'J3', 'L2', 'K8', 'K5', 'N10', 'I5', 'G9', 'G3',
     ...: 'M13', 'E1', 'N14', 'C2', 'O8', 'B2', 'N9', 'B3', 'B5', 'A1', 'C7', 'A2', 'N6', 'A3', 'I8', 'B1', 'G14', 'C
     ...: 1', 'M6', 'C3', 'E8', 'A4', 'F13', 'B4', 'K11', 'D2', 'O5', 'C4', 'O10', 'B6', 'H1', 'A6', 'K14', 'B8', 'B7
     ...: ', 'A5', 'I14', 'A8', 'N13', 'D3', 'M12', 'C8', 'J11', 'B10', 'F10', 'A9', 'E15', 'B9', 'I13', 'C11', 'D11'
     ...: , 'D4', 'E N SE S SW ', 'E2', 'C9', 'D9', 'H14', 'E3', 'N15', 'B12', 'L8', 'D13', 'L13', 'D6', 'B13', 'F2',
     ...:  'F17', 'C10', 'C12', 'E4', 'D17', 'E11', 'C18', 'F3', 'D7', 'F4', 'M13', 'F8', 'F14', 'E12', 'A13', 'D14',
     ...:  'B15', 'G4', 'I15', 'A12', 'E13', 'F15', 'B14', 'E6', 'K7', 'G6', 'K17', 'C16', 'B11', 'H2', 'C15', 'F12',
     ...:  'C13', 'C17', 'K18', 'H3', 'C14', 'A15', 'M7', 'E10', 'M19', 'H6', 'M5', 'G5', 'D16', 'I2', 'E16', 'F6', '
     ...: H11', 'I3', 'D8', 'C6', 'K16', 'D10', 'K15']

In [149]: for i in l:
     ...:     b = b.get_all_moves()[i]
     ...: 

In [150]: b.pretty_print_details()
          1111111111
 1234567890123456789
A++++++++
B++++
C++
D++++++
E+++++++
F++++++++
G+++++++++++++
H++++++++++++
I++++++++++++
J+++++++++++++++++
K+++++++++++
L+++++++++++++++
M+++++++++++++
N++++++++++++
O++++++++++++++++
Side to move: Right
Moves made: 137
Ball at: [13 11]


In [151]: b.get_all_moves()
# About a million moves or more, takes too long to run
