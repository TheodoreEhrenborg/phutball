{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bridal-history",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "corporate-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "satisfactory-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accomplished-photograph",
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-75bd087eb183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2021-05-06-3ply-boards3.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mboard_pairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "board_pairs = []\n",
    "with open(\"2021-05-06-3ply-boards3.pickle\", \"rb\") as f:\n",
    "    while True:\n",
    "        board_pairs.append(pickle.load(f))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "horizontal-purpose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32835"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(board_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pretty-album",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<main.Board at 0x109e1ea60>, 0.9444444444444444)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "placed-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = board_pairs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "written-storm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1111111111\n",
      " 1234567890123456789\n",
      "A+++++++++++++++++○+\n",
      "B+++++++++++++++++++\n",
      "C+++++++++++++++++++\n",
      "D+++++++++++++++++++\n",
      "E+++++++++++++++++++\n",
      "F+++●+++++++++++++++\n",
      "G++++++++++++++++○++\n",
      "H+++++++++○+++++++++\n",
      "I+++++++++++++++++++\n",
      "J+○+++++++++++++++++\n",
      "K+++++++++++++++++++\n",
      "L+++++++++++++++++++\n",
      "M+++++++++++++++++++\n",
      "N++++++++++++++○++++\n",
      "O+++++++++++++++++++\n",
      "Side to move: Right\n",
      "Moves made: 0\n",
      "Ball at: [5 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b.pretty_print_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abstract-philadelphia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.get_flipped_3d_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "perfect-final",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<main.Board at 0x17aacb730>, 1.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board_pairs[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "illegal-better",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1111111111\n",
      " 1234567890123456789\n",
      "A+++++++++++++++++++\n",
      "B+++++++++++++++○+++\n",
      "C+++++++++++○+++++++\n",
      "D+++++++++++++++++++\n",
      "E+++++++++++++++++++\n",
      "F++++++++○++++++++++\n",
      "G+++++++++++++++++++\n",
      "H+++++++++++++++++++\n",
      "I+++++++++○+++++++++\n",
      "J+++++++++++++++++++\n",
      "K+++++++++++++++++++\n",
      "L+++++++++++++++++++\n",
      "M+++++++++++++++++++\n",
      "N++++++++++++++++●++\n",
      "O+++++++++++++++++++\n",
      "Side to move: Left\n",
      "Moves made: 0\n",
      "Ball at: [13 16]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "board_pairs[8][0].pretty_print_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "friendly-bulgaria",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board_pairs[8][0].get_flipped_3d_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-machine",
   "metadata": {},
   "source": [
    "So we see that the array is flipped only for Right players. In both of the above cases, the target value is near 1 (0.94 and 1.0), and the ball is far to the Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "latter-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "for p in board_pairs:\n",
    "    inputs.append(p[0].get_flipped_3d_array().flatten())\n",
    "    outputs.append(p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "center-simon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32835"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "clinical-invention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32835"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "naval-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "corporate-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "solved-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.array(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "after-galaxy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32835, 570)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "comparable-corpus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32835,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "amber-patrol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19701.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(board_pairs) * 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abandoned-vertex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26268.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(board_pairs) * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "furnished-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = inputs[:26268]\n",
    "train_outputs = outputs[:26268]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "beneficial-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = inputs[26268:]\n",
    "test_outputs = outputs[26268:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "regional-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "integral-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([layers.Dense(128, activation='relu',input_shape = (570,)),layers.Dense(1) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bronze-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_absolute_error',optimizer=tf.keras.optimizers.Adam(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adolescent-sugar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128)               73088     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 73,217\n",
      "Trainable params: 73,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fatal-folder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2066 - val_loss: 0.0919\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 1s 827us/step - loss: 0.0739 - val_loss: 0.0762\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 1s 811us/step - loss: 0.0600 - val_loss: 0.0695\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 1s 821us/step - loss: 0.0526 - val_loss: 0.0679\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 1s 849us/step - loss: 0.0488 - val_loss: 0.0667\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 1s 847us/step - loss: 0.0450 - val_loss: 0.0682\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 1s 835us/step - loss: 0.0426 - val_loss: 0.0674\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 1s 832us/step - loss: 0.0406 - val_loss: 0.0659\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 1s 888us/step - loss: 0.0374 - val_loss: 0.0662\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 1s 820us/step - loss: 0.0364 - val_loss: 0.0662\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 1s 813us/step - loss: 0.0346 - val_loss: 0.0660\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 1s 818us/step - loss: 0.0339 - val_loss: 0.0669\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 1s 806us/step - loss: 0.0323 - val_loss: 0.0660\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 1s 806us/step - loss: 0.0306 - val_loss: 0.0663\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 1s 831us/step - loss: 0.0300 - val_loss: 0.0673\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 1s 808us/step - loss: 0.0288 - val_loss: 0.0659\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - 1s 785us/step - loss: 0.0283 - val_loss: 0.0674\n",
      "Epoch 18/100\n",
      "657/657 [==============================] - 1s 893us/step - loss: 0.0269 - val_loss: 0.0667\n",
      "Epoch 19/100\n",
      "657/657 [==============================] - 1s 853us/step - loss: 0.0262 - val_loss: 0.0661\n",
      "Epoch 20/100\n",
      "657/657 [==============================] - 1s 887us/step - loss: 0.0264 - val_loss: 0.0675\n",
      "Epoch 21/100\n",
      "657/657 [==============================] - 1s 829us/step - loss: 0.0252 - val_loss: 0.0658\n",
      "Epoch 22/100\n",
      "657/657 [==============================] - 1s 819us/step - loss: 0.0244 - val_loss: 0.0660\n",
      "Epoch 23/100\n",
      "657/657 [==============================] - 1s 829us/step - loss: 0.0239 - val_loss: 0.0676\n",
      "Epoch 24/100\n",
      "657/657 [==============================] - 1s 825us/step - loss: 0.0236 - val_loss: 0.0662\n",
      "Epoch 25/100\n",
      "657/657 [==============================] - 1s 852us/step - loss: 0.0233 - val_loss: 0.0661\n",
      "Epoch 26/100\n",
      "657/657 [==============================] - 1s 822us/step - loss: 0.0230 - val_loss: 0.0666\n",
      "Epoch 27/100\n",
      "657/657 [==============================] - 1s 818us/step - loss: 0.0223 - val_loss: 0.0660\n",
      "Epoch 28/100\n",
      "657/657 [==============================] - 1s 834us/step - loss: 0.0221 - val_loss: 0.0655\n",
      "Epoch 29/100\n",
      "657/657 [==============================] - 1s 894us/step - loss: 0.0216 - val_loss: 0.0659\n",
      "Epoch 30/100\n",
      "657/657 [==============================] - 1s 856us/step - loss: 0.0217 - val_loss: 0.0662\n",
      "Epoch 31/100\n",
      "657/657 [==============================] - 1s 837us/step - loss: 0.0210 - val_loss: 0.0682\n",
      "Epoch 32/100\n",
      "657/657 [==============================] - 1s 817us/step - loss: 0.0210 - val_loss: 0.0670\n",
      "Epoch 33/100\n",
      "657/657 [==============================] - 1s 829us/step - loss: 0.0210 - val_loss: 0.0671\n",
      "Epoch 34/100\n",
      "657/657 [==============================] - 1s 809us/step - loss: 0.0201 - val_loss: 0.0664\n",
      "Epoch 35/100\n",
      "657/657 [==============================] - 1s 837us/step - loss: 0.0205 - val_loss: 0.0654\n",
      "Epoch 36/100\n",
      "657/657 [==============================] - 1s 827us/step - loss: 0.0198 - val_loss: 0.0664\n",
      "Epoch 37/100\n",
      "657/657 [==============================] - 1s 809us/step - loss: 0.0197 - val_loss: 0.0668\n",
      "Epoch 38/100\n",
      "657/657 [==============================] - 1s 816us/step - loss: 0.0198 - val_loss: 0.0666\n",
      "Epoch 39/100\n",
      "657/657 [==============================] - 1s 813us/step - loss: 0.0194 - val_loss: 0.0654\n",
      "Epoch 40/100\n",
      "657/657 [==============================] - 1s 838us/step - loss: 0.0192 - val_loss: 0.0674\n",
      "Epoch 41/100\n",
      "657/657 [==============================] - 1s 812us/step - loss: 0.0195 - val_loss: 0.0661\n",
      "Epoch 42/100\n",
      "657/657 [==============================] - 1s 890us/step - loss: 0.0186 - val_loss: 0.0667\n",
      "Epoch 43/100\n",
      "657/657 [==============================] - 1s 927us/step - loss: 0.0187 - val_loss: 0.0667\n",
      "Epoch 44/100\n",
      "657/657 [==============================] - 1s 848us/step - loss: 0.0185 - val_loss: 0.0674\n",
      "Epoch 45/100\n",
      "657/657 [==============================] - 1s 825us/step - loss: 0.0185 - val_loss: 0.0663\n",
      "Epoch 46/100\n",
      "657/657 [==============================] - 1s 837us/step - loss: 0.0184 - val_loss: 0.0663\n",
      "Epoch 47/100\n",
      "657/657 [==============================] - 1s 826us/step - loss: 0.0175 - val_loss: 0.0658\n",
      "Epoch 48/100\n",
      "657/657 [==============================] - 1s 815us/step - loss: 0.0178 - val_loss: 0.0669\n",
      "Epoch 49/100\n",
      "657/657 [==============================] - 1s 859us/step - loss: 0.0176 - val_loss: 0.0657\n",
      "Epoch 50/100\n",
      "657/657 [==============================] - 1s 874us/step - loss: 0.0175 - val_loss: 0.0656\n",
      "Epoch 51/100\n",
      "657/657 [==============================] - 1s 817us/step - loss: 0.0175 - val_loss: 0.0656\n",
      "Epoch 52/100\n",
      "657/657 [==============================] - 1s 815us/step - loss: 0.0172 - val_loss: 0.0660\n",
      "Epoch 53/100\n",
      "657/657 [==============================] - 1s 827us/step - loss: 0.0169 - val_loss: 0.0654\n",
      "Epoch 54/100\n",
      "657/657 [==============================] - 1s 876us/step - loss: 0.0168 - val_loss: 0.0655\n",
      "Epoch 55/100\n",
      "657/657 [==============================] - 1s 864us/step - loss: 0.0170 - val_loss: 0.0655\n",
      "Epoch 56/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0170 - val_loss: 0.0657\n",
      "Epoch 57/100\n",
      "657/657 [==============================] - 1s 952us/step - loss: 0.0165 - val_loss: 0.0666\n",
      "Epoch 58/100\n",
      "657/657 [==============================] - 1s 835us/step - loss: 0.0170 - val_loss: 0.0659\n",
      "Epoch 59/100\n",
      "657/657 [==============================] - 1s 871us/step - loss: 0.0169 - val_loss: 0.0661\n",
      "Epoch 60/100\n",
      "657/657 [==============================] - 1s 837us/step - loss: 0.0165 - val_loss: 0.0652\n",
      "Epoch 61/100\n",
      "657/657 [==============================] - 1s 883us/step - loss: 0.0165 - val_loss: 0.0657\n",
      "Epoch 62/100\n",
      "657/657 [==============================] - 1s 833us/step - loss: 0.0158 - val_loss: 0.0663\n",
      "Epoch 63/100\n",
      "657/657 [==============================] - 1s 819us/step - loss: 0.0159 - val_loss: 0.0663\n",
      "Epoch 64/100\n",
      "657/657 [==============================] - 1s 809us/step - loss: 0.0164 - val_loss: 0.0653\n",
      "Epoch 65/100\n",
      "657/657 [==============================] - 1s 815us/step - loss: 0.0161 - val_loss: 0.0651\n",
      "Epoch 66/100\n",
      "657/657 [==============================] - 1s 803us/step - loss: 0.0156 - val_loss: 0.0658\n",
      "Epoch 67/100\n",
      "657/657 [==============================] - 1s 811us/step - loss: 0.0158 - val_loss: 0.0659\n",
      "Epoch 68/100\n",
      "657/657 [==============================] - 1s 838us/step - loss: 0.0161 - val_loss: 0.0653\n",
      "Epoch 69/100\n",
      "657/657 [==============================] - 1s 819us/step - loss: 0.0153 - val_loss: 0.0649\n",
      "Epoch 70/100\n",
      "657/657 [==============================] - 1s 839us/step - loss: 0.0155 - val_loss: 0.0657\n",
      "Epoch 71/100\n",
      "657/657 [==============================] - 1s 821us/step - loss: 0.0153 - val_loss: 0.0656\n",
      "Epoch 72/100\n",
      "657/657 [==============================] - 1s 854us/step - loss: 0.0150 - val_loss: 0.0653\n",
      "Epoch 73/100\n",
      "657/657 [==============================] - 1s 981us/step - loss: 0.0151 - val_loss: 0.0659\n",
      "Epoch 74/100\n",
      "657/657 [==============================] - 1s 974us/step - loss: 0.0151 - val_loss: 0.0657\n",
      "Epoch 75/100\n",
      "657/657 [==============================] - 1s 910us/step - loss: 0.0151 - val_loss: 0.0687\n",
      "Epoch 76/100\n",
      "657/657 [==============================] - 1s 825us/step - loss: 0.0150 - val_loss: 0.0657\n",
      "Epoch 77/100\n",
      "657/657 [==============================] - 1s 839us/step - loss: 0.0152 - val_loss: 0.0652\n",
      "Epoch 78/100\n",
      "657/657 [==============================] - 1s 967us/step - loss: 0.0150 - val_loss: 0.0661\n",
      "Epoch 79/100\n",
      "657/657 [==============================] - 1s 856us/step - loss: 0.0148 - val_loss: 0.0653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "657/657 [==============================] - 1s 942us/step - loss: 0.0148 - val_loss: 0.0661\n",
      "Epoch 81/100\n",
      "657/657 [==============================] - 1s 848us/step - loss: 0.0146 - val_loss: 0.0651\n",
      "Epoch 82/100\n",
      "657/657 [==============================] - 1s 881us/step - loss: 0.0146 - val_loss: 0.0650\n",
      "Epoch 83/100\n",
      "657/657 [==============================] - 1s 944us/step - loss: 0.0148 - val_loss: 0.0661\n",
      "Epoch 84/100\n",
      "657/657 [==============================] - 1s 958us/step - loss: 0.0144 - val_loss: 0.0661\n",
      "Epoch 85/100\n",
      "657/657 [==============================] - 1s 832us/step - loss: 0.0146 - val_loss: 0.0647\n",
      "Epoch 86/100\n",
      "657/657 [==============================] - 1s 836us/step - loss: 0.0143 - val_loss: 0.0648\n",
      "Epoch 87/100\n",
      "657/657 [==============================] - 1s 826us/step - loss: 0.0143 - val_loss: 0.0654\n",
      "Epoch 88/100\n",
      "657/657 [==============================] - 1s 837us/step - loss: 0.0144 - val_loss: 0.0651\n",
      "Epoch 89/100\n",
      "657/657 [==============================] - 1s 894us/step - loss: 0.0142 - val_loss: 0.0650\n",
      "Epoch 90/100\n",
      "657/657 [==============================] - 1s 851us/step - loss: 0.0143 - val_loss: 0.0649\n",
      "Epoch 91/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0141 - val_loss: 0.0654\n",
      "Epoch 92/100\n",
      "657/657 [==============================] - 1s 830us/step - loss: 0.0141 - val_loss: 0.0660\n",
      "Epoch 93/100\n",
      "657/657 [==============================] - 1s 920us/step - loss: 0.0141 - val_loss: 0.0655\n",
      "Epoch 94/100\n",
      "657/657 [==============================] - 1s 860us/step - loss: 0.0141 - val_loss: 0.0647\n",
      "Epoch 95/100\n",
      "657/657 [==============================] - 1s 849us/step - loss: 0.0141 - val_loss: 0.0653\n",
      "Epoch 96/100\n",
      "657/657 [==============================] - 1s 828us/step - loss: 0.0136 - val_loss: 0.0652\n",
      "Epoch 97/100\n",
      "657/657 [==============================] - 1s 970us/step - loss: 0.0139 - val_loss: 0.0654\n",
      "Epoch 98/100\n",
      "657/657 [==============================] - 1s 912us/step - loss: 0.0135 - val_loss: 0.0653\n",
      "Epoch 99/100\n",
      "657/657 [==============================] - 1s 847us/step - loss: 0.0141 - val_loss: 0.0653\n",
      "Epoch 100/100\n",
      "657/657 [==============================] - 1s 822us/step - loss: 0.0137 - val_loss: 0.0656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x185823d60>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_inputs, train_outputs, epochs=100, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-tuning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "offensive-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential([layers.Dense(256, activation='relu',input_shape = (570,)),layers.Dense(256, activation='relu'),layers.Dense(1) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "hairy-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='mean_absolute_error',optimizer=tf.keras.optimizers.Adam(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "complimentary-guatemala",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               146176    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 212,225\n",
      "Trainable params: 212,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "electrical-venue",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.1878 - val_loss: 0.0812\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0701 - val_loss: 0.0708\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0577 - val_loss: 0.0672\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0521 - val_loss: 0.0720\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0491 - val_loss: 0.0673\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0446 - val_loss: 0.0650\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0426 - val_loss: 0.0646\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0387 - val_loss: 0.0642\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0370 - val_loss: 0.0655\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0350 - val_loss: 0.0642\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0339 - val_loss: 0.0645\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0314 - val_loss: 0.0645\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0304 - val_loss: 0.0639\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0299 - val_loss: 0.0639\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0288 - val_loss: 0.0633\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0272 - val_loss: 0.0631\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0265 - val_loss: 0.0626\n",
      "Epoch 18/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0256 - val_loss: 0.0629\n",
      "Epoch 19/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0245 - val_loss: 0.0634\n",
      "Epoch 20/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0241 - val_loss: 0.0629\n",
      "Epoch 21/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0236 - val_loss: 0.0629\n",
      "Epoch 22/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0231 - val_loss: 0.0629\n",
      "Epoch 23/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0226 - val_loss: 0.0631\n",
      "Epoch 24/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0221 - val_loss: 0.0624\n",
      "Epoch 25/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0214 - val_loss: 0.0621\n",
      "Epoch 26/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0215 - val_loss: 0.0624\n",
      "Epoch 27/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0208 - val_loss: 0.0617\n",
      "Epoch 28/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0199 - val_loss: 0.0617\n",
      "Epoch 29/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0197 - val_loss: 0.0629\n",
      "Epoch 30/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0200 - val_loss: 0.0617\n",
      "Epoch 31/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0190 - val_loss: 0.0614\n",
      "Epoch 32/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0188 - val_loss: 0.0618\n",
      "Epoch 33/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0186 - val_loss: 0.0610\n",
      "Epoch 34/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0181 - val_loss: 0.0614\n",
      "Epoch 35/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0179 - val_loss: 0.0609\n",
      "Epoch 36/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0175 - val_loss: 0.0619\n",
      "Epoch 37/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0172 - val_loss: 0.0611\n",
      "Epoch 38/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0173 - val_loss: 0.0607\n",
      "Epoch 39/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0167 - val_loss: 0.0606\n",
      "Epoch 40/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0164 - val_loss: 0.0612\n",
      "Epoch 41/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0167 - val_loss: 0.0609\n",
      "Epoch 42/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0162 - val_loss: 0.0607\n",
      "Epoch 43/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0159 - val_loss: 0.0613\n",
      "Epoch 44/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0163 - val_loss: 0.0603\n",
      "Epoch 45/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0155 - val_loss: 0.0606\n",
      "Epoch 46/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0156 - val_loss: 0.0601\n",
      "Epoch 47/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0154 - val_loss: 0.0602\n",
      "Epoch 48/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0151 - val_loss: 0.0614\n",
      "Epoch 49/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0152 - val_loss: 0.0599\n",
      "Epoch 50/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0153 - val_loss: 0.0605\n",
      "Epoch 51/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0147 - val_loss: 0.0603\n",
      "Epoch 52/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0147 - val_loss: 0.0598\n",
      "Epoch 53/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0149 - val_loss: 0.0599\n",
      "Epoch 54/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0144 - val_loss: 0.0602\n",
      "Epoch 55/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0143 - val_loss: 0.0603\n",
      "Epoch 56/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0143 - val_loss: 0.0596\n",
      "Epoch 57/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0138 - val_loss: 0.0602\n",
      "Epoch 58/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0138 - val_loss: 0.0607\n",
      "Epoch 59/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0135 - val_loss: 0.0602\n",
      "Epoch 60/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0137 - val_loss: 0.0596\n",
      "Epoch 61/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0134 - val_loss: 0.0610\n",
      "Epoch 62/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0133 - val_loss: 0.0594\n",
      "Epoch 63/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0131 - val_loss: 0.0606\n",
      "Epoch 64/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0133 - val_loss: 0.0599\n",
      "Epoch 65/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0133 - val_loss: 0.0596\n",
      "Epoch 66/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0127 - val_loss: 0.0596\n",
      "Epoch 67/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0129 - val_loss: 0.0598\n",
      "Epoch 68/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0128 - val_loss: 0.0611\n",
      "Epoch 69/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0131 - val_loss: 0.0600\n",
      "Epoch 70/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0128 - val_loss: 0.0595\n",
      "Epoch 71/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0127 - val_loss: 0.0592\n",
      "Epoch 72/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0124 - val_loss: 0.0591\n",
      "Epoch 73/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0122 - val_loss: 0.0614\n",
      "Epoch 74/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0125 - val_loss: 0.0597\n",
      "Epoch 75/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0121 - val_loss: 0.0593\n",
      "Epoch 76/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0118 - val_loss: 0.0593\n",
      "Epoch 77/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0119 - val_loss: 0.0590\n",
      "Epoch 78/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0118 - val_loss: 0.0593\n",
      "Epoch 79/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0119 - val_loss: 0.0596\n",
      "Epoch 80/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0118 - val_loss: 0.0596\n",
      "Epoch 81/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0118 - val_loss: 0.0590\n",
      "Epoch 82/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0116 - val_loss: 0.0590\n",
      "Epoch 83/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0117 - val_loss: 0.0599\n",
      "Epoch 84/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0115 - val_loss: 0.0588\n",
      "Epoch 85/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0116 - val_loss: 0.0599\n",
      "Epoch 86/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0114 - val_loss: 0.0591\n",
      "Epoch 87/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0113 - val_loss: 0.0590\n",
      "Epoch 88/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0113 - val_loss: 0.0595\n",
      "Epoch 89/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0112 - val_loss: 0.0588\n",
      "Epoch 90/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0113 - val_loss: 0.0595\n",
      "Epoch 91/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0112 - val_loss: 0.0586\n",
      "Epoch 92/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0114 - val_loss: 0.0589\n",
      "Epoch 93/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0111 - val_loss: 0.0598\n",
      "Epoch 94/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0109 - val_loss: 0.0590\n",
      "Epoch 95/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0110 - val_loss: 0.0599\n",
      "Epoch 96/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0112 - val_loss: 0.0595\n",
      "Epoch 97/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0111 - val_loss: 0.0600\n",
      "Epoch 98/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0106 - val_loss: 0.0593\n",
      "Epoch 99/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0111 - val_loss: 0.0594\n",
      "Epoch 100/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0107 - val_loss: 0.0595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x185f36220>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_inputs, train_outputs, epochs=100, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "buried-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.Sequential([layers.Dense(256, activation='relu',input_shape = (570,)),layers.Dropout(0.2),layers.Dense(256, activation='relu'),layers.Dense(1) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "coastal-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='mean_absolute_error',optimizer=tf.keras.optimizers.Adam(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "explicit-majority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 256)               146176    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 212,225\n",
      "Trainable params: 212,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "known-birthday",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2087 - val_loss: 0.0899\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0857 - val_loss: 0.0706\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0705 - val_loss: 0.0685\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0626 - val_loss: 0.0679\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0572 - val_loss: 0.0654\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0548 - val_loss: 0.0641\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0515 - val_loss: 0.0655\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0496 - val_loss: 0.0632\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0475 - val_loss: 0.0671\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0470 - val_loss: 0.0635\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0446 - val_loss: 0.0629\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0439 - val_loss: 0.0637\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0426 - val_loss: 0.0642\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0416 - val_loss: 0.0628\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0393 - val_loss: 0.0610\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0395 - val_loss: 0.0615\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0380 - val_loss: 0.0630\n",
      "Epoch 18/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0375 - val_loss: 0.0610\n",
      "Epoch 19/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0368 - val_loss: 0.0634\n",
      "Epoch 20/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0360 - val_loss: 0.0613\n",
      "Epoch 21/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0358 - val_loss: 0.0615\n",
      "Epoch 22/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0356 - val_loss: 0.0625\n",
      "Epoch 23/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0341 - val_loss: 0.0625\n",
      "Epoch 24/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0336 - val_loss: 0.0608\n",
      "Epoch 25/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0337 - val_loss: 0.0608\n",
      "Epoch 26/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0330 - val_loss: 0.0607\n",
      "Epoch 27/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0322 - val_loss: 0.0615\n",
      "Epoch 28/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0319 - val_loss: 0.0614\n",
      "Epoch 29/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0318 - val_loss: 0.0599\n",
      "Epoch 30/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0315 - val_loss: 0.0600\n",
      "Epoch 31/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0310 - val_loss: 0.0619\n",
      "Epoch 32/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0313 - val_loss: 0.0600\n",
      "Epoch 33/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0299 - val_loss: 0.0612\n",
      "Epoch 34/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0302 - val_loss: 0.0602\n",
      "Epoch 35/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0298 - val_loss: 0.0622\n",
      "Epoch 36/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0300 - val_loss: 0.0606\n",
      "Epoch 37/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0293 - val_loss: 0.0593\n",
      "Epoch 38/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0292 - val_loss: 0.0595\n",
      "Epoch 39/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0287 - val_loss: 0.0619\n",
      "Epoch 40/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0286 - val_loss: 0.0596\n",
      "Epoch 41/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0279 - val_loss: 0.0592\n",
      "Epoch 42/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0280 - val_loss: 0.0589\n",
      "Epoch 43/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0275 - val_loss: 0.0608\n",
      "Epoch 44/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0276 - val_loss: 0.0590\n",
      "Epoch 45/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0275 - val_loss: 0.0587\n",
      "Epoch 46/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0274 - val_loss: 0.0597\n",
      "Epoch 47/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0270 - val_loss: 0.0591\n",
      "Epoch 48/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0267 - val_loss: 0.0594\n",
      "Epoch 49/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0271 - val_loss: 0.0581\n",
      "Epoch 50/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0263 - val_loss: 0.0588\n",
      "Epoch 51/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0263 - val_loss: 0.0590\n",
      "Epoch 52/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0262 - val_loss: 0.0603\n",
      "Epoch 53/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0263 - val_loss: 0.0594\n",
      "Epoch 54/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0257 - val_loss: 0.0606\n",
      "Epoch 55/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0257 - val_loss: 0.0596\n",
      "Epoch 56/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0255 - val_loss: 0.0589\n",
      "Epoch 57/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0252 - val_loss: 0.0590\n",
      "Epoch 58/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0256 - val_loss: 0.0585\n",
      "Epoch 59/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0253 - val_loss: 0.0593\n",
      "Epoch 60/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0249 - val_loss: 0.0598\n",
      "Epoch 61/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0252 - val_loss: 0.0584\n",
      "Epoch 62/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0248 - val_loss: 0.0588\n",
      "Epoch 63/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0248 - val_loss: 0.0597\n",
      "Epoch 64/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0246 - val_loss: 0.0585\n",
      "Epoch 65/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0243 - val_loss: 0.0583\n",
      "Epoch 66/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0242 - val_loss: 0.0595\n",
      "Epoch 67/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0245 - val_loss: 0.0583\n",
      "Epoch 68/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0237 - val_loss: 0.0586\n",
      "Epoch 69/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0241 - val_loss: 0.0585\n",
      "Epoch 70/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0237 - val_loss: 0.0587\n",
      "Epoch 71/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0235 - val_loss: 0.0589\n",
      "Epoch 72/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0238 - val_loss: 0.0602\n",
      "Epoch 73/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0232 - val_loss: 0.0585\n",
      "Epoch 74/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0235 - val_loss: 0.0584\n",
      "Epoch 75/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0232 - val_loss: 0.0591\n",
      "Epoch 76/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0232 - val_loss: 0.0588\n",
      "Epoch 77/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0232 - val_loss: 0.0592\n",
      "Epoch 78/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0231 - val_loss: 0.0589\n",
      "Epoch 79/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0230 - val_loss: 0.0576\n",
      "Epoch 80/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0231 - val_loss: 0.0591\n",
      "Epoch 81/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0230 - val_loss: 0.0583\n",
      "Epoch 82/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0223 - val_loss: 0.0578\n",
      "Epoch 83/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0227 - val_loss: 0.0607\n",
      "Epoch 84/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0228 - val_loss: 0.0584\n",
      "Epoch 85/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0223 - val_loss: 0.0582\n",
      "Epoch 86/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0221 - val_loss: 0.0592\n",
      "Epoch 87/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0221 - val_loss: 0.0583\n",
      "Epoch 88/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0220 - val_loss: 0.0591\n",
      "Epoch 89/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0223 - val_loss: 0.0579\n",
      "Epoch 90/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0218 - val_loss: 0.0582\n",
      "Epoch 91/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0221 - val_loss: 0.0585\n",
      "Epoch 92/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0218 - val_loss: 0.0580\n",
      "Epoch 93/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0213 - val_loss: 0.0581\n",
      "Epoch 94/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0215 - val_loss: 0.0576\n",
      "Epoch 95/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0220 - val_loss: 0.0582\n",
      "Epoch 96/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0215 - val_loss: 0.0585\n",
      "Epoch 97/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0217 - val_loss: 0.0585\n",
      "Epoch 98/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0216 - val_loss: 0.0599\n",
      "Epoch 99/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0214 - val_loss: 0.0576\n",
      "Epoch 100/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0210 - val_loss: 0.0598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1860472e0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(train_inputs, train_outputs, epochs=100, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "persistent-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = keras.Sequential([layers.Dense(256, activation='relu',input_shape = (570,)),layers.Dropout(0.5),layers.Dense(256, activation='relu'),layers.Dense(1) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "instructional-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(loss='mean_absolute_error',optimizer=tf.keras.optimizers.Adam(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "younger-lecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 256)               146176    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 212,225\n",
      "Trainable params: 212,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "egyptian-blink",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2395 - val_loss: 0.1012\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.1121 - val_loss: 0.0862\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0915 - val_loss: 0.0877\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0802 - val_loss: 0.0867\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0728 - val_loss: 0.0679\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0688 - val_loss: 0.0743\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0662 - val_loss: 0.0752\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0634 - val_loss: 0.0657\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0616 - val_loss: 0.0763\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0607 - val_loss: 0.0641\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0589 - val_loss: 0.0626\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0570 - val_loss: 0.0670\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0557 - val_loss: 0.0648\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0544 - val_loss: 0.0618\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0535 - val_loss: 0.0608\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0522 - val_loss: 0.0630\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0513 - val_loss: 0.0633\n",
      "Epoch 18/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0507 - val_loss: 0.0638\n",
      "Epoch 19/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0635\n",
      "Epoch 20/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0497 - val_loss: 0.0623\n",
      "Epoch 21/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0487 - val_loss: 0.0647\n",
      "Epoch 22/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0474 - val_loss: 0.0610\n",
      "Epoch 23/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0468 - val_loss: 0.0629\n",
      "Epoch 24/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0463 - val_loss: 0.0634\n",
      "Epoch 25/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0463 - val_loss: 0.0647\n",
      "Epoch 26/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0450 - val_loss: 0.0620\n",
      "Epoch 27/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0442 - val_loss: 0.0609\n",
      "Epoch 28/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0445 - val_loss: 0.0605\n",
      "Epoch 29/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0446 - val_loss: 0.0608\n",
      "Epoch 30/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0429 - val_loss: 0.0616\n",
      "Epoch 31/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0427 - val_loss: 0.0618\n",
      "Epoch 32/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0425 - val_loss: 0.0590\n",
      "Epoch 33/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0430 - val_loss: 0.0600\n",
      "Epoch 34/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0409 - val_loss: 0.0610\n",
      "Epoch 35/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0414 - val_loss: 0.0596\n",
      "Epoch 36/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0413 - val_loss: 0.0581\n",
      "Epoch 37/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0412 - val_loss: 0.0599\n",
      "Epoch 38/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0404 - val_loss: 0.0593\n",
      "Epoch 39/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0399 - val_loss: 0.0599\n",
      "Epoch 40/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0586\n",
      "Epoch 41/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0400 - val_loss: 0.0603\n",
      "Epoch 42/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0392 - val_loss: 0.0586\n",
      "Epoch 43/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0386 - val_loss: 0.0586\n",
      "Epoch 44/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0385 - val_loss: 0.0580\n",
      "Epoch 45/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0375 - val_loss: 0.0575\n",
      "Epoch 46/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0379 - val_loss: 0.0591\n",
      "Epoch 47/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0381 - val_loss: 0.0578\n",
      "Epoch 48/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0376 - val_loss: 0.0573\n",
      "Epoch 49/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0373 - val_loss: 0.0610\n",
      "Epoch 50/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0369 - val_loss: 0.0563\n",
      "Epoch 51/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0372 - val_loss: 0.0576\n",
      "Epoch 52/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0368 - val_loss: 0.0571\n",
      "Epoch 53/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0362 - val_loss: 0.0570\n",
      "Epoch 54/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0361 - val_loss: 0.0571\n",
      "Epoch 55/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0586\n",
      "Epoch 56/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0358 - val_loss: 0.0578\n",
      "Epoch 57/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0356 - val_loss: 0.0588\n",
      "Epoch 58/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0349 - val_loss: 0.0570\n",
      "Epoch 59/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0347 - val_loss: 0.0569\n",
      "Epoch 60/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0354 - val_loss: 0.0566\n",
      "Epoch 61/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0344 - val_loss: 0.0574\n",
      "Epoch 62/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0343 - val_loss: 0.0559\n",
      "Epoch 63/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0342 - val_loss: 0.0582\n",
      "Epoch 64/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0344 - val_loss: 0.0560\n",
      "Epoch 65/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0334 - val_loss: 0.0571\n",
      "Epoch 66/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0342 - val_loss: 0.0575\n",
      "Epoch 67/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0334 - val_loss: 0.0565\n",
      "Epoch 68/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0335 - val_loss: 0.0581\n",
      "Epoch 69/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0335 - val_loss: 0.0578\n",
      "Epoch 70/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0337 - val_loss: 0.0564\n",
      "Epoch 71/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0331 - val_loss: 0.0575\n",
      "Epoch 72/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0330 - val_loss: 0.0565\n",
      "Epoch 73/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0328 - val_loss: 0.0572\n",
      "Epoch 74/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0330 - val_loss: 0.0553\n",
      "Epoch 75/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0328 - val_loss: 0.0563\n",
      "Epoch 76/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0330 - val_loss: 0.0556\n",
      "Epoch 77/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0323 - val_loss: 0.0564\n",
      "Epoch 78/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0322 - val_loss: 0.0557\n",
      "Epoch 79/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0325 - val_loss: 0.0555\n",
      "Epoch 80/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0314 - val_loss: 0.0555\n",
      "Epoch 81/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0313 - val_loss: 0.0572\n",
      "Epoch 82/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0311 - val_loss: 0.0562\n",
      "Epoch 83/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0315 - val_loss: 0.0580\n",
      "Epoch 84/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0316 - val_loss: 0.0554\n",
      "Epoch 85/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0311 - val_loss: 0.0563\n",
      "Epoch 86/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0311 - val_loss: 0.0569\n",
      "Epoch 87/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0313 - val_loss: 0.0548\n",
      "Epoch 88/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0314 - val_loss: 0.0553\n",
      "Epoch 89/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0309 - val_loss: 0.0552\n",
      "Epoch 90/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0309 - val_loss: 0.0563\n",
      "Epoch 91/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0312 - val_loss: 0.0564\n",
      "Epoch 92/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0307 - val_loss: 0.0563\n",
      "Epoch 93/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0298 - val_loss: 0.0566\n",
      "Epoch 94/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0306 - val_loss: 0.0573\n",
      "Epoch 95/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0302 - val_loss: 0.0559\n",
      "Epoch 96/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0307 - val_loss: 0.0571\n",
      "Epoch 97/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0304 - val_loss: 0.0563\n",
      "Epoch 98/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0299 - val_loss: 0.0560\n",
      "Epoch 99/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0302 - val_loss: 0.0566\n",
      "Epoch 100/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0302 - val_loss: 0.0552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x186157220>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(train_inputs, train_outputs, epochs=100, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "treated-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = keras.Sequential([layers.Dense(256, activation='relu',input_shape = (570,)),layers.Dropout(0.5),layers.Dense(256, activation='relu'),layers.Dropout(0.5),layers.Dense(1) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "casual-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(loss='mean_absolute_error',optimizer=tf.keras.optimizers.Adam(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "patient-functionality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 256)               146176    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 212,225\n",
      "Trainable params: 212,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "designed-watson",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.2581 - val_loss: 0.1367\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.1359 - val_loss: 0.0904\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.1061 - val_loss: 0.0714\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0931 - val_loss: 0.0678\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0842 - val_loss: 0.0678\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0789 - val_loss: 0.0796\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0759 - val_loss: 0.0675\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0739 - val_loss: 0.0698\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0719 - val_loss: 0.0778\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0695 - val_loss: 0.0697\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0691 - val_loss: 0.0665\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0678 - val_loss: 0.0697\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0666 - val_loss: 0.0643\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0650 - val_loss: 0.0671\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0643 - val_loss: 0.0632\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0637 - val_loss: 0.0631\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0629 - val_loss: 0.0653\n",
      "Epoch 18/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0627 - val_loss: 0.0630\n",
      "Epoch 19/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0624 - val_loss: 0.0657\n",
      "Epoch 20/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0620 - val_loss: 0.0694\n",
      "Epoch 21/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0620 - val_loss: 0.0674\n",
      "Epoch 22/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0612 - val_loss: 0.0753\n",
      "Epoch 23/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0600 - val_loss: 0.0696\n",
      "Epoch 24/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0601 - val_loss: 0.0710\n",
      "Epoch 25/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0598 - val_loss: 0.0665\n",
      "Epoch 26/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0597 - val_loss: 0.0649\n",
      "Epoch 27/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0592 - val_loss: 0.0722\n",
      "Epoch 28/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0581 - val_loss: 0.0708\n",
      "Epoch 29/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0586 - val_loss: 0.0648\n",
      "Epoch 30/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0588 - val_loss: 0.0652\n",
      "Epoch 31/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0578 - val_loss: 0.0690\n",
      "Epoch 32/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0580 - val_loss: 0.0655\n",
      "Epoch 33/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0576 - val_loss: 0.0729\n",
      "Epoch 34/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0573 - val_loss: 0.0776\n",
      "Epoch 35/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0568 - val_loss: 0.0677\n",
      "Epoch 36/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0562 - val_loss: 0.0675\n",
      "Epoch 37/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0560 - val_loss: 0.0686\n",
      "Epoch 38/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0559 - val_loss: 0.0640\n",
      "Epoch 39/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0562 - val_loss: 0.0787\n",
      "Epoch 40/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0561 - val_loss: 0.0688\n",
      "Epoch 41/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0551 - val_loss: 0.0675\n",
      "Epoch 42/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0550 - val_loss: 0.0653\n",
      "Epoch 43/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0547 - val_loss: 0.0630\n",
      "Epoch 44/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0558 - val_loss: 0.0633\n",
      "Epoch 45/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0555 - val_loss: 0.0666\n",
      "Epoch 46/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0540 - val_loss: 0.0675\n",
      "Epoch 47/100\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0545 - val_loss: 0.0666\n",
      "Epoch 48/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0540 - val_loss: 0.0724\n",
      "Epoch 49/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0547 - val_loss: 0.0659\n",
      "Epoch 50/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0535 - val_loss: 0.0655\n",
      "Epoch 51/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0535 - val_loss: 0.0726\n",
      "Epoch 52/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0552 - val_loss: 0.0654\n",
      "Epoch 53/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0543 - val_loss: 0.0656\n",
      "Epoch 54/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0538 - val_loss: 0.0693\n",
      "Epoch 55/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0532 - val_loss: 0.0639\n",
      "Epoch 56/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0539 - val_loss: 0.0696\n",
      "Epoch 57/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0528 - val_loss: 0.0653\n",
      "Epoch 58/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0521 - val_loss: 0.0694\n",
      "Epoch 59/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0526 - val_loss: 0.0694\n",
      "Epoch 60/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0528 - val_loss: 0.0657\n",
      "Epoch 61/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0531 - val_loss: 0.0648\n",
      "Epoch 62/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0529 - val_loss: 0.0675\n",
      "Epoch 63/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0521 - val_loss: 0.0641\n",
      "Epoch 64/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0523 - val_loss: 0.0687\n",
      "Epoch 65/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0524 - val_loss: 0.0638\n",
      "Epoch 66/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0516 - val_loss: 0.0671\n",
      "Epoch 67/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0520 - val_loss: 0.0615\n",
      "Epoch 68/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0519 - val_loss: 0.0710\n",
      "Epoch 69/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0522 - val_loss: 0.0658\n",
      "Epoch 70/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0528 - val_loss: 0.0660\n",
      "Epoch 71/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0514 - val_loss: 0.0647\n",
      "Epoch 72/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0522 - val_loss: 0.0712\n",
      "Epoch 73/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0526 - val_loss: 0.0650\n",
      "Epoch 74/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0511 - val_loss: 0.0642\n",
      "Epoch 75/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0510 - val_loss: 0.0677\n",
      "Epoch 76/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0506 - val_loss: 0.0692\n",
      "Epoch 77/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0514 - val_loss: 0.0620\n",
      "Epoch 78/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0509 - val_loss: 0.0632\n",
      "Epoch 79/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0513 - val_loss: 0.0665\n",
      "Epoch 80/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0513 - val_loss: 0.0683\n",
      "Epoch 81/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0645\n",
      "Epoch 82/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0695\n",
      "Epoch 83/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0507 - val_loss: 0.0716\n",
      "Epoch 84/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0672\n",
      "Epoch 85/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0501 - val_loss: 0.0693\n",
      "Epoch 86/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0505 - val_loss: 0.0697\n",
      "Epoch 87/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0503 - val_loss: 0.0636\n",
      "Epoch 88/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0504 - val_loss: 0.0649\n",
      "Epoch 89/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0507 - val_loss: 0.0704\n",
      "Epoch 90/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0680\n",
      "Epoch 91/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0497 - val_loss: 0.0643\n",
      "Epoch 92/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0499 - val_loss: 0.0665\n",
      "Epoch 93/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0509 - val_loss: 0.0700\n",
      "Epoch 94/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0507 - val_loss: 0.0698\n",
      "Epoch 95/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0495 - val_loss: 0.0690\n",
      "Epoch 96/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0497 - val_loss: 0.0684\n",
      "Epoch 97/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0490 - val_loss: 0.0682\n",
      "Epoch 98/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0496 - val_loss: 0.0659\n",
      "Epoch 99/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0496 - val_loss: 0.0685\n",
      "Epoch 100/100\n",
      "657/657 [==============================] - 1s 1ms/step - loss: 0.0490 - val_loss: 0.0708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18626b0a0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(train_inputs, train_outputs, epochs=100, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "viral-vault",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 - 0s - loss: 0.0555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05549696087837219"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(test_inputs,  test_outputs, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-nylon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
